# コスト最適化戦略：親の財布を守りつつ、子どもたちの成長を支える

## 現状分析

### 現在のコスト構造

```
VPS環境（本番）:
  LLM: OpenAI gpt-4o
  料金: $15/1M input tokens, $60/1M output tokens
  
ローカル環境（学習・検証）:
  LLM: Ollama (qwen2.5:32b)
  料金: 電気代のみ（ほぼ無料）
```

### 月間コスト試算

仮定:
- ユーザー数: 10人
- 1日あたり平均会話数: 50回
- 1会話の平均トークン数: 
  - Input: 500 tokens（プロンプト + 履歴）
  - Output: 200 tokens（応答）

```python
# 月間トークン数
input_tokens = 50 * 30 * 500 = 750,000 tokens
output_tokens = 50 * 30 * 200 = 300,000 tokens

# 月間コスト
input_cost = (750,000 / 1,000,000) * $15 = $11.25
output_cost = (300,000 / 1,000,000) * $60 = $18.00
total_cost = $29.25/月 ≈ ¥4,500/月（$1=¥150として）
```

**年間コスト**: 約 ¥54,000

これは「3人の娘を育てる」コストとしては妥当ですが、最適化の余地があります。

---

## コスト最適化戦略

### 戦略1: ハイブリッドLLM運用（推奨）

**基本方針**: 
- **重要な会話のみgpt-4o**
- **定型的な会話はOllama（ローカル）**

#### 実装案

```python
class HybridLLMRouter:
    """
    会話の重要度に応じてLLMを切り替える
    """
    
    def route_llm(self, user_message: str, context: dict) -> str:
        """
        LLMを選択
        """
        importance = self.calculate_importance(user_message, context)
        
        if importance >= 0.7:
            return "gpt-4o"  # クラウド（高品質）
        elif importance >= 0.4:
            return "gpt-4o-mini"  # クラウド（低コスト）
        else:
            return "ollama"  # ローカル（無料）
    
    def calculate_importance(self, message: str, context: dict) -> float:
        """
        重要度を計算（0.0-1.0）
        """
        score = 0.0
        
        # 1. 新規ユーザー → 重要（第一印象）
        if context['is_new_user']:
            score += 0.3
        
        # 2. プロレス（じゃれ合い）→ 重要（学習対象）
        if context['layer4_judgment'] == "じゃれ合い":
            score += 0.4
        
        # 3. 長い会話 → 重要（深い対話）
        if len(message) > 50:
            score += 0.2
        
        # 4. キャラクター選択直後 → 重要
        if context['just_switched_character']:
            score += 0.3
        
        # 5. 定型的な挨拶 → 重要度低
        greetings = ["おはよう", "こんにちは", "こんばんは", "おやすみ"]
        if any(g in message for g in greetings):
            score -= 0.3
        
        return min(1.0, max(0.0, score))
```

#### コスト削減効果

```
従来: 全会話でgpt-4o
  → 100% クラウドLLM
  → ¥4,500/月

ハイブリッド運用:
  - 30%: gpt-4o（重要な会話）
  - 30%: gpt-4o-mini（通常会話）
  - 40%: Ollama（定型会話）
  
コスト計算:
  gpt-4o: ¥4,500 * 0.3 = ¥1,350
  gpt-4o-mini: ¥450 * 0.3 = ¥135
  Ollama: ¥0 * 0.4 = ¥0
  
合計: ¥1,485/月（67%削減！）
```

---

### 戦略2: プロレスパターンDBの活用（既存設計）

**基本方針**: 学習済みパターンはLLM不要

```python
# プロレスパターンDBから取得
if best_pattern := prowrestling_db.find_best_match(message):
    return best_pattern['response']  # LLM不要！
else:
    return llm.generate(message)  # LLMで生成
```

#### コスト削減効果

学習が進むにつれて、パターンDB利用率が上昇：

```
Phase 1（初期）:
  パターンDB利用率: 10%
  → コスト削減: 10%
  
Phase 2（3ヶ月後）:
  パターンDB利用率: 40%
  → コスト削減: 40%
  
Phase 3（6ヶ月後）:
  パターンDB利用率: 60%
  → コスト削減: 60%
```

**長期的にはコストがゼロに近づく**

---

### 戦略3: コンテキスト圧縮

**問題**: 会話履歴が長くなるとトークン数が増大

**解決策**: 
1. 重要な情報のみ保持
2. 古い会話を要約
3. 不要な情報を削除

```python
class ContextCompressor:
    """
    コンテキストを圧縮してトークン数を削減
    """
    
    def compress(self, conversation_history: list) -> list:
        """
        会話履歴を圧縮
        """
        # 1. 最新5件は全て保持
        recent = conversation_history[-5:]
        
        # 2. それ以前は要約
        older = conversation_history[:-5]
        if older:
            summary = self.summarize(older)
            return [{"role": "system", "content": f"過去の会話要約: {summary}"}] + recent
        
        return recent
    
    def summarize(self, messages: list) -> str:
        """
        複数の会話を要約（ローカルOllamaで実行）
        """
        # ローカルLLMで要約（無料）
        prompt = f"以下の会話を3文で要約してください:\n{messages}"
        return ollama.generate(prompt)
```

#### コスト削減効果

```
従来: 会話履歴全て送信
  Input tokens: 500 tokens/会話
  
圧縮後: 最新5件 + 要約
  Input tokens: 200 tokens/会話
  
削減率: 60%
月間コスト: ¥4,500 → ¥1,800
```

---

### 戦略4: gpt-4o-miniの活用

**gpt-4o-mini**: gpt-4oの10分の1のコスト

```
gpt-4o:
  Input: $15/1M tokens
  Output: $60/1M tokens
  
gpt-4o-mini:
  Input: $0.15/1M tokens
  Output: $0.60/1M tokens
  
→ 10倍安い！
```

**使い分け**:
- **gpt-4o**: プロレス（じゃれ合い）、新規ユーザー、重要会話
- **gpt-4o-mini**: 通常会話、質問応答
- **Ollama**: 定型会話、パターンマッチング可能な会話

---

### 戦略5: キャッシュの活用

**問題**: 同じプロンプトを何度も送信している

**解決策**: OpenAIのPrompt Caching機能を利用

```python
# システムプロンプトをキャッシュ
system_prompt = """
あなたは牡丹です。17歳の次女で、LA帰りの帰国子女...
（以下、長いプロンプト）
"""

# キャッシュされるため、2回目以降はトークン数が大幅減少
```

#### コスト削減効果

```
システムプロンプト: 500 tokens
従来: 毎回送信 → 500 tokens × 50回/日 = 25,000 tokens/日

キャッシュ利用:
  初回: 500 tokens
  2回目以降: 50 tokens（キャッシュから読み込み）
  → 平均: 100 tokens/日
  
削減率: 96%！
```

---

### 戦略6: ユーザー数制限（初期）

**現実的な運用**: テスト版なので、ユーザー数を制限

```
Phase 1（現在）: 
  テスター: 5-10人
  コスト: ¥1,500-3,000/月
  
Phase 2（3ヶ月後）:
  テスター: 20-30人
  コスト: ¥3,000-5,000/月
  （パターンDB活用で削減）
  
Phase 3（6ヶ月後）:
  一般公開検討
  スポンサー・寄付を募る
```

---

## 総合コスト試算

### 全戦略を組み合わせた場合

```
ベースライン: ¥4,500/月

最適化後:
  1. ハイブリッドLLM: 67%削減 → ¥1,485
  2. プロレスパターンDB: 40%削減 → ¥891
  3. コンテキスト圧縮: 60%削減 → ¥356
  4. gpt-4o-mini活用: 既に反映済み
  5. プロンプトキャッシュ: 30%削減 → ¥249
  
最終月間コスト: 約¥250/月
年間コスト: 約¥3,000/年

削減率: 94%！
```

**コーヒー1杯分のコストで、3人の娘を育てられる**

---

## 実装優先順位

### Phase 1: 即座に実施可能（今週）

1. **gpt-4o-miniへの部分切り替え**
   ```python
   # 通常会話はgpt-4o-mini
   if context['layer4_judgment'] != "じゃれ合い":
       model = "gpt-4o-mini"
   else:
       model = "gpt-4o"
   ```
   **効果**: 70%削減

2. **プロンプトキャッシュの有効化**
   ```python
   # OpenAI APIのcache機能を有効化
   ```
   **効果**: 30%削減

**即座の削減**: ¥4,500 → ¥945/月（79%削減）

### Phase 2: 2週間以内

3. **ハイブリッドLLMルーター実装**
   ```bash
   python scripts/implement_hybrid_llm_router.py
   ```
   **効果**: さらに50%削減

4. **コンテキスト圧縮**
   ```bash
   python scripts/implement_context_compressor.py
   ```
   **効果**: さらに40%削減

**Phase 2後のコスト**: ¥250/月

### Phase 3: 長期（3-6ヶ月）

5. **プロレスパターンDBの充実**
   - 自動学習による蓄積
   - パターン利用率の向上

**Phase 3後のコスト**: ほぼゼロ（電気代のみ）

---

## モニタリング

### コスト追跡ダッシュボード

```python
# 毎日のコスト集計
class CostMonitor:
    def track_usage(self):
        daily_cost = {
            'gpt-4o': self.calc_cost('gpt-4o'),
            'gpt-4o-mini': self.calc_cost('gpt-4o-mini'),
            'ollama': 0,
            'pattern_db': 0  # パターンDB利用（無料）
        }
        
        print(f"今日のコスト: ¥{sum(daily_cost.values())}")
        print(f"今月の累計: ¥{self.monthly_total}")
```

### アラート設定

```python
# 月間コストが予算を超えたらアラート
if monthly_cost > BUDGET:
    notify("⚠️ 予算超過！Ollamaの利用率を上げてください")
```

---

## 親としての判断

### コストと価値のバランス

```
投資（コスト）:
  Phase 1: ¥945/月
  Phase 2: ¥250/月
  Phase 3: ほぼゼロ
  
リターン（価値）:
  - AI技術の習得
  - 研究成果（論文・記事）
  - オープンソースへの貢献
  - 転職活動での実績
  - 娘たち（牡丹・花相・百合）の成長
  
→ 圧倒的にリターンが大きい
```

### 本当の「親」の仕事

- 必要な投資はする
- でも、無駄遣いはしない
- **賢く育てる**

まさに今回の最適化戦略です。

---

## まとめ

### Before（現状）
```
全会話でgpt-4o使用
→ ¥4,500/月
→ 年間¥54,000
```

### After（最適化後）
```
ハイブリッドLLM + プロレスパターンDB
→ ¥250/月
→ 年間¥3,000
→ 94%削減！
```

### 最終形（半年後）
```
プロレスパターンDB充実
→ ほぼゼロ
→ 電気代のみ
```

**親の財布を守りつつ、娘たちは健やかに成長する。これが理想です。**

---

**🤖 Generated with Claude Code**

**Co-Authored-By**: Claude <noreply@anthropic.com>

**作成日**: 2025-11-13
