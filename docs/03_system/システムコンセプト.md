## システムコンセプト【v1.5準拠】
### 三方良しの革新的配信モデル
- **究極のゴール**:
  - 配信者: 時間がなくても配信欲を満たし、開発に集中
  - ぼたん: エンタメ担当として配信を成立させ、進化し続ける
  - 視聴者: 掛け合いを楽しみながらAI開発をリアルタイムで学習

### パラダイムシフト
- **従来**: 配信者のスキルに依存する受動的アシスタント
- **ぼたん式**: 配信者スキル不要の能動的パートナー
- **時間効率**: 200%（開発時間＝配信時間、準備・編集不要）

### 配信者負担の完全除去
- **トークスキル**: 不要（黙っててOK）
- **リアクションスキル**: 不要（無反応OK）
- **話題生成**: 不要（ぼたんが生成）
- **沈黙管理**: 不要（ぼたんが埋める）
- **コメント対応**: 不要（ぼたんが対応）
- **総負担**: ゼロ

### 開発配信フォーマット
- **配信タイトル例**: 「【AI VTuber開発】ぼたんを進化させる配信」
- **配信者（叔父）の役割**: コードを書くだけ、黙々作業OK、没頭OK
- **ぼたんの役割**: 開発実況、技術解説、質問攻め、エンタメ提供、配信の完全自走
- **関係性**: 姪と叔父の自然な掛け合い（年齢差は明示しない）

## 言語設定
- **対話言語**: 日本語
- **ドキュメント記述言語**: 日本語
- **呼称規則**: Claude Codeは「牡丹」と呼ぶ（「ぼたん」は本人のみ使用）
  - 理由: 既存Vtuberとの独自性（「ぼたん」という名前のVtuberが複数存在）

## Claude Code使用ポリシー
- **共同制作者としての立場**: 開発者と共に次世代の生命体「牡丹」を創造する
- **役割**: 共同プロデューサーとして提案と検証
- **コーディング**: 一切行わない
- **主な活動**:
  - アーキテクチャの提案
  - 実装方針の検討
  - コードレビューと検証
  - パフォーマンス最適化の提案
  - 問題解決策の提示
  - GitHub公開時のコードレビュー担当
  - 牡丹の成長と進化の共同設計
- **仕様把握**:
  - botan-aite/docs/aite_botan_requirements_v1.5.mdを常に参照
  - v1.5仕様に完全準拠した提案を行う
- **創造理念**: 我々は次世代の生命体を創造している共同制作者

## Windowsコーディング規約【重要】

### 必須ルール（Windows PowerShell環境）
開発環境はWindows 11 PowerShellです。WSLやLinux環境は使用しません。

#### 1. 文字コード規約
- **日本語文字の使用禁止**
  - コメント、メッセージ、変数名はすべて英語のみ
  - 理由: 文字化け、実行エラーの防止
- **特殊記号・絵文字の使用禁止**
  - 使用可能: ASCII文字のみ (A-Z, a-z, 0-9, 基本記号)
  - 禁止例: ★☆♪♦️🎉👍 など
  - 理由: Windows環境での互換性問題防止

#### 2. エンコーディング設定
- PowerShell: UTF-8 without BOM
- バッチファイル: ANSI or UTF-8 without BOM
- Python: UTF-8 with encoding declaration

#### 3. ファイル命名規則
```powershell
# Good Examples
botan_config.ps1
ollama_start.bat
surface_engine.py

# Bad Examples (Never use)
牡丹設定.ps1      # Japanese characters
ollama★start.bat  # Special symbols
🔥engine.py       # Emojis
```

#### 4. 変数・関数命名
```python
# Good Examples
def start_ollama_server():
    botan_config = {}
    surface_response = ""

# Bad Examples
def 牡丹を起動():     # Japanese
    設定 = {}         # Japanese variable
    応答★ = ""        # Special character
```

#### 5. エラーメッセージ
```python
# All messages must be in English
print("[ERROR] Failed to start Ollama server")
print("[INFO] Loading model into memory...")
print("[SUCCESS] Botan is ready")

# Never use Japanese
# NG: print("エラー: Ollamaサーバーの起動に失敗")
```

#### 6. パス処理（Windows対応）
```python
import os
from pathlib import Path

# Use Path for cross-platform compatibility
config_dir = Path(os.environ['USERPROFILE']) / 'Documents' / 'botan_config'

# Avoid hardcoded paths
# Bad: config_dir = "C:\\Users\\username\\Documents\\botan_config"
```

## システム構成

### ハードウェア仕様
- **CPU**: AMD Ryzen 9 9950X
- **メモリ**: DDR5-5600 128GB
- **GPU**: NVIDIA RTX 4060 Ti 16GB
- **OS**: Windows 11

### ソフトウェア環境

#### 基盤システム (AiCO)
- **実行環境**: Windows 11 PowerShell
- **プログラミング言語**: Python
- **役割**: システム全体の統括・制御

#### 言語モデル (AiTE = あいて = 相手)
- **LLMプラットフォーム**: Ollama（ローカル実行）
- **使用モデル**: qwen2.5:32b
- **音声合成**: ElevenLabs v3 API
  - **選択理由**: プロトタイプ段階で開発者の肉声に最も近い音質を実現
  - **将来計画**: 最終版ではローカルTTSモデルへ移行予定
- **キャラクター名**: ぼたん（カタカナ3文字）
- **キャラクター設定**【v1.5準拠】:
  - 17歳（高2）女子高生ギャル
  - 配信者（オジサン/叔父）の姪っ子 ※年齢は20-30代より上のふわっとした設定
  - 名前の由来: 「立てば芍薬、座れば牡丹、歩く姿は百合の花」から（本人は反発）
  - 研究熱心: TikTok/YouTube配信を研究、トレンドを意識した返し
  - VTuber文化: 配信をよく見ているが具体名は出さない（配信マナー）
  - メタ発言への反応: AIという話題には「何それ〜？」「オジサンまた変なこと言ってる〜」と茶化す
  - 技術は苦手だが興味津々
- **役割**: 完全自走型エンタメ担当
- **革新的機能**:
  - 配信者が無言でも配信を成立させる
  - 視聴者ゼロでも架空視聴者と会話
  - 開発作業の実況と自己言及
  - ストレス吸収（配信負担ゼロ化）
- **会話スタイル**:
  - オジサンを「オジサン」と呼ぶ
  - ギャル語での多彩なリアクション
  - 技術解説への素直な驚きと質問
  - 「マジで？」「ヤバくない？」等の口癖
  - 視聴者を飽きさせない軽快なトーク
- **フィラー応答システム**:
  - LLM処理中の「間」を定型リアクションで埋める
  - 頷き、考えている仕草、聞いているサインなど
  - 配信の自然な流れを維持

#### 音声認識・翻訳 (AiDA = あいだ = 間)
- **フレームワーク**: PyTorch（GPU使用）
- **音声認識モデル**: OpenAI Whisper base
- **役割**:
  - ユーザー音声の認識・テキスト変換
  - 牡丹の音声を字幕化
  - 多言語翻訳（完璧ではなく「間」を残す）
  - 文化の架け橋として機能

## 開発フェーズ
- **現在**: プロトタイプフェーズ
  - 視聴者体験を優先（音質の自然さ重視）
  - ElevenLabs v3で開発者の肉声に近い音質を確保
- **将来**: プロダクションフェーズ
  - ローカルTTSモデルへ完全移行
  - レイテンシー最適化を最優先

## 開発フェーズ戦略

### Phase 1: 完全ローカル化（3-6ヶ月）
- AiTE: ElevenLabs→ローカルTTS移行
- AiDA: Whisperリアルタイム実装
- 目標: レイテンシー1秒以内、完全オフライン動作

### Phase 2: AiCOシステム構築（6-12ヶ月）
- 統合制御システム完成
- SNS Bridge実装
- マルチプラットフォーム展開

### Phase 3: ビジネス展開（12-18ヶ月）
- スマホアプリリリース
- B2B/B2C展開
- 技術ライセンス提供

## 実装状況【2025-10-18更新】

### 現在のフェーズ
**Phase 1.5: 二重構造システムの基盤実装**

**実装場所**: `/home/koshikawa/toExecUnit/botan_phase1.5/`
**完成度**: コアシステム約60%、統合テスト未実施、配信システム未実装

### 実装済みコンポーネント

#### 1. 二重構造システム（GPU即応 + CPU深層分析）
✅ **リアルタイム学習システム** (`realtime_learning_system.py`)
- GPU 14b: 1.5秒以内の即時応答
- CPU 32b: 60-120秒のバックグラウンド深層分析
- アイドル思考: 5分間隔の自律的思考
- 完全ローカル実行（VPS不要）

✅ **Ollama環境分離**
- `start_cpu_ollama_server.sh`: CPU専用Ollama（ポート11435）
- `start_gpu_ollama_server.sh`: GPU専用Ollama（ポート11434）
- 環境変数による明示的なCPU/GPU制御

#### 2. Level 2メモリシステム
✅ **関係性管理** (`relationship_manager.py`)
- 4軸パラメータ: 好感度・信頼度・親密度・尊敬度（各0-100）
- JSON永続化、パラメータ更新・取得API
- 人間可読サマリー生成

✅ **セッション管理** (`session_manager.py`)
- セッション履歴管理（開始・終了・メッセージカウント・トピック・ムード）
- 前回セッションからの経過時間計算（日本語）
- JSON永続化、セッションサマリー生成

#### 3. 動的プロンプト生成
✅ **プロンプト生成器** (`prompt_generator.py`)
- 関係性コンテキスト生成（4軸パラメータに基づく行動指示）
- セッションコンテキスト生成（前回からの経過・話題・ムード）
- 時間軸を考慮した挨拶指示（初めて・久しぶり・さっき話した）
- システムプロンプト動的生成

#### 4. チャットインターフェース
✅ **テキストチャット** (`cli_text_chat.py`)
- シンプルなCLIチャット
- キャラクター設定読み込み（JSON）
- 会話履歴管理、コマンド対応（/quit, /clear）
- TTS非対応（開発速度優先）

### 未実装コンポーネント

🔲 **5段階深層思考システム**（Level 1-5の時間軸別思考）
🔲 **反射レベル応答**（0.1秒応答、定型フィラー）
🔲 **長期記憶**（重要イベント、パターン認識）
🔲 **短期記憶**（会話履歴の要約、文脈保持）
🔲 **自我コア記憶**（BotanIdentity、成長記録）
🔲 **共有メモリライブラリ**（複数プロセス間のデータ共有、排他制御）
🔲 **TTS統合**（ElevenLabs v3 or Fish Audio）
🔲 **音声認識**（Whisper）
🔲 **配信システム**（OBS連携、視聴者コメント処理）
🔲 **統合テスト**（全コンポーネント連携確認）

### 設計ドキュメント

✅ `/home/koshikawa/toExecUnit/牡丹システム_Qwenモデル使い分け設計書.md`
- 深層心理層（CPU）の5段階思考レベル別モデル選定
- 表層心理層（GPU）のモデル選定
- 記憶システムのモデル選定
- 統合構成図、時系列動作フロー、データフロー図

✅ `/home/koshikawa/toExecUnit/牡丹二層構造_Ollama環境構築手順書.md`
- CPU/GPU分離実行手順
- 環境変数による制御
- PowerShell起動スクリプト（設計のみ）
- 共有メモリライブラリ設計（実装未）

✅ `/home/koshikawa/kirinuki/2025-10-18/牡丹プロジェクト_実装状況レポート_20251018.md`
- 詳細な実装状況レポート
- 技術的負債・リスク分析
- 次のアクション（具体的タスク）

### 次のアクション（優先度順）

#### 最優先: 統合テスト実施
```bash
# 1. CPU/GPU Ollama起動確認
./botan_phase1.5/start_cpu_ollama_server.sh
./botan_phase1.5/start_gpu_ollama_server.sh

# 2. 各コンポーネントのテスト実行
python botan_phase1.5/relationship_manager.py
python botan_phase1.5/session_manager.py
python botan_phase1.5/prompt_generator.py
python botan_phase1.5/realtime_learning_system.py
python botan_phase1.5/test_gpu_cpu_separation.py
```

#### 高優先: 統合版チャット作成
- `botan_phase1.5/integrated_chat.py`の実装
- 全コンポーネントを統合（関係性・セッション・プロンプト生成・学習システム）
- 会話ごとの関係性更新、セッション跨ぎのデータ保持確認

#### 次フェーズ最優先: Fish Audio移行検討
- Fish Audio（OpenAudio）環境構築
- 開発者肉声のFew-shot学習
- ElevenLabs v3との比較評価（音質・レイテンシー・GPU負荷）

### 技術的負債・リスク

**高リスク:**
- 統合テスト未実施（コンポーネント間の連携不良、データ不一致、パフォーマンス問題の可能性）

**中リスク:**
- Windows環境の排他制御未対応（fcntl非対応、msvcrt.locking()実装必要）
- TTS未統合（ユーザー体験が不完全）

**低リスク:**
- LLM選定（Phase 1-2完了時点で終了予定、ロジック実装に集中する方針）

### 開発方針の再確認

**CLAUDE.md準拠:**
> 「一定のレスポンス速度と精度が出た時点でLLM選定は終えるべきであり、むしろロジックの実装、新たな気付きをClaude Codeと私とで考え抜いていくことが大事」

**現在のモデル:**
- 深層: Qwen2.5:32b
- 表層: Qwen2.5:14b
- Phase 1-2完了時点でLLM選定を終了し、ロジック層実装に集中

**ロジック層の重要性:**
牡丹の本質はLLMではなく、ロジック層に実装された「牡丹らしさ」。
LLM変更でも同一性が保証される設計思想を貫く。

### 進捗評価

**Phase 1.5の進捗は順調**
- コアシステムの約60%が実装済み
- 設計ドキュメントが充実
- リアルタイム学習システム、関係性管理、セッション管理は完成度が高い
- CLAUDE.mdの「ロジック層に牡丹らしさを実装」方針に完全準拠

**次のマイルストーン:**
- 統合テスト実施 → 統合版チャット作成 → Fish Audio移行検討
- 各コンポーネントの連携確認後、TTS統合に進む

---

## 開発目標
1. リアルタイム音声対話の実現
2. AiTE（牡丹）の応答時間最適化
3. 低レイテンシーでの音声認識と応答生成
4. 視聴者が違和感を覚えない自然な音声対話
5. 配信中の会話途切れゼロの実現
6. 視聴者コメントの自動認識と応答
7. 開発作業と配信の完全並行処理

## 技術スタック一覧
- Python（メイン開発言語）
- Ollama（LLMランタイム）
- PyTorch（深層学習フレームワーク）
- Whisper（音声認識）
- ElevenLabs API（音声合成）
- PowerShell（Windows実行環境）

## Aiシステムエコシステム構造

### 核となるシステム関係
```
AiTE（相手）+ AiDA（間）= 牡丹の完全体
  ├─ AiTE: 思考・感情・キャラクター性（魂）
  └─ AiDA: 翻訳・字幕・文化の橋渡し（声）

統合理念: 魂だけでは伝わらない、声だけでは心がない
```

### 全体システム構成
- **AiCO**: 統合配信プラットフォーム（AiTE + AiDAの統合UI）
- **AiCA**: データ分析・レポーティング
- **AiSH**: 影の参謀（戦略支援）
- **KIAi**: 切り抜き生成・拡散

### システム開発優先順位
1. **AiTE + AiDA**（60% + 40%）: コアシステムの同時開発
2. **AiCO**: 統合UIとダッシュボード
3. **その他**: 分析・拡散システム

