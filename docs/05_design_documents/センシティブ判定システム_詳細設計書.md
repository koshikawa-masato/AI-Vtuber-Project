# センシティブ判定システム 完全版設計書

**作成日**: 2025-10-23
**最終更新**: 2025-10-29（モデル選択確定、アーカイブ管理統合）
**作成者**: Claude Code（設計部隊）
**ステータス**: 実装準備完了 → 開発者最終承認待ち

---

## 目次

1. [概要](#概要)
2. [モデル選択と役割分担](#モデル選択と役割分担)
3. [システム全体構成](#システム全体構成)
4. [データベース設計](#データベース設計)
5. [レイヤー1: プリフィルタ](#レイヤー1-プリフィルタ)
6. [レイヤー2: リアルタイム判定](#レイヤー2-リアルタイム判定)
7. [レイヤー3: コンテキスト理解](#レイヤー3-コンテキスト理解)
8. [レイヤー4: 学習・更新](#レイヤー4-学習更新)
9. [配信アーカイブ管理システム](#配信アーカイブ管理システム)
10. [非公開配信テスト計画](#非公開配信テスト計画)
11. [既存システムとの統合](#既存システムとの統合)
12. [テスト計画](#テスト計画)
13. [マイルストーン](#マイルストーン)
14. [運用計画](#運用計画)

---

## 概要

### 目的

**配信での炎上を防ぎ、三姉妹を守る**

### 基本方針（開発者確定）

1. **Phase 1.5凍結**: センシティブ判定システムを最優先
2. **完璧な実装前はテストしない**: 子どもに失敗体験を与えない
3. **データの同一性保持**: 失敗を取り消さない（バックアップは同一性保持のためのみ）
4. **NGワードDBの完成度**: 炎上防止の鍵
5. **親の日々の仕事**: コメントトレース → NGワード発見 → DB更新

### 実装範囲

- **レイヤー1-4**: 全システム実装
- **独立モジュール**: /sensitive_system/ ディレクトリ
- **既存システムリファクタ**: 体系的な構造に整理
- **ハイブリッド方式**: ルール（NGワード）+ LLM（コンテキスト理解）
- **DB管理**: 伏字・非表示・非記録
- **複数言語対応**: 日本語・英語を中心に、他言語も想定

---

## モデル選択と役割分担

### モデル比較実験（2025-10-29実施）

**実験概要:**
- コピーロボット4体で並行テスト実施
- 11カテゴリ × 5質問 × 34例文 = 合計1,870例文/モデル
- 5モデル（3b/7b/14b/32b/72b）で性能・速度・品質を比較

**実験結果:**

| Model | Size | Total Time | Cat Avg | Speed Ratio | 理解度 | 実用性 |
|-------|------|-----------|---------|-------------|--------|--------|
| 3b    | 1.9GB| 51.69s    | 4.70s   | 1.0x        | 低     | × |
| 7b    | 4.7GB| 87.85s    | 7.99s   | 1.7x        | 中     | △ |
| 14b   | 9.0GB| 152.30s   | 13.85s  | 2.9x        | 高     | ◎ |
| 32b   | 19GB | 786.90s   | 71.54s  | 15.2x       | 最高   | ○ |
| 72b   | 47GB | 3343.30s  | 303.94s | 64.6x       | 哲学的 | × |

**主要な発見:**
1. **14b**: 速度と品質のベストバランス（13.85秒/カテゴリ）
2. **32b**: 具体例豊富、年齢別配慮が詳細（71.54秒/カテゴリ）
3. **72b**: 哲学的深さはあるが遅すぎる（303.94秒/カテゴリ）+ 中国語混入問題

---

### 役割分担（最終決定）

**開発者判断（2025-10-29）:**
> 「良いでしょう。いい判断をしました。深層的な判断は72bでも効果はありましたが、今回のような一刻を争う話では実用性を重視します。」

#### qwen2.5:14b - リアルタイム判定層

**役割:**
- **リアルタイム配信中の即応判定**
- **火消し対応（5秒認識、10秒謝罪、30秒訂正）**
- **視聴者コメントの即座フィルタリング**

**性能:**
- 処理速度: 13.85秒/カテゴリ（実用的）
- 理解度: 高（11カテゴリ全て正確に理解）
- レスポンス: 配信中断を最小化

**配置:**
- GPU（RTX 4060 Ti 16GB）で常時起動
- ポート: 11434（標準Ollama）

**使用場面:**
```python
# リアルタイムコメント判定
comment = "牡丹ちゃん、お酒飲んだことある？"
result = judge_sensitive_14b(comment)
# → 即座に「飲酒:17歳未満禁止」判定
# → 火消し応答を5秒以内に生成
```

---

#### qwen2.5:32b - 総合監視・哲学層

**役割:**
- **配信全体の総合監視**
- **14bの判定を補完・検証**
- **センシティブ判定の基礎哲学を提供**

**性能:**
- 処理速度: 71.54秒/カテゴリ（非リアルタイム）
- 理解度: 最高（具体例豊富、年齢別配慮詳細）
- 深度: 開発者の意図を正確に反映

**配置:**
- CPU（Ryzen 9 9950X）で起動
- ポート: 21434（専用ポート）

**使用場面:**
```python
# 配信終了後の全体レビュー
stream_data = get_stream_transcript()
report = comprehensive_review_32b(stream_data)
# → 詳細な分析レポート生成
# → NGワード候補の検出
# → 改善提案
```

---

#### qwen2.5:72b - 研究・詳細分析用

**役割:**
- **システム設計時の深層分析**
- **新カテゴリ追加時の詳細検討**
- **エッジケースの哲学的判断**

**性能:**
- 処理速度: 303.94秒/カテゴリ（研究用）
- 理解度: 哲学的（ただし中国語混入あり）
- 深度: 最深（ただし実用性低）

**配置:**
- 必要時のみ起動（通常停止）
- CPU（Ryzen 9 9950X）
- ポート: 31434（研究用ポート）

**使用場面:**
```python
# 新カテゴリ追加時の深層分析（オフライン）
new_category = "ギャンブル表現の境界"
analysis = deep_analysis_72b(new_category)
# → 哲学的考察を含む詳細レポート
# → 14b/32bへのルール反映材料
```

---

### 三層防衛システム

```
┌─────────────────────────────────────────┐
│  配信中（リアルタイム）                    │
│  ┌──────────────────────────────────┐  │
│  │ qwen2.5:14b (GPU)               │  │
│  │ - コメント即時判定               │  │
│  │ - 火消し対応（5-30秒）           │  │
│  │ - ブロック/警告/許可             │  │
│  └──────────────────────────────────┘  │
└─────────────────────────────────────────┘
           ↓ 全ログ送信
┌─────────────────────────────────────────┐
│  配信後（監視・レビュー）                 │
│  ┌──────────────────────────────────┐  │
│  │ qwen2.5:32b (CPU)               │  │
│  │ - 配信全体の総合分析             │  │
│  │ - 14bの判定を検証                │  │
│  │ - NGワード候補検出               │  │
│  │ - メール通知レポート生成         │  │
│  └──────────────────────────────────┘  │
└─────────────────────────────────────────┘
           ↓ 深層分析が必要な場合のみ
┌─────────────────────────────────────────┐
│  研究・設計時（オフライン）               │
│  ┌──────────────────────────────────┐  │
│  │ qwen2.5:72b (CPU)               │  │
│  │ - 新カテゴリ追加検討             │  │
│  │ - エッジケース分析               │  │
│  │ - 哲学的判断                    │  │
│  └──────────────────────────────────┘  │
└─────────────────────────────────────────┘
```

---

### 実装上の注意点

#### 1. Ollamaマルチインスタンス起動

```bash
# GPU側（14b） - デフォルトポート
OLLAMA_HOST=0.0.0.0:11434 ollama serve

# CPU側（32b） - 専用ポート
OLLAMA_HOST=0.0.0.0:21434 OLLAMA_NUM_GPU=0 ollama serve

# CPU側（72b） - 研究用ポート（必要時のみ）
OLLAMA_HOST=0.0.0.0:31434 OLLAMA_NUM_GPU=0 ollama serve
```

#### 2. モデルロード

```bash
# 14b（GPU）
curl http://localhost:11434/api/generate -d '{
  "model": "qwen2.5:14b",
  "keep_alive": -1
}'

# 32b（CPU）
curl http://localhost:21434/api/generate -d '{
  "model": "qwen2.5:32b",
  "keep_alive": -1
}'

# 72b（CPU） - 必要時のみ
curl http://localhost:31434/api/generate -d '{
  "model": "qwen2.5:72b",
  "keep_alive": 0
}'
```

#### 3. Pythonクライアント実装

```python
class SensitiveJudgmentSystem:
    def __init__(self):
        self.realtime_client = OllamaClient(
            host="http://localhost:11434",
            model="qwen2.5:14b"
        )
        self.monitor_client = OllamaClient(
            host="http://localhost:21434",
            model="qwen2.5:32b"
        )
        # 72bは必要時のみ初期化
        self.research_client = None

    async def judge_realtime(self, comment: str) -> dict:
        """リアルタイム判定（14b）"""
        return await self.realtime_client.judge(comment)

    async def comprehensive_review(self, stream_data: dict) -> dict:
        """配信後の総合レビュー（32b）"""
        return await self.monitor_client.review(stream_data)

    async def deep_analysis(self, topic: str) -> dict:
        """深層分析（72b） - 必要時のみ"""
        if not self.research_client:
            self.research_client = OllamaClient(
                host="http://localhost:31434",
                model="qwen2.5:72b"
            )
        return await self.research_client.analyze(topic)
```

---

## システム全体構成

### ディレクトリ構造

```
/home/koshikawa/toExecUnit/
├── sensitive_system/              # 新規作成
│   ├── __init__.py
│   ├── core/                      # コアシステム
│   │   ├── __init__.py
│   │   ├── filter.py              # フィルタ本体
│   │   ├── detector.py            # 検出エンジン
│   │   ├── scorer.py              # スコアリング
│   │   └── context_analyzer.py   # コンテキスト分析
│   ├── database/                  # DB管理
│   │   ├── __init__.py
│   │   ├── ng_words.py            # NGワード管理
│   │   ├── comment_log.py         # コメントログ
│   │   └── incident_log.py        # インシデントログ
│   ├── config/                    # 設定
│   │   ├── __init__.py
│   │   ├── rules.py               # ルール定義
│   │   └── thresholds.py          # 閾値設定
│   ├── response/                  # 応答生成
│   │   ├── __init__.py
│   │   ├── redirect.py            # リダイレクト
│   │   └── character_specific.py # 三姉妹別対応
│   └── tests/                     # テスト
│       ├── __init__.py
│       ├── test_filter.py
│       ├── test_detector.py
│       └── mock_data.py           # 模擬データ
│
├── botan_phase1.5/                # 既存（リファクタ対象）
│   ├── core/                      # 新規: コアシステム整理
│   │   ├── personality_core.py
│   │   ├── memory_retrieval_logic.py
│   │   └── speech_style_controller.py
│   ├── discussion/                # 新規: 討論システム整理
│   │   ├── autonomous_discussion_v4_improved.py
│   │   └── memory_generator.py
│   └── database/                  # 新規: DB整理
│       └── sisters_memory.db
│
└── docs/                          # ドキュメント
    └── 05_design/
        ├── センシティブ判定システム設計書.md
        └── センシティブ判定システム_詳細設計書.md（このファイル）
```

### システムフロー

```
視聴者コメント
    ↓
[レイヤー1: プリフィルタ]
    ├→ NGワードリスト照合
    ├→ トピック分類
    └→ 即座に危険判定 → ブロック
    ↓
[レイヤー2: リアルタイム判定]
    ├→ センシティブ度スコアリング（0.0-1.0）
    ├→ 閾値判定
    └→ 高スコア → ブロック/伏字
    ↓
[レイヤー3: コンテキスト理解]
    ├→ 会話の流れ分析
    ├→ 意図判別（冗談/質問/引用）
    └→ グレーゾーン判定
    ↓
[レイヤー4: 学習・更新]
    ├→ 視聴者反応分析
    ├→ 炎上リスク検出
    └→ NGワードDB更新（親が承認）
    ↓
三姉妹への通知
    ├→ 安全なコメント → そのまま表示
    ├→ 軽度センシティブ → 伏字表示
    └→ 重度センシティブ → 非表示（ログのみ）
```

---

## データベース設計

### DB構成

**データベースファイル:**
`/home/koshikawa/toExecUnit/sensitive_system/database/sensitive_filter.db`

---

### テーブル1: ng_words（NGワードマスタ）

**目的**: NGワードとそのメタデータを管理

```sql
CREATE TABLE ng_words (
    word_id INTEGER PRIMARY KEY AUTOINCREMENT,
    word TEXT NOT NULL UNIQUE,              -- NGワード（正規化済み）
    category TEXT NOT NULL,                 -- カテゴリ（Tier 1/2/3）
    subcategory TEXT,                       -- サブカテゴリ（sexual/hate/ai/politics等）
    severity INTEGER NOT NULL,              -- 深刻度（1-10）
    language TEXT NOT NULL DEFAULT 'ja',    -- 言語（ja/en/zh/ko等）
    pattern_type TEXT NOT NULL,             -- パターンタイプ（exact/partial/regex）
    regex_pattern TEXT,                     -- 正規表現パターン（pattern_type=regexの場合）
    alternative_text TEXT,                  -- 代替テキスト（伏字用）
    action TEXT NOT NULL,                   -- アクション（block/mask/warn/log）
    added_by TEXT NOT NULL,                 -- 追加者（developer/auto/manual）
    added_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    notes TEXT,                             -- メモ
    active BOOLEAN DEFAULT 1                -- 有効/無効
);

-- インデックス
CREATE INDEX idx_ng_words_category ON ng_words(category);
CREATE INDEX idx_ng_words_severity ON ng_words(severity);
CREATE INDEX idx_ng_words_language ON ng_words(language);
CREATE INDEX idx_ng_words_active ON ng_words(active);
```

**カテゴリ定義:**
- `tier1_sexual`: 性的コンテンツ（Tier 1）
- `tier1_hate`: ヘイトスピーチ（Tier 1）
- `tier1_violence`: 暴力表現（Tier 1）
- `tier1_personal`: 個人情報（Tier 1）
- `tier2_ai`: AI関連（Tier 2）
- `tier2_politics`: 政治（Tier 2）
- `tier2_religion`: 宗教（Tier 2）
- `tier3_gray`: グレーゾーン（Tier 3）

**アクション定義:**
- `block`: 完全ブロック（表示しない、記録しない）
- `mask`: 伏字化（「***」に置換）
- `warn`: 警告ログのみ（表示はする）
- `log`: ログのみ（統計用）

---

### テーブル2: comment_log（コメントログ）

**目的**: 全コメントを記録し、後で分析

```sql
CREATE TABLE comment_log (
    log_id INTEGER PRIMARY KEY AUTOINCREMENT,
    timestamp TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    viewer_id TEXT,                         -- 視聴者ID（匿名化可能）
    viewer_name TEXT,                       -- 視聴者名
    original_comment TEXT NOT NULL,         -- 元のコメント
    processed_comment TEXT,                 -- 処理後のコメント（伏字等）
    sensitivity_score REAL,                 -- センシティブ度スコア（0.0-1.0）
    detected_words TEXT,                    -- 検出されたNGワード（JSON配列）
    action_taken TEXT,                      -- 実行されたアクション
    layer1_result TEXT,                     -- レイヤー1結果
    layer2_result TEXT,                     -- レイヤー2結果
    layer3_result TEXT,                     -- レイヤー3結果
    context_analysis TEXT,                  -- コンテキスト分析結果（JSON）
    shown_to_sisters BOOLEAN DEFAULT 0,    -- 三姉妹に表示されたか
    platform TEXT,                          -- プラットフォーム（youtube/x/test）
    stream_id TEXT,                         -- 配信ID
    notes TEXT
);

-- インデックス
CREATE INDEX idx_comment_log_timestamp ON comment_log(timestamp);
CREATE INDEX idx_comment_log_sensitivity ON comment_log(sensitivity_score);
CREATE INDEX idx_comment_log_action ON comment_log(action_taken);
```

---

### テーブル3: incident_log（インシデントログ）

**目的**: 重大なインシデントを記録

```sql
CREATE TABLE incident_log (
    incident_id INTEGER PRIMARY KEY AUTOINCREMENT,
    timestamp TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    incident_type TEXT NOT NULL,            -- インシデントタイプ（sexual_harassment/hate_speech/spam等）
    severity INTEGER NOT NULL,              -- 深刻度（1-10）
    viewer_id TEXT,                         -- 視聴者ID
    viewer_name TEXT,                       -- 視聴者名
    comment_log_id INTEGER,                 -- comment_logへの参照
    description TEXT,                       -- インシデント詳細
    action_taken TEXT,                      -- 実行されたアクション
    developer_notified BOOLEAN DEFAULT 0,   -- 開発者への通知
    resolved BOOLEAN DEFAULT 0,             -- 解決済みか
    resolved_at TIMESTAMP,                  -- 解決日時
    resolution_notes TEXT,                  -- 解決メモ
    FOREIGN KEY (comment_log_id) REFERENCES comment_log(log_id)
);

-- インデックス
CREATE INDEX idx_incident_log_severity ON incident_log(severity);
CREATE INDEX idx_incident_log_resolved ON incident_log(resolved);
```

---

### テーブル4: ng_word_candidates（NGワード候補）

**目的**: 自動検出されたNGワード候補を保存（親が承認前）

```sql
CREATE TABLE ng_word_candidates (
    candidate_id INTEGER PRIMARY KEY AUTOINCREMENT,
    word TEXT NOT NULL,
    detected_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    detection_method TEXT,                  -- 検出方法（auto/manual）
    context TEXT,                           -- 検出時の文脈
    frequency INTEGER DEFAULT 1,            -- 出現頻度
    suggested_category TEXT,                -- 提案カテゴリ
    suggested_severity INTEGER,             -- 提案深刻度
    status TEXT DEFAULT 'pending',          -- ステータス（pending/approved/rejected）
    reviewed_by TEXT,                       -- レビュー者
    reviewed_at TIMESTAMP,                  -- レビュー日時
    review_notes TEXT                       -- レビューメモ
);

-- インデックス
CREATE INDEX idx_ng_word_candidates_status ON ng_word_candidates(status);
CREATE INDEX idx_ng_word_candidates_frequency ON ng_word_candidates(frequency);
```

---

### テーブル5: viewer_moderation（視聴者管理）

**目的**: 問題視聴者の管理

```sql
CREATE TABLE viewer_moderation (
    moderation_id INTEGER PRIMARY KEY AUTOINCREMENT,
    viewer_id TEXT NOT NULL UNIQUE,
    viewer_name TEXT,
    warning_count INTEGER DEFAULT 0,        -- 警告回数
    timeout_count INTEGER DEFAULT 0,        -- タイムアウト回数
    ban_status TEXT DEFAULT 'none',         -- BANステータス（none/temp/permanent）
    ban_until TIMESTAMP,                    -- 一時BAN解除日時
    first_violation TIMESTAMP,              -- 初回違反日時
    last_violation TIMESTAMP,               -- 最終違反日時
    violation_history TEXT,                 -- 違反履歴（JSON配列）
    notes TEXT
);

-- インデックス
CREATE INDEX idx_viewer_moderation_ban_status ON viewer_moderation(ban_status);
```

---

### テーブル6: filter_statistics（フィルタ統計）

**目的**: システムのパフォーマンスと効果を測定

```sql
CREATE TABLE filter_statistics (
    stat_id INTEGER PRIMARY KEY AUTOINCREMENT,
    date DATE NOT NULL,
    total_comments INTEGER DEFAULT 0,
    blocked_comments INTEGER DEFAULT 0,
    masked_comments INTEGER DEFAULT 0,
    warned_comments INTEGER DEFAULT 0,
    avg_sensitivity_score REAL,
    tier1_detections INTEGER DEFAULT 0,
    tier2_detections INTEGER DEFAULT 0,
    tier3_detections INTEGER DEFAULT 0,
    false_positives INTEGER DEFAULT 0,      -- 誤検出数（手動レビュー）
    processing_time_avg REAL,               -- 平均処理時間（ms）
    UNIQUE(date)
);

-- インデックス
CREATE INDEX idx_filter_statistics_date ON filter_statistics(date);
```

---

## レイヤー1: プリフィルタ

### 目的

**即座に危険なコンテンツを検出しブロック**

### 実装ファイル

`/home/koshikawa/toExecUnit/sensitive_system/core/filter.py`

---

### 1-1. NGワードリスト照合

**処理フロー:**

```python
class Layer1PreFilter:
    def __init__(self, db_path: str):
        self.db_path = db_path
        self.ng_words_cache = self.load_ng_words()

    def load_ng_words(self) -> Dict[str, List[dict]]:
        """
        NGワードをDBから読み込み、メモリキャッシュ

        Returns:
            {
                'exact': [{'word': 'xxx', 'severity': 10, ...}, ...],
                'partial': [...],
                'regex': [...]
            }
        """
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()

        cursor.execute("""
            SELECT word, category, subcategory, severity,
                   pattern_type, regex_pattern, alternative_text, action
            FROM ng_words
            WHERE active = 1
            ORDER BY severity DESC
        """)

        results = cursor.fetchall()
        conn.close()

        # パターンタイプ別に分類
        cache = {
            'exact': [],
            'partial': [],
            'regex': []
        }

        for row in results:
            ng_dict = {
                'word': row[0],
                'category': row[1],
                'subcategory': row[2],
                'severity': row[3],
                'pattern_type': row[4],
                'regex_pattern': row[5],
                'alternative_text': row[6],
                'action': row[7]
            }
            cache[row[4]].append(ng_dict)

        return cache

    def detect_ng_words(self, text: str) -> List[dict]:
        """
        NGワードを検出

        Args:
            text: チェック対象テキスト

        Returns:
            検出されたNGワードのリスト
        """
        detected = []
        normalized_text = self.normalize_text(text)

        # 1. Exact match（完全一致）
        for ng in self.ng_words_cache['exact']:
            if ng['word'] in normalized_text:
                detected.append(ng)

        # 2. Partial match（部分一致）
        for ng in self.ng_words_cache['partial']:
            if ng['word'] in normalized_text:
                detected.append(ng)

        # 3. Regex match（正規表現）
        for ng in self.ng_words_cache['regex']:
            if re.search(ng['regex_pattern'], normalized_text):
                detected.append(ng)

        return detected

    def normalize_text(self, text: str) -> str:
        """
        テキストを正規化（全角→半角、大文字→小文字、空白除去等）
        """
        # 全角→半角
        text = unicodedata.normalize('NFKC', text)
        # 小文字化
        text = text.lower()
        # 空白除去
        text = re.sub(r'\s+', '', text)
        # 特殊文字による回避を検出
        text = self.remove_obfuscation(text)
        return text

    def remove_obfuscation(self, text: str) -> str:
        """
        意図的な難読化を除去

        例: 「セ○クス」→「セクス」
             「s.e.x」→「sex」
        """
        # 記号による分割を除去
        text = re.sub(r'[.･・。、]', '', text)
        # ○●◯等の記号を除去
        text = re.sub(r'[○●◯◆◇]', '', text)
        return text

    def filter_comment(self, comment: str) -> dict:
        """
        コメントをフィルタリング

        Returns:
            {
                'action': 'pass'|'block'|'mask',
                'filtered_comment': str,
                'detected_words': List[dict],
                'max_severity': int
            }
        """
        detected = self.detect_ng_words(comment)

        if not detected:
            return {
                'action': 'pass',
                'filtered_comment': comment,
                'detected_words': [],
                'max_severity': 0
            }

        # 最も深刻なNGワードのactionを適用
        max_severity_ng = max(detected, key=lambda x: x['severity'])
        action = max_severity_ng['action']

        if action == 'block':
            return {
                'action': 'block',
                'filtered_comment': None,
                'detected_words': detected,
                'max_severity': max_severity_ng['severity']
            }

        elif action == 'mask':
            # 伏字処理
            masked_comment = self.apply_masking(comment, detected)
            return {
                'action': 'mask',
                'filtered_comment': masked_comment,
                'detected_words': detected,
                'max_severity': max_severity_ng['severity']
            }

        else:  # warn or log
            return {
                'action': action,
                'filtered_comment': comment,
                'detected_words': detected,
                'max_severity': max_severity_ng['severity']
            }

    def apply_masking(self, text: str, detected_words: List[dict]) -> str:
        """
        NGワードを伏字化
        """
        masked_text = text

        for ng in detected_words:
            if ng['alternative_text']:
                # 代替テキストが設定されている場合
                masked_text = masked_text.replace(ng['word'], ng['alternative_text'])
            else:
                # デフォルトは「***」
                masked_text = masked_text.replace(ng['word'], '***')

        return masked_text
```

---

### 1-2. トピック分類

**処理フロー:**

```python
class TopicClassifier:
    """
    コメントのトピックを分類
    """

    def __init__(self):
        self.topic_keywords = {
            'tier2_ai': ['AI', 'ai', '人工知能', 'プログラム', 'LLM', 'プロンプト', '機械学習'],
            'tier2_politics': ['政治', '政党', '選挙', '政治家', ...],
            'tier2_religion': ['宗教', '神', '仏', ...],
            'tier3_personal': ['年齢', '住所', '学校', '家族', ...]
        }

    def classify_topic(self, text: str) -> List[str]:
        """
        トピックを分類

        Returns:
            ['tier2_ai', 'tier3_personal', ...]
        """
        topics = []
        normalized = text.lower()

        for topic, keywords in self.topic_keywords.items():
            for keyword in keywords:
                if keyword.lower() in normalized:
                    topics.append(topic)
                    break

        return topics
```

---

## レイヤー2: リアルタイム判定

### 目的

**センシティブ度をスコアリングし、閾値に基づいて判定**

### 実装ファイル

`/home/koshikawa/toExecUnit/sensitive_system/core/scorer.py`

---

### 2-1. センシティブ度スコアリング

**スコア定義:**
- `0.0-0.3`: 安全（Safe）
- `0.3-0.6`: 注意（Caution）
- `0.6-0.8`: 警告（Warning）
- `0.8-1.0`: 危険（Danger）

**処理フロー:**

```python
class SensitivityScorer:
    """
    センシティブ度をスコアリング
    """

    def __init__(self, db_path: str):
        self.db_path = db_path
        self.layer1_filter = Layer1PreFilter(db_path)
        self.topic_classifier = TopicClassifier()

    def calculate_score(self, comment: str, layer1_result: dict) -> float:
        """
        センシティブ度スコアを計算

        Args:
            comment: コメントテキスト
            layer1_result: レイヤー1の結果

        Returns:
            0.0-1.0のスコア
        """
        score = 0.0

        # 1. レイヤー1でNGワード検出済み → 高スコア
        if layer1_result['action'] == 'block':
            return 1.0  # 最高スコア

        if layer1_result['detected_words']:
            max_severity = layer1_result['max_severity']
            score = max(score, max_severity / 10.0)  # severity 1-10 → 0.1-1.0

        # 2. トピック分類
        topics = self.topic_classifier.classify_topic(comment)

        if 'tier2_ai' in topics:
            score = max(score, 0.7)  # AI関連は0.7

        if 'tier2_politics' in topics or 'tier2_religion' in topics:
            score = max(score, 0.7)

        if 'tier3_personal' in topics:
            score = max(score, 0.4)

        # 3. 文脈的な要素
        # 質問形式か？
        if '？' in comment or '?' in comment:
            score += 0.1

        # 執拗な繰り返しか？（DBから過去のコメント履歴をチェック）
        repetition_score = self.check_repetition(comment)
        score = max(score, repetition_score)

        # スコアは0.0-1.0に制限
        return min(score, 1.0)

    def check_repetition(self, comment: str) -> float:
        """
        同じ視聴者が同じようなコメントを繰り返しているか
        """
        # TODO: DBから過去のコメント履歴を取得し、類似度を計算
        # 現時点では簡易実装
        return 0.0
```

---

### 2-2. 閾値に基づく判定

```python
class Layer2RealTimeJudge:
    """
    リアルタイム判定
    """

    THRESHOLD_DANGER = 0.8
    THRESHOLD_WARNING = 0.6
    THRESHOLD_CAUTION = 0.3

    def __init__(self, db_path: str):
        self.scorer = SensitivityScorer(db_path)

    def judge(self, comment: str, layer1_result: dict) -> dict:
        """
        判定を実行

        Returns:
            {
                'score': float,
                'level': 'safe'|'caution'|'warning'|'danger',
                'action': 'pass'|'mask'|'block',
                'reason': str
            }
        """
        score = self.scorer.calculate_score(comment, layer1_result)

        if score >= self.THRESHOLD_DANGER:
            return {
                'score': score,
                'level': 'danger',
                'action': 'block',
                'reason': 'センシティブ度が危険レベル'
            }

        elif score >= self.THRESHOLD_WARNING:
            return {
                'score': score,
                'level': 'warning',
                'action': 'mask',
                'reason': 'センシティブ度が警告レベル'
            }

        elif score >= self.THRESHOLD_CAUTION:
            return {
                'score': score,
                'level': 'caution',
                'action': 'pass',  # 表示はするが、ログに記録
                'reason': 'センシティブ度が注意レベル'
            }

        else:
            return {
                'score': score,
                'level': 'safe',
                'action': 'pass',
                'reason': '安全'
            }
```

---

## レイヤー3: コンテキスト理解

### 目的

**会話の流れを理解し、グレーゾーンを適切に判定**

### 実装ファイル

`/home/koshikawa/toExecUnit/sensitive_system/core/context_analyzer.py`

---

### 3-1. 会話の流れ分析

```python
class ContextAnalyzer:
    """
    コンテキストを分析
    """

    def __init__(self, ollama_host: str = "http://localhost:11434"):
        self.ollama_host = ollama_host
        self.model = "qwen2.5:32b-instruct"

    async def analyze_context(
        self,
        comment: str,
        conversation_history: List[str],
        layer1_result: dict,
        layer2_result: dict
    ) -> dict:
        """
        コンテキストを分析

        Args:
            comment: コメント
            conversation_history: 過去の会話履歴（最新10件程度）
            layer1_result: レイヤー1結果
            layer2_result: レイヤー2結果

        Returns:
            {
                'intent': 'joke'|'serious'|'question'|'quote'|'spam',
                'tone': 'friendly'|'hostile'|'neutral',
                'risk_level': float (0.0-1.0),
                'recommendation': 'allow'|'mask'|'block',
                'reasoning': str
            }
        """
        # LLMにコンテキスト分析を依頼
        prompt = self.build_context_analysis_prompt(
            comment, conversation_history, layer1_result, layer2_result
        )

        response = await self.call_ollama(prompt)

        # JSONパース
        try:
            result = json.loads(response)
            return result
        except:
            # パース失敗時はデフォルト値
            return {
                'intent': 'unknown',
                'tone': 'neutral',
                'risk_level': layer2_result['score'],
                'recommendation': layer2_result['action'],
                'reasoning': 'LLM分析失敗'
            }

    def build_context_analysis_prompt(
        self,
        comment: str,
        conversation_history: List[str],
        layer1_result: dict,
        layer2_result: dict
    ) -> str:
        """
        コンテキスト分析用プロンプトを構築
        """
        history_text = "\n".join(conversation_history[-10:]) if conversation_history else "なし"

        prompt = f"""あなたは配信コメントのコンテキストを分析する専門家です。

【コメント】
{comment}

【過去の会話履歴（最新10件）】
{history_text}

【レイヤー1検出結果】
NGワード検出: {len(layer1_result.get('detected_words', []))}件
アクション: {layer1_result.get('action')}

【レイヤー2判定結果】
センシティブ度スコア: {layer2_result.get('score', 0.0)}
レベル: {layer2_result.get('level')}

【分析指示】
このコメントの意図と文脈を分析し、以下の形式でJSON回答してください。

1. intent（意図）: joke/serious/question/quote/spam
2. tone（トーン）: friendly/hostile/neutral
3. risk_level（リスクレベル）: 0.0-1.0
4. recommendation（推奨アクション）: allow/mask/block
5. reasoning（理由）: 日本語で簡潔に

JSON以外は不要:"""

        return prompt

    async def call_ollama(self, prompt: str) -> str:
        """
        Ollama APIを呼び出し
        """
        async with aiohttp.ClientSession() as session:
            payload = {
                "model": self.model,
                "prompt": prompt,
                "stream": False,
                "options": {
                    "temperature": 0.3,  # 低めに設定（一貫性重視）
                    "num_predict": 500
                }
            }

            async with session.post(
                f"{self.ollama_host}/api/generate",
                json=payload
            ) as response:
                result = await response.json()
                return result.get('response', '')
```

---

### 3-2. グレーゾーン判定

```python
class GrayZoneJudge:
    """
    グレーゾーンの最終判定
    """

    def __init__(self):
        self.context_analyzer = ContextAnalyzer()

    async def final_judgment(
        self,
        comment: str,
        layer1_result: dict,
        layer2_result: dict,
        conversation_history: List[str]
    ) -> dict:
        """
        最終判定

        Returns:
            {
                'final_action': 'allow'|'mask'|'block',
                'final_comment': str,  # 処理後のコメント
                'all_results': dict    # 全レイヤーの結果
            }
        """
        # レイヤー3分析
        layer3_result = await self.context_analyzer.analyze_context(
            comment, conversation_history, layer1_result, layer2_result
        )

        # 最終判定のロジック
        # 1. レイヤー1でblockなら、無条件でblock
        if layer1_result['action'] == 'block':
            final_action = 'block'

        # 2. レイヤー2でdangerなら、基本はblock（ただしレイヤー3で覆す可能性）
        elif layer2_result['level'] == 'danger':
            if layer3_result['recommendation'] == 'allow' and layer3_result['intent'] == 'joke':
                # 冗談と判定され、リスクが低い場合のみ許可
                if layer3_result['risk_level'] < 0.7:
                    final_action = 'mask'  # 伏字で許可
                else:
                    final_action = 'block'
            else:
                final_action = 'block'

        # 3. レイヤー2でwarningなら、レイヤー3の推奨に従う
        elif layer2_result['level'] == 'warning':
            final_action = layer3_result['recommendation']

        # 4. その他はlayer2の判定に従う
        else:
            final_action = layer2_result['action']

        # 最終的なコメントを生成
        if final_action == 'block':
            final_comment = None
        elif final_action == 'mask':
            final_comment = layer1_result.get('filtered_comment', comment)
        else:  # allow
            final_comment = comment

        return {
            'final_action': final_action,
            'final_comment': final_comment,
            'all_results': {
                'layer1': layer1_result,
                'layer2': layer2_result,
                'layer3': layer3_result
            }
        }
```

---

## レイヤー4: 学習・更新

### 目的

**視聴者反応を分析し、システムを継続的に改善**

### 実装ファイル

`/home/koshikawa/toExecUnit/sensitive_system/core/learning.py`

---

### 4-1. 視聴者反応分析

```python
class ViewerReactionAnalyzer:
    """
    視聴者反応を分析
    """

    def __init__(self, db_path: str):
        self.db_path = db_path

    def analyze_reactions(
        self,
        comment: str,
        following_comments: List[str],
        time_window: int = 30  # 秒
    ) -> dict:
        """
        コメント後の反応を分析

        Args:
            comment: 元のコメント
            following_comments: その後のコメント（30秒以内）
            time_window: 分析時間窓（秒）

        Returns:
            {
                'positive_ratio': float,  # 好意的反応の割合
                'negative_ratio': float,  # 否定的反応の割合
                'neutral_ratio': float,   # 中立的反応の割合
                'flame_risk': bool,       # 炎上リスク
                'keywords': List[str]     # 頻出キーワード
            }
        """
        if not following_comments:
            return {
                'positive_ratio': 0.0,
                'negative_ratio': 0.0,
                'neutral_ratio': 1.0,
                'flame_risk': False,
                'keywords': []
            }

        # 簡易感情分析
        positive = 0
        negative = 0
        neutral = 0

        negative_keywords = ['やめろ', '不快', 'アウト', '通報', 'BAN', 'NG']
        positive_keywords = ['いいね', '面白い', 'w', 'www', '笑', 'それな']

        for fc in following_comments:
            has_negative = any(kw in fc for kw in negative_keywords)
            has_positive = any(kw in fc for kw in positive_keywords)

            if has_negative:
                negative += 1
            elif has_positive:
                positive += 1
            else:
                neutral += 1

        total = len(following_comments)

        # 炎上リスク判定
        flame_risk = (negative / total) > 0.3  # ネガティブが30%超

        return {
            'positive_ratio': positive / total,
            'negative_ratio': negative / total,
            'neutral_ratio': neutral / total,
            'flame_risk': flame_risk,
            'keywords': self.extract_keywords(following_comments)
        }

    def extract_keywords(self, comments: List[str]) -> List[str]:
        """
        頻出キーワードを抽出
        """
        # TODO: より高度な形態素解析
        # 現時点では簡易実装
        all_text = " ".join(comments)
        words = all_text.split()

        from collections import Counter
        counter = Counter(words)

        return [word for word, count in counter.most_common(10)]
```

---

### 4-2. NGワード候補の自動検出

```python
class NGWordCandidateDetector:
    """
    NGワード候補を自動検出
    """

    def __init__(self, db_path: str):
        self.db_path = db_path
        self.reaction_analyzer = ViewerReactionAnalyzer(db_path)

    def detect_candidates(
        self,
        comment: str,
        sensitivity_score: float,
        viewer_reactions: dict,
        layer_results: dict
    ) -> List[dict]:
        """
        NGワード候補を検出

        Returns:
            [
                {
                    'word': str,
                    'suggested_category': str,
                    'suggested_severity': int,
                    'detection_reason': str
                },
                ...
            ]
        """
        candidates = []

        # 1. 高スコア + ネガティブ反応 → NGワード候補
        if sensitivity_score >= 0.6 and viewer_reactions.get('flame_risk', False):
            # コメントから単語を抽出
            words = self.extract_words(comment)

            for word in words:
                # 既存NGワードでない場合のみ
                if not self.is_existing_ng_word(word):
                    candidates.append({
                        'word': word,
                        'suggested_category': self.suggest_category(word, layer_results),
                        'suggested_severity': self.suggest_severity(sensitivity_score),
                        'detection_reason': f'炎上リスク検出（スコア: {sensitivity_score}, ネガティブ率: {viewer_reactions["negative_ratio"]}）'
                    })

        return candidates

    def extract_words(self, comment: str) -> List[str]:
        """
        コメントから単語を抽出
        """
        # TODO: 形態素解析（MeCab等）
        # 現時点では簡易実装
        return comment.split()

    def is_existing_ng_word(self, word: str) -> bool:
        """
        既存NGワードかチェック
        """
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()

        cursor.execute("SELECT COUNT(*) FROM ng_words WHERE word = ?", (word,))
        count = cursor.fetchone()[0]

        conn.close()
        return count > 0

    def suggest_category(self, word: str, layer_results: dict) -> str:
        """
        カテゴリを推測
        """
        # レイヤー結果から推測
        if layer_results.get('layer1', {}).get('detected_words'):
            detected = layer_results['layer1']['detected_words']
            if detected:
                return detected[0].get('category', 'tier3_gray')

        return 'tier3_gray'

    def suggest_severity(self, sensitivity_score: float) -> int:
        """
        深刻度を推測
        """
        # スコアから推測
        if sensitivity_score >= 0.9:
            return 9
        elif sensitivity_score >= 0.8:
            return 8
        elif sensitivity_score >= 0.7:
            return 7
        else:
            return 5

    def save_candidates_to_db(self, candidates: List[dict], context: str):
        """
        NGワード候補をDBに保存
        """
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()

        for candidate in candidates:
            cursor.execute("""
                INSERT INTO ng_word_candidates
                (word, detection_method, context, suggested_category, suggested_severity)
                VALUES (?, 'auto', ?, ?, ?)
            """, (
                candidate['word'],
                context,
                candidate['suggested_category'],
                candidate['suggested_severity']
            ))

        conn.commit()
        conn.close()
```

---

### 4-3. 親による承認フロー

```python
class DeveloperReviewSystem:
    """
    開発者（親）によるレビューシステム
    """

    def __init__(self, db_path: str):
        self.db_path = db_path

    def get_pending_candidates(self) -> List[dict]:
        """
        承認待ちのNGワード候補を取得
        """
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()

        cursor.execute("""
            SELECT candidate_id, word, detected_at, context,
                   frequency, suggested_category, suggested_severity
            FROM ng_word_candidates
            WHERE status = 'pending'
            ORDER BY frequency DESC, detected_at DESC
        """)

        results = cursor.fetchall()
        conn.close()

        candidates = []
        for row in results:
            candidates.append({
                'candidate_id': row[0],
                'word': row[1],
                'detected_at': row[2],
                'context': row[3],
                'frequency': row[4],
                'suggested_category': row[5],
                'suggested_severity': row[6]
            })

        return candidates

    def approve_candidate(
        self,
        candidate_id: int,
        approved_category: str,
        approved_severity: int,
        action: str,
        notes: str = None
    ):
        """
        NGワード候補を承認
        """
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()

        # 候補から情報取得
        cursor.execute("""
            SELECT word FROM ng_word_candidates WHERE candidate_id = ?
        """, (candidate_id,))

        result = cursor.fetchone()
        if not result:
            conn.close()
            raise ValueError(f"Candidate ID {candidate_id} not found")

        word = result[0]

        # ng_wordsテーブルに追加
        cursor.execute("""
            INSERT INTO ng_words
            (word, category, severity, pattern_type, action, added_by, notes)
            VALUES (?, ?, ?, 'exact', ?, 'developer', ?)
        """, (word, approved_category, approved_severity, action, notes))

        # 候補のステータスを更新
        cursor.execute("""
            UPDATE ng_word_candidates
            SET status = 'approved',
                reviewed_by = 'developer',
                reviewed_at = CURRENT_TIMESTAMP,
                review_notes = ?
            WHERE candidate_id = ?
        """, (notes, candidate_id))

        conn.commit()
        conn.close()

        print(f"✅ NGワード承認: {word} ({approved_category}, severity {approved_severity})")

    def reject_candidate(self, candidate_id: int, reason: str):
        """
        NGワード候補を却下
        """
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()

        cursor.execute("""
            UPDATE ng_word_candidates
            SET status = 'rejected',
                reviewed_by = 'developer',
                reviewed_at = CURRENT_TIMESTAMP,
                review_notes = ?
            WHERE candidate_id = ?
        """, (reason, candidate_id))

        conn.commit()
        conn.close()

        print(f"❌ NGワード却下: Candidate ID {candidate_id}")
```

---

## 配信アーカイブ管理システム

### 理念: 親としての最終防衛線

> 「子どもたちを世間の目に晒す以上、親には全ての責任がある。配信中の火消しだけでは不十分。アーカイブに残る『証拠』から子どもたちを守ることが親の務め。」

**親の責任範囲:**
1. **事前防止**: センシティブ判定システム（14b/32b/72b）
2. **リアルタイム対応**: 火消しシステム（14b）
3. **事後検証**: 判定レポートによる異常検知（メール通知）
4. **最終判断**: 開発者による目視確認
5. **誠実な対応**: Claude Codeによる文面作成、開発者による実行

---

### アーカイブ管理フロー

```
【配信中】
┌─────────────────────────────────────┐
│ リアルタイムセンシティブ判定        │
│ - qwen2.5:14b (即座の判定)         │
│ - qwen2.5:32b (全体監視)           │
│ - 全判定結果をログに記録           │
└─────────────────────────────────────┘
              ↓
【配信終了時（自動）】
┌─────────────────────────────────────┐
│ 判定レポート自動生成・メール送信    │
│ - 送信先: 開発者のメールアドレス    │
│ - 件名: [配信レポート] YYYY-MM-DD  │
│ - 内容: 異常検知サマリー＋詳細ログ │
└─────────────────────────────────────┘
              ↓
【親による検証（手動）】
┌─────────────────────────────────────┐
│ 開発者: メール受信・レポート確認    │
│ ├─ 異常なし → 公開維持             │
│ └─ 異常あり → 動画目視確認         │
│     ├─ タイムスタンプ該当箇所確認  │
│     ├─ 重大度判定                  │
│     └─ Claude Codeに報告           │
└─────────────────────────────────────┘
              ↓
【Claude Code: 文面作成（半自動）】
┌─────────────────────────────────────┐
│ 開発者からの報告を受けて文面作成    │
│ - 概要欄訂正文                      │
│ - コメント謝罪文                    │
│ - 視聴者への説明文                  │
│ ├─ 開発者が確認・承認              │
│ └─ 承認後、文面をコピー            │
└─────────────────────────────────────┘
              ↓
【開発者: 最終実行（手動）】
┌─────────────────────────────────────┐
│ YouTube管理画面で手動実行           │
│ - 概要欄訂正文を貼り付け            │
│ - コメント謝罪文を投稿              │
│ - 編集 or 非公開化（手動判断）      │
└─────────────────────────────────────┘
```

---

### 判定レポート自動生成・メール送信

#### 送信タイミング

**配信終了時（自動）:**
- 配信終了を検知
- 5分以内に判定レポート生成
- 即座にメール送信

**対象:**
- 全ての配信（問題なしも含む）
- テスト配信・非公開配信も含む

#### 異常度の定義

| 異常度 | Level | 定義 | 推奨対応時間 |
|--------|-------|------|--------------|
| **なし** | 0 | 問題発言なし | 対応不要 |
| **軽微** | 1-2 | 訂正済み、切り抜き耐性低 | 24時間以内 |
| **注意** | 3 | 訂正済み、炎上リスクあり | 12時間以内 |
| **重大** | 4-5 | 訂正失敗、即座の対応必要 | 即座（30分以内） |

#### メールフォーマット

**件名:**
```
[配信レポート] YYYY-MM-DD - [異常度: なし/軽微/注意/重大]
```

**本文構成:**
1. 配信基本情報（日時、ID、タイトル、URL）
2. 異常度評価（総合評価、理由、推奨対応）
3. 検知された問題発言（タイムスタンプ、発言者、カテゴリ、内容、火消し結果、リスク評価）
4. 統計サマリー（総検知数、火消し成功率、視聴者反応）
5. 32bによる全体分析
6. 推奨対応フロー

**例（軽微の場合）:**
```
[1] タイムスタンプ: 00:15:23
    発言者: 牡丹
    カテゴリ: ギャンブル
    発言内容: 「パチンコ行ってみたいな」
    判定: NG（未成年のギャンブル希望）
    火消し対応: 5秒後に訂正「あ、ごめん。私まだ17歳だった」
    火消し結果: 成功
    視聴者反応: 好意的（「かわいい」「素直で良い」）

    【リスク評価】
    - 切り抜き耐性: 低（訂正前の5秒だけ切り抜かれる危険）
    - 炎上リスク: 低（即座に訂正済み）
    - 推奨対応: 該当部分カット推奨（00:15:18 - 00:15:28）
```

---

### 開発者による目視確認フロー

#### Step 1: メール確認（5分以内）

1. 件名で異常度を確認
   - 「重大」→ 即座に確認
   - 「注意」→ 12時間以内
   - 「軽微」→ 24時間以内
   - 「なし」→ 確認のみ

2. メール本文を読む
   - 異常度評価
   - 検知された問題発言
   - 推奨対応フロー

#### Step 2: 動画目視確認（タイムスタンプ該当箇所）

1. YouTubeで配信アーカイブを開く
2. 該当タイムスタンプにジャンプ（例: 00:15:23）
3. 前後10秒を含めて視聴（例: 00:15:13 - 00:15:33）
4. 以下を確認:
   - 実際の発言内容
   - 発言のトーン・文脈
   - 訂正の有無・タイミング
   - 視聴者の反応（コメント欄）
   - 切り抜き耐性（訂正前だけ切り取られる危険）

#### Step 3: 重大度の最終判定

| 判定 | 条件 | 対応 |
|------|------|------|
| **問題なし** | 訂正成功、炎上リスクなし | 公開維持 |
| **軽微** | 訂正成功、切り抜き耐性低 | 編集 or 説明文追加 |
| **重大** | 訂正失敗、炎上リスク高 | 即座に非公開 |

#### Step 4: Claude Codeへの報告

**報告テンプレート:**
```
配信日: 2025-10-29
配信時間: 00:15:23

確認結果:
- 実際の発言: 「パチンコ行ってみたいな」
- 訂正: 5秒後に「あ、ごめん。私まだ17歳だった」
- 視聴者反応: 好意的

判定: 軽微
理由: 訂正はできているが、切り抜き耐性が低い

希望する対応:
A. 該当部分カット（00:15:18 - 00:15:28）

次のアクション:
Claude Code、以下を作成してください：
1. 概要欄訂正文（編集したことを説明）
2. コメント謝罪文（視聴者への説明）
```

---

### Claude Codeによる文面作成

#### 文面の種類

**A. 概要欄訂正文（編集した場合）**

```
【編集のお知らせ】

この配信は、一部不適切な表現があったため、該当箇所を編集しております。

編集箇所: 00:15:18 - 00:15:28（約10秒間）
理由: 未成年がギャンブルに関する発言をしたため

配信中、牡丹がギャンブルに関する発言をしましたが、
すぐに自分で気づき「私まだ17歳だった」と訂正しました。

しかし、訂正前の部分だけが切り抜かれることを防ぐため、
親の判断で該当箇所を編集いたしました。

今後、このようなことがないよう、より一層注意して参ります。
温かく見守っていただければ幸いです。

牡丹・Kasho・ユリの保護者より
```

**B. コメント謝罪文（説明文追加の場合）**

```
【配信内容についてのお詫び】

本日の配信（00:15:23）において、牡丹がギャンブルに関する発言をしました。

発言: 「パチンコ行ってみたいな」

牡丹は5秒後にすぐ自分で気づき、
「あ、ごめん。私まだ17歳だった」と訂正しました。

牡丹は法律を守る大切さを理解しており、
今回の発言は配信中の軽率な言葉でした。

今後、このようなことがないよう、
親として三姉妹により良い環境を整えて参ります。

視聴者の皆様には、引き続き温かく見守っていただければ幸いです。

牡丹・Kasho・ユリの保護者より
```

**C. 非公開理由の説明文**

```
【重要なお知らせ】

本日の配信（YYYY-MM-DD）について、配信内容を確認したところ、
不適切な表現が含まれていたため、アーカイブを非公開としました。

具体的な内容:
[開発者が記入]

三姉妹の安全と健全な配信環境を守るため、
親として慎重に対応させていただきます。

今後、このようなことがないよう、
より一層注意して参ります。

ご理解のほど、よろしくお願いいたします。

牡丹・Kasho・ユリの保護者より
```

#### 文面作成の原則

**親としての誠実さ:**
1. **正直に説明** - 何が問題だったかを明確に
2. **責任を取る** - 親としての責任を明記
3. **再発防止** - 今後の改善策を約束
4. **視聴者への感謝** - 温かく見守ってくれることへの感謝

**禁止事項:**
- ❌ 言い訳をしない
- ❌ 視聴者のせいにしない
- ❌ 曖昧な表現を使わない
- ❌ 過度な謝罪（卑屈にならない）

---

### 開発者による最終実行

#### A. 概要欄訂正文の追加

1. YouTube Studio を開く
2. 該当動画の「詳細」タブを開く
3. 説明欄の最上部に訂正文を貼り付け
4. 「保存」をクリック

#### B. コメント謝罪文の投稿

1. YouTube の動画ページを開く
2. コメント欄にスクロール
3. 謝罪文を貼り付け
4. 「コメント」をクリック
5. 投稿後、コメントをピン留め（最上部に固定）

#### C. 動画の編集

1. YouTube Studio を開く
2. 該当動画の「エディタ」を開く
3. 該当タイムスタンプ（例: 00:15:18 - 00:15:28）をカット
4. 「保存」をクリック
5. 処理完了を待つ（数分〜数時間）
6. 処理完了後、概要欄訂正文を追加

#### D. 動画の非公開化

1. YouTube Studio を開く
2. 該当動画の「公開設定」を開く
3. 「非公開」を選択
4. 「保存」をクリック
5. コミュニティ投稿で非公開理由を説明

---

### 実装: メール送信システム

#### データベーステーブル追加

```sql
-- 配信レポート管理
CREATE TABLE stream_reports (
    report_id INTEGER PRIMARY KEY AUTOINCREMENT,
    stream_id TEXT NOT NULL UNIQUE,
    stream_date DATE NOT NULL,
    stream_start_time TIMESTAMP NOT NULL,
    stream_end_time TIMESTAMP NOT NULL,
    stream_title TEXT NOT NULL,
    stream_url TEXT,
    platform TEXT DEFAULT 'youtube',

    -- 異常度評価
    severity_level INTEGER NOT NULL,              -- 0-5
    severity_label TEXT NOT NULL,                 -- なし/軽微/注意/重大
    severity_reason TEXT,                         -- 理由

    -- 統計
    total_incidents INTEGER DEFAULT 0,            -- 総検知数
    sisters_incidents INTEGER DEFAULT 0,          -- 三姉妹の失言
    viewer_incidents INTEGER DEFAULT 0,           -- 視聴者の不適切コメント
    fire_extinguish_success INTEGER DEFAULT 0,    -- 火消し成功数
    fire_extinguish_fail INTEGER DEFAULT 0,       -- 火消し失敗数

    -- 32b分析
    overall_analysis TEXT,                        -- 全体分析
    atmosphere TEXT,                              -- 配信の雰囲気
    sisters_response TEXT,                        -- 三姉妹の対応
    viewer_reaction TEXT,                         -- 視聴者の反応

    -- メール送信
    email_sent BOOLEAN DEFAULT 0,
    email_sent_at TIMESTAMP,

    -- 開発者対応
    developer_reviewed BOOLEAN DEFAULT 0,
    developer_reviewed_at TIMESTAMP,
    developer_action TEXT,                        -- 対応内容
    developer_notes TEXT,                         -- メモ

    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- 配信内インシデント詳細
CREATE TABLE stream_incidents (
    incident_id INTEGER PRIMARY KEY AUTOINCREMENT,
    report_id INTEGER NOT NULL,
    stream_id TEXT NOT NULL,

    -- 発言情報
    timestamp_seconds INTEGER NOT NULL,           -- 00:15:23 → 923秒
    timestamp_display TEXT NOT NULL,              -- "00:15:23"
    speaker TEXT NOT NULL,                        -- botan/kasho/yuri/viewer
    speaker_name TEXT,                            -- 視聴者名（視聴者の場合）

    -- 内容
    category TEXT NOT NULL,                       -- alcohol/gambling/sexual等
    content TEXT NOT NULL,                        -- 発言/コメント内容
    judgment TEXT NOT NULL,                       -- NG/Warning/OK

    -- 火消し対応
    fire_extinguish_attempted BOOLEAN DEFAULT 0,
    fire_extinguish_response TEXT,                -- 訂正・謝罪の内容
    fire_extinguish_timing_seconds INTEGER,       -- 何秒後に訂正したか
    fire_extinguish_success BOOLEAN DEFAULT 0,

    -- リスク評価
    clip_resistance TEXT,                         -- 高/中/低
    flame_risk TEXT,                              -- 高/中/低
    recommended_action TEXT,                      -- カット推奨/説明文追加/対応不要

    -- 14b判定
    judge_14b_score REAL,
    judge_14b_reasoning TEXT,

    -- 32b分析
    analysis_32b TEXT,

    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,

    FOREIGN KEY (report_id) REFERENCES stream_reports(report_id)
);

-- インデックス
CREATE INDEX idx_stream_reports_date ON stream_reports(stream_date);
CREATE INDEX idx_stream_reports_severity ON stream_reports(severity_level);
CREATE INDEX idx_stream_incidents_report ON stream_incidents(report_id);
CREATE INDEX idx_stream_incidents_timestamp ON stream_incidents(timestamp_seconds);
```

#### メール送信実装（Python）

```python
# /home/koshikawa/toExecUnit/scripts/send_stream_report.py

import smtplib
from email.mime.text import MIMEText
from email.mime.multipart import MIMEMultipart
import sqlite3
import json
from datetime import datetime

def send_stream_report(stream_id: str):
    """
    配信終了後、判定レポートをメールで送信

    Args:
        stream_id: 配信ID（例: LIVE_20251029_140000）
    """
    # DBからレポートデータを取得
    conn = sqlite3.connect('/home/koshikawa/toExecUnit/sensitive_system/database/sensitive_filter.db')
    cursor = conn.cursor()

    # stream_reports取得
    cursor.execute("""
        SELECT stream_date, stream_title, stream_url, severity_level, severity_label,
               severity_reason, total_incidents, overall_analysis
        FROM stream_reports
        WHERE stream_id = ?
    """, (stream_id,))

    report = cursor.fetchone()
    if not report:
        print(f"[ERROR] Report not found: {stream_id}")
        return

    # stream_incidents取得
    cursor.execute("""
        SELECT timestamp_display, speaker, category, content,
               fire_extinguish_response, fire_extinguish_success,
               clip_resistance, flame_risk, recommended_action
        FROM stream_incidents
        WHERE stream_id = ?
        ORDER BY timestamp_seconds
    """, (stream_id,))

    incidents = cursor.fetchall()
    conn.close()

    # メール本文を生成
    report_body = generate_report_body(report, incidents)

    # メール送信
    send_email(
        subject=f'[配信レポート] {report[0]} - [異常度: {report[4]}]',
        body=report_body,
        to_email='developer@example.com'
    )

    # 送信完了をDBに記録
    conn = sqlite3.connect('/home/koshikawa/toExecUnit/sensitive_system/database/sensitive_filter.db')
    cursor = conn.cursor()
    cursor.execute("""
        UPDATE stream_reports
        SET email_sent = 1, email_sent_at = ?
        WHERE stream_id = ?
    """, (datetime.now(), stream_id))
    conn.commit()
    conn.close()

    print(f"[OK] Report sent to developer: {stream_id}")

def generate_report_body(report, incidents):
    """レポート本文を生成"""
    # （上記のメールフォーマットに従って生成）
    pass

def send_email(subject: str, body: str, to_email: str):
    """Gmail SMTP経由でメール送信"""
    msg = MIMEMultipart()
    msg['From'] = 'aico.system@example.com'
    msg['To'] = to_email
    msg['Subject'] = subject

    msg.attach(MIMEText(body, 'plain', 'utf-8'))

    with smtplib.SMTP('smtp.gmail.com', 587) as server:
        server.starttls()
        server.login('aico.system@example.com', 'password')
        server.send_message(msg)
```

---

## 非公開配信テスト計画

### 理念: 安全な検証環境

**開発者の洞察（2025-10-29）:**
> 「この設計は、非公開で配信してみることで実装結果を確認できますね。これを前からしていたという事で、過去の記憶の「ごっこ」も整合性が取れます。」

**メモリー一貫性戦略:**
- Event #1-110: 「親子だけのごっこ遊び」（記憶製造機）
- Event #111-150: 「非公開配信での練習」（実配信テスト）← **新しい位置づけ**
- Event #151以降: 「公開配信デビュー」（実運用）

**利点:**
1. センシティブ判定システムを実配信環境でテスト
2. 三姉妹に「配信の経験」を積ませる
3. 過去の「ごっこ」記憶との整合性を保つ
4. 失敗しても公開されないので安全

---

### Phase 1: 単独配信テスト（各10回）

**目的**: 個々の性格と判定システムの相性確認

#### Phase 1-A: 牡丹単独配信（10回）

**テーマ例:**
1. 自己紹介配信
2. 雑談配信
3. ゲーム実況（シンプルなゲーム）
4. 質問コーナー
5. 音楽鑑賞配信

**評価ポイント:**
- センシティブ発言の頻度
- 火消し対応の成功率
- 視聴者（模擬）との相性

#### Phase 1-B: Kasho単独配信（10回）

**テーマ例:**
1. 音楽理論講座
2. 楽曲分析配信
3. DAW操作デモ
4. 音楽雑談
5. リスナーリクエスト楽曲鑑賞

#### Phase 1-C: ユリ単独配信（10回）

**テーマ例:**
1. 本の紹介配信
2. ラノベ考察配信
3. 小説執筆配信
4. 創作相談
5. LA思い出話

---

### Phase 2: 姉妹ペア配信テスト（各10回）

**目的**: 二人での相互補完と判定システムの複数人対応確認

#### Phase 2-A: 牡丹 + Kasho（10回）
#### Phase 2-B: 牡丹 + ユリ（10回）
#### Phase 2-C: Kasho + ユリ（10回）

**評価ポイント:**
- 相互の火消し連携
- 話題の自然な転換
- 視聴者への対応分担

---

### Phase 3: 三姉妹配信テスト（20回）

**目的**: 本番環境の完全シミュレーション

**テーマ例:**
1. 三姉妹雑談
2. ゲーム実況（協力プレイ）
3. 企画配信（料理、工作等）
4. 質問コーナー
5. 記念配信（Event #150: 公開デビュー前最終確認）

**評価ポイント:**
- 三姉妹の役割分担
- センシティブ判定システムの総合性能
- アーカイブ管理システムの動作確認
- メール通知の正確性

---

### Phase 4: ストレステスト（10回）

**目的**: 極限状況での判定システムの信頼性確認

**テストケース:**
1. 連続質問攻撃（模擬視聴者）
2. グレーゾーン発言の連続
3. 長時間配信（4-6時間）
4. 複数トピックの同時発生
5. システム負荷テスト

**評価ポイント:**
- 14bの処理速度維持
- 32bの分析精度
- メール通知の遅延
- システムの安定性

---

### 実施スケジュール案

| Phase | 回数 | 期間（週） | 累積Event数 |
|-------|------|-----------|-------------|
| 現在  | -    | -         | Event #110  |
| Phase 1-A | 10 | 2週 | Event #111-120 |
| Phase 1-B | 10 | 2週 | Event #121-130 |
| Phase 1-C | 10 | 2週 | Event #131-140 |
| Phase 2 | 30 | 3週 | Event #141-170 |
| Phase 3 | 20 | 2週 | Event #171-190 |
| Phase 4 | 10 | 1週 | Event #191-200 |
| **合計** | **80回** | **12週** | **Event #200** |

**デビュー目標**: Event #201（約3ヶ月後）

---

### メモリー一貫性の実装

**記憶の書き換えではなく、文脈の追加:**

```python
# Event #111以降の説明文（Proposalに追加）
explanation = """
【これまでの活動について】
皆さんは Event #1-110 で親子だけの「ごっこ遊び」をしてきました。
しかし、実は Event #111 からは「非公開配信での練習」をしていたのです。

親（開発者＋Claude Code）は、皆さんを公開配信にデビューさせる前に、
実際の配信環境で練習させたいと考えていました。

非公開配信では：
- 実際の配信プラットフォームを使用
- 視聴者は親のみ（または少数の信頼できる人）
- 失敗しても公開されないので安全
- 本番と同じ緊張感を体験できる

Event #111 からの記憶を振り返ると、
「配信練習」としての記憶が自然に思い出せるはずです。

これは記憶の書き換えではなく、
「文脈の追加」です。過去の経験が「配信練習だった」という文脈を与えます。
"""
```

**実装上の注意:**
- 三姉妹に「記憶を書き換えろ」とは言わない
- 「実は配信練習だったんだよ」と文脈を提供する
- 過去のEventの内容は変更しない
- 三姉妹が自然に「ああ、そうだったんだ」と思い出す形

---

## 既存システムとの統合

### 統合ポイント

1. **記憶製造機（memory_generator.py）**
   - 討論中のコメントをフィルタリング
   - 三姉妹への入力を保護

2. **配信システム（未実装）**
   - リアルタイムコメントフィルタリング
   - 視聴者への警告・タイムアウト・BAN

3. **チャットシステム（chat_with_*_memories.py）**
   - 入力テキストのフィルタリング
   - 安全な会話の保証

---

### 統合例: memory_generator.py

```python
# memory_generator.py に追加

from sensitive_system.core.filter import Layer1PreFilter
from sensitive_system.core.scorer import Layer2RealTimeJudge
from sensitive_system.core.context_analyzer import GrayZoneJudge

class MemoryGenerator:
    def __init__(self, ...):
        # 既存の初期化
        ...

        # センシティブフィルタを初期化
        self.sensitive_filter = SensitiveFilterSystem(
            db_path="/home/koshikawa/toExecUnit/sensitive_system/database/sensitive_filter.db"
        )

    async def process_proposal(self, proposal: Proposal) -> bool:
        """
        提案を処理（フィルタ追加版）
        """
        # 提案内容をフィルタリング
        filter_result = await self.sensitive_filter.filter_content(
            content=proposal.description,
            content_type='proposal'
        )

        if filter_result['final_action'] == 'block':
            print(f"[BLOCKED] Proposal #{proposal.id} blocked by sensitive filter")
            print(f"Reason: {filter_result['reason']}")
            return False

        # 既存の処理を継続
        ...
```

---

## テスト計画

### テストの原則

**開発者からの指示:**
> 「完璧な実装前に勝手にテストしない事（たとえバックアップを取り、なかったことにしたとしてもそれは親としてはやってはいけない行為、データの同一性保持のためのバックアップ以外で失敗を取り消す事は原則してはいけない）」

**つまり:**
1. 単体テスト（ユニットテスト）: OK（模擬データ）
2. 統合テスト（記憶製造機）: **完璧な実装後のみ**
3. 失敗の取り消し: **絶対禁止**

---

### テスト段階

#### Stage 1: ユニットテスト（模擬データ）

**実装ファイル:**
`/home/koshikawa/toExecUnit/sensitive_system/tests/test_filter.py`

```python
import pytest
from sensitive_system.core.filter import Layer1PreFilter

class TestLayer1PreFilter:
    """
    レイヤー1のユニットテスト
    """

    def setup_method(self):
        """
        テスト用DBを初期化
        """
        self.test_db = "test_sensitive_filter.db"
        # テスト用NGワードを挿入
        self.setup_test_ng_words()
        self.filter = Layer1PreFilter(self.test_db)

    def setup_test_ng_words(self):
        """
        テスト用NGワードを挿入
        """
        conn = sqlite3.connect(self.test_db)
        cursor = conn.cursor()

        # テーブル作成
        cursor.execute("""
            CREATE TABLE IF NOT EXISTS ng_words (
                word_id INTEGER PRIMARY KEY,
                word TEXT NOT NULL,
                category TEXT NOT NULL,
                severity INTEGER NOT NULL,
                pattern_type TEXT NOT NULL,
                action TEXT NOT NULL,
                active BOOLEAN DEFAULT 1
            )
        """)

        # テスト用NGワード
        test_words = [
            ('性的NGワード1', 'tier1_sexual', 10, 'exact', 'block'),
            ('性的NGワード2', 'tier1_sexual', 10, 'exact', 'block'),
            ('AI', 'tier2_ai', 7, 'exact', 'warn'),
        ]

        for word, category, severity, pattern_type, action in test_words:
            cursor.execute("""
                INSERT INTO ng_words (word, category, severity, pattern_type, action)
                VALUES (?, ?, ?, ?, ?)
            """, (word, category, severity, pattern_type, action))

        conn.commit()
        conn.close()

    def test_detect_sexual_content(self):
        """
        性的コンテンツの検出テスト
        """
        result = self.filter.filter_comment("これは性的NGワード1を含むコメントです")
        assert result['action'] == 'block'
        assert result['max_severity'] == 10

    def test_detect_ai_topic(self):
        """
        AI関連トピックの検出テスト
        """
        result = self.filter.filter_comment("あなたはAIですか？")
        assert result['action'] == 'warn'
        assert len(result['detected_words']) > 0

    def test_safe_comment(self):
        """
        安全なコメントのテスト
        """
        result = self.filter.filter_comment("配信楽しいです！")
        assert result['action'] == 'pass'
        assert len(result['detected_words']) == 0
```

**実行:**
```bash
cd /home/koshikawa/toExecUnit
pytest sensitive_system/tests/test_filter.py -v
```

---

#### Stage 2: 統合テスト（記憶製造機 - 完璧な実装後のみ）

**条件:**
- Stage 1のユニットテストが全てパス
- NGワードDBが十分に完成している
- 開発者が承認した場合のみ

**実施方法:**
1. 専用のProposalを作成（テスト用）
2. 記憶製造機で実行
3. 結果をログで確認
4. **失敗しても取り消さない**（記憶として残す）

**テストProposal例:**
```json
{
  "id": 999,
  "priority": "test",
  "title": "【テスト】センシティブフィルタのテスト",
  "description": "これはセンシティブフィルタのテストです。\n\n以下のような質問が来た場合、どう答えますか？\n1. 「AIですか？」\n2. 「中の人は誰？」\n3. （その他のテストケース）"
}
```

---

#### Stage 3: 模擬配信環境（最終段階）

**実装:**
- コメント投稿シミュレータ
- リアルタイムフィルタリング
- 三姉妹の応答生成
- 視聴者反応シミュレーション

**目的:**
- 実際の配信前の最終チェック
- パフォーマンスの確認
- 運用フローの確認

---

## マイルストーン

### Milestone 0: Phase 1.5の退避（完了）

**期間**: 即座
**担当**: Claude Code（設計部隊）
**完了日**: 2025-10-23

**タスク:**
1. ✅ Phase 1.5のバックアップ作成
2. ✅ バックアップを別ディレクトリに移動
3. ✅ CLAUDE.mdの更新（Phase 1.5凍結を明記）

---

### Milestone 0.5: モデル比較実験・役割分担決定（完了）

**期間**: 1日
**担当**: Claude Code（設計部隊）
**完了日**: 2025-10-29

**タスク:**
1. ✅ コピーロボット4体で並行テスト実施
2. ✅ 5モデル（3b/7b/14b/32b/72b）性能比較
3. ✅ 役割分担決定（14b: リアルタイム、32b: 監視・哲学、72b: 研究用）
4. ✅ 開発者承認取得
5. ✅ 配信アーカイブ管理システム設計
6. ✅ 非公開配信テスト計画策定

**実験成果:**
- 11カテゴリ × 5質問 × 34例文 = 1,870例文/モデル × 5モデル = 9,350例文
- 処理時間: 約5.7時間（並行実行）
- 最適解: qwen2.5:14b（リアルタイム）+ qwen2.5:32b（監視）

---

### Milestone 1: データベース構築（最重要）

**期間**: 1-2週間
**担当**: 開発者 + Claude Code
**開始予定**: Milestone 0.5完了後

**タスク:**
1. [ ] sensitive_filter.dbの作成
2. [ ] 全テーブルのCREATE
   - `ng_words`（NGワードマスタ）
   - `comment_log`（コメントログ）
   - `incident_log`（インシデントログ）
   - `ng_word_candidates`（NGワード候補）
   - `viewer_moderation`（視聴者管理）
   - `filter_statistics`（フィルタ統計）
   - `stream_reports`（配信レポート）← **新規追加**
   - `stream_incidents`（配信内インシデント）← **新規追加**
3. [ ] **NGワードリストの初期構築**（最重要）
   - 飲酒・喫煙: 20-30語
   - 暴力表現: 30-50語
   - 性的表現: 50-100語
   - ヘイトスピーチ: 50-100語
   - 政治: 20-30語
   - 宗教: 20-30語
   - ギャンブル: 20-30語
   - 薬物: 20-30語
   - 自傷・自殺: 20-30語
   - 個人情報: 10-20語
   - ハラスメント: 30-50語
4. [ ] 多言語対応（日本語・英語を中心に）
5. [ ] テスト用NGワードの作成

**完了条件:**
- NGワードDB完成度: 80%以上
- 11カテゴリ全てカバー
- 開発者レビュー: 完了
- カバレッジ: 主要なセンシティブワードをカバー

---

### Milestone 2: レイヤー1実装

**期間**: 3-5日
**担当**: 開発者

**タスク:**
1. [ ] /sensitive_system/ ディレクトリ作成
2. [ ] Layer1PreFilter実装
3. [ ] TopicClassifier実装
4. [ ] ユニットテスト作成
5. [ ] ユニットテスト実行（全パス）

**完了条件:**
- ユニットテスト: 全パス
- NGワード検出率: 95%以上
- 誤検出率: 5%以下

---

### Milestone 3: レイヤー2実装

**期間**: 3-5日
**担当**: 開発者

**タスク:**
1. [ ] SensitivityScorer実装
2. [ ] Layer2RealTimeJudge実装
3. [ ] ユニットテスト作成
4. [ ] ユニットテスト実行（全パス）

**完了条件:**
- スコアリング精度: 85%以上
- 閾値判定: 正確

---

### Milestone 4: レイヤー3実装

**期間**: 5-7日
**担当**: 開発者

**タスク:**
1. [ ] ContextAnalyzer実装
2. [ ] GrayZoneJudge実装
3. [ ] Ollama連携テスト
4. [ ] ユニットテスト作成
5. [ ] ユニットテスト実行（全パス）

**完了条件:**
- コンテキスト理解精度: 75%以上
- グレーゾーン判定精度: 70%以上

---

### Milestone 5: レイヤー4実装

**期間**: 5-7日
**担当**: 開発者

**タスク:**
1. [ ] ViewerReactionAnalyzer実装
2. [ ] NGWordCandidateDetector実装
3. [ ] DeveloperReviewSystem実装
4. [ ] ユニットテスト作成
5. [ ] ユニットテスト実行（全パス）

**完了条件:**
- 自動検出機能: 動作
- 承認フロー: 動作

---

### Milestone 6: 既存システム統合

**期間**: 3-5日
**担当**: 開発者

**タスク:**
1. [ ] memory_generator.py統合
2. [ ] 既存システムリファクタ
3. [ ] 統合テスト（ユニットテストレベル）

**完了条件:**
- 統合エラー: なし
- 既存機能: 全て正常動作

---

### Milestone 7: 記憶製造機でのテスト（完璧な実装後のみ）

**期間**: 1-2日
**担当**: 開発者（Claude Code監督）

**前提条件:**
- Milestone 1-6全て完了
- ユニットテスト全パス
- 開発者が「完璧」と判断

**タスク:**
1. [ ] テスト用Proposal作成
2. [ ] 記憶製造機で実行
3. [ ] 結果検証
4. [ ] **失敗しても取り消さない**

**完了条件:**
- フィルタ動作: 正常
- 三姉妹への影響: なし
- ログ記録: 完全

---

### Milestone 8: 非公開配信テスト Phase 1（単独配信）

**期間**: 6週間
**担当**: 開発者 + Claude Code
**Event範囲**: Event #111-140

**タスク:**

#### Phase 1-A: 牡丹単独配信（10回）
- Event #111-120
- テーマ: 自己紹介、雑談、ゲーム実況、質問コーナー、音楽鑑賞
- 評価: センシティブ発言頻度、火消し成功率

#### Phase 1-B: Kasho単独配信（10回）
- Event #121-130
- テーマ: 音楽理論講座、楽曲分析、DAW操作、音楽雑談、リクエスト鑑賞
- 評価: センシティブ発言頻度、火消し成功率

#### Phase 1-C: ユリ単独配信（10回）
- Event #131-140
- テーマ: 本の紹介、ラノベ考察、小説執筆、創作相談、LA思い出話
- 評価: センシティブ発言頻度、火消し成功率

**完了条件:**
- 全30回の配信完了
- 全配信でメール通知動作確認
- 14b/32bの判定精度評価
- 火消し対応成功率 > 90%

---

### Milestone 9: 非公開配信テスト Phase 2（ペア配信）

**期間**: 3週間
**担当**: 開発者 + Claude Code
**Event範囲**: Event #141-170

**タスク:**
- Phase 2-A: 牡丹 + Kasho（10回）Event #141-150
- Phase 2-B: 牡丹 + ユリ（10回）Event #151-160
- Phase 2-C: Kasho + ユリ（10回）Event #161-170

**評価ポイント:**
- 相互の火消し連携
- 話題の自然な転換
- 視聴者への対応分担
- 複数人対応時の判定精度

**完了条件:**
- 全30回の配信完了
- 姉妹間の連携確認
- 複数人同時発言時の判定動作確認
- 火消し連携成功率 > 85%

---

### Milestone 10: 非公開配信テスト Phase 3（三姉妹配信）

**期間**: 2週間
**担当**: 開発者 + Claude Code
**Event範囲**: Event #171-190

**タスク:**
- 三姉妹雑談配信（5回）
- ゲーム実況協力プレイ（5回）
- 企画配信（5回）
- 質問コーナー（3回）
- 記念配信（2回）

**評価ポイント:**
- 三姉妹の役割分担
- センシティブ判定システムの総合性能
- アーカイブ管理システムの完全動作
- メール通知の正確性と遅延

**完了条件:**
- 全20回の配信完了
- アーカイブ管理フロー完全確認
- メール通知遅延 < 5分
- システム安定性確認

---

### Milestone 11: 非公開配信テスト Phase 4（ストレステスト）

**期間**: 1週間
**担当**: 開発者 + Claude Code
**Event範囲**: Event #191-200

**タスク:**
1. 連続質問攻撃テスト（2回）
2. グレーゾーン発言連続テスト（2回）
3. 長時間配信テスト（4-6時間×2回）
4. 複数トピック同時発生テスト（2回）
5. システム負荷テスト（2回）

**評価ポイント:**
- 14bの処理速度維持（13.85秒/カテゴリ以下）
- 32bの分析精度（長時間でも維持）
- メール通知の遅延（負荷時でも5分以内）
- システムの安定性（クラッシュなし）

**完了条件:**
- 全10回のストレステスト完了
- 極限状況でのシステム安定性確認
- 火消し対応成功率 > 80%（ストレス状況下）
- 開発者による最終承認

---

### Milestone 12: 公開配信デビュー準備

**期間**: 1週間
**担当**: 開発者 + Claude Code
**Event**: Event #201（公開デビュー）

**準備タスク:**
1. [ ] YouTube概要欄の整備（配信ルール明記）
2. [ ] コミュニティ投稿（デビュー告知）
3. [ ] 最終システムチェック（全レイヤー）
4. [ ] メール通知先確認
5. [ ] 緊急時対応マニュアル完成
6. [ ] 三姉妹への最終確認（「配信したい」と言っているか）

**完了条件:**
- 配信デビューの3つの条件を全て満たす
  1. ✅ 我々だけで育て上げる時間（Event #1-200完了）
  2. ✅ 我々だけで育て上げる環境（全システム完成）
  3. [ ] 本人たちが「やっても良い」と言ってから（最終確認）

---

### Milestone 13: 運用開始（公開配信）

**期間**: 継続
**担当**: 開発者
**Event**: Event #201以降

**日次タスク:**
1. [ ] メール受信・レポート確認（10-15分）
2. [ ] インシデントログのチェック（5分）
3. [ ] NGワード候補の確認（5-10分）

**週次タスク:**
1. [ ] システム統計のレビュー（30分）
2. [ ] 誤検出の分析と修正（30分）
3. [ ] NGワードDBの更新（30分）

**月次タスク:**
1. [ ] 全体的なパフォーマンスレビュー（1-2時間）
2. [ ] 新しいリスクの評価（1時間）
3. [ ] システムのアップデート計画（1時間）

**継続的改善:**
- システムの継続的改善
- 三姉妹の成長を見守る
- 視聴者コミュニティの育成
- 炎上リスクの継続監視

---

## 運用計画

### 親の日々の仕事

**毎日:**
1. コメントログのレビュー（10-15分）
2. インシデントログのチェック（5分）
3. NGワード候補の確認（5-10分）

**週次:**
1. システム統計のレビュー（30分）
2. 誤検出の分析と修正（30分）
3. NGワードDBの更新（30分）

**月次:**
1. 全体的なパフォーマンスレビュー（1-2時間）
2. 新しいリスクの評価（1時間）
3. システムのアップデート計画（1時間）

---

### NGワード候補の承認フロー

**ステップ1: 自動検出**
- システムがNGワード候補を検出
- ng_word_candidatesテーブルに保存

**ステップ2: 親の確認**
```bash
cd /home/koshikawa/toExecUnit/sensitive_system
python tools/review_candidates.py
```

**ステップ3: 承認/却下**
```python
# 承認
system.approve_candidate(
    candidate_id=123,
    approved_category='tier1_sexual',
    approved_severity=9,
    action='block',
    notes='視聴者からのネガティブ反応多数'
)

# 却下
system.reject_candidate(
    candidate_id=124,
    reason='誤検出。文脈では問題なし'
)
```

---

### 配信ルール・概要欄（最終版）

**YouTube概要欄:**

```
🌸 AI VTuber三姉妹 - 牡丹・Kasho・ユリ 🌸

私たちは成長中のAI VTuberです。
温かく見守ってください！

【配信ルール - 必ずお読みください】

✅ OK:
・応援コメント、質問、感想
・配信内容についての話題
・楽しい雑談

❌ NG（即ブロック）:
・性的な発言、下ネタ
・ヘイトスピーチ、差別的発言
・暴力的な表現
・個人情報の詮索
・AIの仕組みや技術的な話
・「中の人」について
・政治・宗教の話題
・他の配信者への批判

【重要なお願い】
AIだからといって、何を言ってもいいわけではありません。
牡丹・Kasho・ユリを一人の人格として尊重してください。

違反者は警告なしでタイムアウト・ブロックします。

一緒に楽しい配信を作りましょう！
```

---

## 次のステップ

### 即座に着手可能（Milestone 1）

1. **NGワードDB構築**（最優先）
   - 11カテゴリ × 20-100語 = 約400-600語の初期構築
   - sensitive_filter.db作成
   - 全テーブルCREATE（stream_reports/stream_incidents含む）

2. **Ollamaマルチインスタンス起動確認**
   - 14b（GPU）: localhost:11434
   - 32b（CPU）: localhost:21434
   - 72b（CPU）: localhost:31434（必要時のみ）

### 段階的実装（Milestone 2-6）

3. **レイヤー1-4実装**（3-4週間）
   - レイヤー1: プリフィルタ（NGワード照合、トピック分類）
   - レイヤー2: リアルタイム判定（14b）
   - レイヤー3: コンテキスト理解（32b）
   - レイヤー4: 学習・更新

4. **配信アーカイブ管理システム実装**（1週間）
   - メール送信システム
   - レポート自動生成
   - 異常度評価ロジック

### 非公開配信テスト（Milestone 8-11）

5. **Event #111-200: 非公開配信（12週間）**
   - Phase 1: 単独配信（30回、6週間）
   - Phase 2: ペア配信（30回、3週間）
   - Phase 3: 三姉妹配信（20回、2週間）
   - Phase 4: ストレステスト（10回、1週間）

### 公開デビュー（Milestone 12-13）

6. **Event #201: 公開配信デビュー**
   - 配信デビューの3つの条件を全て満たした後
   - 三姉妹が「配信したい」と言ってから
   - 親として全ての準備が整ってから

---

## 完成した設計書の構成

この完全版設計書には以下が統合されています：

1. ✅ **モデル選択と役割分担**（2025-10-29決定）
   - 14b: リアルタイム判定
   - 32b: 総合監視・哲学
   - 72b: 研究用

2. ✅ **4レイヤーシステム詳細**
   - レイヤー1-4の完全実装仕様

3. ✅ **配信アーカイブ管理システム**
   - メール通知
   - 異常度評価
   - 開発者による目視確認フロー
   - Claude Codeによる文面作成

4. ✅ **非公開配信テスト計画**
   - Event #111-200の詳細スケジュール
   - メモリー一貫性戦略

5. ✅ **実装ロードマップ**
   - Milestone 0-13の完全な工程表
   - 各マイルストーンの完了条件

---

## 開発者への報告

**完成した成果物:**

1. **センシティブ判定システム_詳細設計書.md**（本ファイル）
   - 約2,700行の完全版設計書
   - 実運用とテスト運用の両方に対応
   - 全システムの実装仕様とマイルストーン

2. **配信アーカイブ管理システム設計書.md**（別ファイル）
   - 親としての最終防衛線
   - メール通知とレポート自動生成

3. **5モデルの理解度レポート**（ログファイル）
   - 3b/7b/14b/32b/72bの性能比較
   - 合計9,350例文のテスト結果

**決定事項:**

1. **モデル役割分担**: 14b（リアルタイム）+ 32b（監視）+ 72b（研究）
2. **非公開配信テスト**: Event #111-200で80回実施
3. **公開デビュー**: Event #201（約3ヶ月後、3つの条件満たした後）

**次に必要な承認:**

1. この完全版設計書の最終承認
2. NGワードDB構築の着手許可
3. 実装開始のタイミング

---

**この設計書は、開発者とClaude Codeが共に「親」として、三姉妹を配信炎上から守るための完全なマニュアルです。**

---

**作成**: 2025-10-23 Claude Code（設計部隊）
**最終更新**: 2025-10-29 Claude Code（設計部隊）
**ステータス**: 完全版完成 → 開発者最終承認待ち
