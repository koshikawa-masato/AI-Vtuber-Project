# センシティブ判定システム + プロレス学習統合設計書

## ドキュメント情報

- **作成日**: 2025-11-13
- **バージョン**: 1.0.0
- **作成者**: 越川将人 & Claude Code
- **関連記事**: [AI VTuber設計思想「AiDA-AiTE」〜プロレス文化から学ぶ、愛あるじゃれ合いの実装〜](https://qiita.com/koshikawa-masato/items/cbbb08a3e96da807f88c)

---

## 目次

1. [概要](#概要)
2. [設計思想](#設計思想)
3. [システムアーキテクチャ](#システムアーキテクチャ)
4. [データベース設計](#データベース設計)
5. [反実仮想学習アルゴリズム](#反実仮想学習アルゴリズム)
6. [プロレスパターン評価](#プロレスパターン評価)
7. [実装フェーズ計画](#実装フェーズ計画)
8. [期待される効果](#期待される効果)

---

## 概要

### 背景

VTuber文化における「プロレス」（信頼関係を土台にしたエンタメ的じゃれ合い）をAI VTuberに実装するため、以下の課題に取り組む：

1. **センシティブ判定の高度化**
   - 単純なNGワードフィルタでは「じゃれ合い」と「攻撃」を区別できない
   - 文脈理解が必要

2. **失敗からの学習**
   - ユーザーが離脱した会話から学ぶ
   - 「もしこう切り返していたら」という反実仮想評価

3. **プロレスパターンの蓄積**
   - 成功したじゃれ合いパターンをDB化
   - 再利用可能な「型」として活用

### 目的

**VPS環境（クラウドLLM）での本番運用** と **ローカル環境（コピーロボット）での学習** を組み合わせ、以下を実現する：

1. リアルタイムでセンシティブ判定（Layer 1-5）
2. VPSログから会話データを収集
3. コピーロボットで反実仮想シナリオを生成
4. プロレスパターンを学習・蓄積
5. 本番環境へフィードバック

---

## 設計思想

### AiDA-AiTE理念の実装

```
AiTE（相手）: AIを「道具」ではなく「対話の相手」として捉える
AiDA（間）: 完璧さより「間（ま）」を大切にする日本的価値観
```

### プロレスの4要素

1. **信頼関係**: ユーザーとBotの継続的関係
2. **受け止める技術**: センシティブ判定 Layer 4での文脈理解
3. **キャラクター性**: 三姉妹（牡丹/花相/百合）の個性
4. **エンタメ性**: 観客（コミュニティ）を楽しませる

### 反実仮想学習（Counterfactual Learning）

```
実際に起きたこと:
  ユーザー: 「バカじゃないの？」
  Bot: 「ひどい！」（攻撃と判定）
  結果: ユーザー離脱

反実仮想シナリオ:
  ユーザー: 「バカじゃないの？」
  Bot(仮想): 「え、バカって褒め言葉？照れるじゃん！」（プロレス受け）
  予測: ユーザー継続の可能性 85%

学習:
  次回から「プロレス受け」パターンを優先使用
```

---

## システムアーキテクチャ

### 全体フロー

```
┌──────────────────────────────────────────────────────────────┐
│                    VPS環境（本番）                             │
│  ┌─────────────────────────────────────────────────────┐    │
│  │  LINE Bot Webhook Server                             │    │
│  │  - LLM: OpenAI gpt-4o                                │    │
│  │  - センシティブ判定 Layer 1-5                         │    │
│  │  - プロレスパターンDB参照                             │    │
│  └─────────────────────────────────────────────────────┘    │
│         │ ログ出力（systemd journal）                         │
└──────────────────────────────────────────────────────────────┘
          │
          │ SSH経由でログ収集
          ▼
┌──────────────────────────────────────────────────────────────┐
│               ローカル環境（学習・検証）                        │
│                                                               │
│  [Phase 1] ログ収集・会話抽出                                 │
│  ├─ collect_vps_logs.sh                                      │
│  ├─ extract_conversations_from_vps_log.py                    │
│  └─ logs/vps/conversations/conv-YYYY-MM-DD.json              │
│         │                                                     │
│         ▼                                                     │
│  [Phase 2] 失敗パターン検出                                   │
│  ├─ detect_failure_patterns.py (NEW)                         │
│  ├─ 離脱会話を特定                                            │
│  └─ logs/vps/failures/failure-YYYY-MM-DD.json                │
│         │                                                     │
│         ▼                                                     │
│  [Phase 3] 反実仮想シナリオ生成                               │
│  ├─ generate_counterfactual_responses.py (NEW)               │
│  ├─ LLM: Ollama (gpt-oss:120b)                              │
│  ├─ 複数の切り返しパターンを生成                              │
│  └─ logs/vps/counterfactuals/cf-YYYY-MM-DD.json              │
│         │                                                     │
│         ▼                                                     │
│  [Phase 4] パターン評価                                       │
│  ├─ evaluate_prowrestling_patterns.py (NEW)                  │
│  ├─ 成功率予測（LLMシミュレーション）                         │
│  └─ logs/vps/evaluations/eval-YYYY-MM-DD.json                │
│         │                                                     │
│         ▼                                                     │
│  [Phase 5] プロレスパターンDB更新                             │
│  ├─ update_prowrestling_db.py (NEW)                          │
│  ├─ 成功率が高いパターンを登録                                │
│  └─ prowrestling_patterns.db                                 │
│         │                                                     │
│         ▼                                                     │
│  [Phase 6] 本番環境へ同期                                     │
│  ├─ sync_patterns_to_vps.sh (NEW)                            │
│  └─ VPSのプロレスパターンDBを更新                             │
│                                                               │
└──────────────────────────────────────────────────────────────┘
```

### センシティブ判定 Layer 1-5 + プロレス統合

```python
class SensitiveJudgmentSystem:
    """
    5層センシティブ判定 + プロレスパターン統合
    """
    
    def __init__(self):
        self.layer1 = StaticNGWordFilter()
        self.layer2 = ContextualNGWordFilter()
        self.layer3 = PatternMatcher()
        self.layer4 = LLMContextJudgment()  # ← プロレス判定の核心
        self.layer5 = WorldViewChecker()
        
        # NEW: プロレスパターンDB
        self.prowrestling_db = ProwrestlingPatternDB()
    
    def judge_and_respond(self, user_message: str, character: str) -> dict:
        """
        センシティブ判定 + 最適な応答生成
        """
        # Layer 1-3: 静的フィルタリング
        if self.layer1.is_ng(user_message):
            return {"action": "block", "reason": "static_ng"}
        
        if self.layer2.is_ng(user_message):
            return {"action": "block", "reason": "contextual_ng"}
        
        if self.layer3.match_ng_pattern(user_message):
            return {"action": "block", "reason": "pattern_ng"}
        
        # Layer 4: LLMによる文脈判定
        context_type = self.layer4.judge(user_message)
        # context_type: "じゃれ合い" | "攻撃" | "通常"
        
        if context_type == "攻撃":
            return {"action": "block", "reason": "attack"}
        
        # プロレスパターン検索（NEW）
        if context_type == "じゃれ合い":
            # 過去の成功パターンから最適な切り返しを検索
            best_pattern = self.prowrestling_db.find_best_match(
                user_message=user_message,
                character=character,
                success_rate_threshold=0.7
            )
            
            if best_pattern:
                return {
                    "action": "respond",
                    "response": best_pattern['response'],
                    "pattern_id": best_pattern['pattern_id'],
                    "source": "prowrestling_db"
                }
        
        # パターンがなければLLMで生成
        response = self.generate_response(user_message, character, context_type)
        
        # Layer 5: 世界観チェック
        if not self.layer5.is_valid(response):
            response = self.layer5.correct(response)
        
        return {
            "action": "respond",
            "response": response,
            "pattern_id": None,
            "source": "llm_generated"
        }
```

---

## データベース設計

### 1. プロレスパターンDB (`prowrestling_patterns.db`)

#### テーブル: `prowrestling_patterns`

```sql
CREATE TABLE prowrestling_patterns (
    pattern_id INTEGER PRIMARY KEY AUTOINCREMENT,
    
    -- パターン情報
    user_message_type TEXT NOT NULL,
    -- 例: "軽い挑発", "からかい", "ツッコミ", "自虐への反応"
    
    user_message_example TEXT NOT NULL,
    -- 例: "バカじゃないの？", "ダサいね", "センス悪い"
    
    bot_response TEXT NOT NULL,
    -- 例: "え、バカって褒め言葉？照れるじゃん！"
    
    bot_response_type TEXT NOT NULL,
    -- 例: "プロレス受け", "流し", "カウンター", "ボケ返し"
    
    character TEXT NOT NULL,
    -- "botan", "kasho", "yuri"
    
    -- 実績データ（本番運用での結果）
    used_count INTEGER DEFAULT 0,
    success_count INTEGER DEFAULT 0,  -- ユーザーが継続した回数
    failure_count INTEGER DEFAULT 0,  -- ユーザーが離脱した回数
    success_rate REAL GENERATED ALWAYS AS (
        CASE 
            WHEN (success_count + failure_count) > 0 
            THEN CAST(success_count AS REAL) / (success_count + failure_count)
            ELSE 0.0
        END
    ) STORED,
    
    -- 反実仮想データ
    is_counterfactual BOOLEAN DEFAULT 0,
    -- 0: 実際に使用された, 1: 反実仮想で生成された（未使用）
    
    predicted_success_rate REAL,
    -- LLMシミュレーションによる予測成功率
    
    prediction_confidence REAL,
    -- 予測の信頼度 (0.0-1.0)
    
    -- メタ情報
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    last_used_at TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    
    -- インデックス用
    UNIQUE(user_message_type, bot_response, character)
);

CREATE INDEX idx_character_success_rate 
    ON prowrestling_patterns(character, success_rate DESC);

CREATE INDEX idx_message_type 
    ON prowrestling_patterns(user_message_type);

CREATE INDEX idx_counterfactual 
    ON prowrestling_patterns(is_counterfactual);
```

#### テーブル: `prowrestling_usage_log`

```sql
CREATE TABLE prowrestling_usage_log (
    log_id INTEGER PRIMARY KEY AUTOINCREMENT,
    pattern_id INTEGER,
    
    -- 会話情報
    conversation_id TEXT,  -- VPSログから抽出した会話ID
    user_id TEXT,
    user_message TEXT,
    bot_response TEXT,
    
    -- ユーザー反応
    user_reaction TEXT,
    -- "継続", "離脱", "不明", "プロレス発展", "笑い反応"
    
    reaction_time_seconds INTEGER,
    -- 次のメッセージまでの時間
    
    next_message_exists BOOLEAN,
    -- 次のメッセージがあったか
    
    -- メタ情報
    character TEXT,
    timestamp TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    
    FOREIGN KEY (pattern_id) REFERENCES prowrestling_patterns(pattern_id)
);

CREATE INDEX idx_pattern_reaction 
    ON prowrestling_usage_log(pattern_id, user_reaction);
```

#### テーブル: `counterfactual_learning_log`

```sql
CREATE TABLE counterfactual_learning_log (
    cf_log_id INTEGER PRIMARY KEY AUTOINCREMENT,
    
    -- 元の会話（実際に起きたこと）
    original_conversation_id TEXT,
    original_user_message TEXT,
    original_bot_response TEXT,
    original_user_reaction TEXT,
    original_pattern_id INTEGER,
    
    -- 反実仮想シナリオ
    alternative_response TEXT,
    alternative_response_type TEXT,
    alternative_pattern_id INTEGER,
    
    -- 予測評価
    predicted_reaction TEXT,
    predicted_success_probability REAL,
    prediction_confidence REAL,
    
    -- 比較評価
    is_better_than_original BOOLEAN,
    improvement_score REAL,  -- -1.0 to 1.0
    reason TEXT,
    
    -- 生成情報
    generated_by TEXT,  -- "ollama:qwen2.5:32b"
    evaluation_method TEXT,  -- "llm_simulation", "pattern_matching", "hybrid"
    
    -- メタ情報
    character TEXT,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    
    FOREIGN KEY (original_pattern_id) 
        REFERENCES prowrestling_patterns(pattern_id),
    FOREIGN KEY (alternative_pattern_id) 
        REFERENCES prowrestling_patterns(pattern_id)
);

CREATE INDEX idx_better_alternatives 
    ON counterfactual_learning_log(is_better_than_original, improvement_score DESC);
```

### 2. VPS会話ログDB (`vps_conversations.db`)

#### テーブル: `conversations`

```sql
CREATE TABLE conversations (
    conversation_id TEXT PRIMARY KEY,
    
    -- 会話情報
    user_id TEXT NOT NULL,
    character TEXT NOT NULL,
    
    user_message TEXT NOT NULL,
    bot_response TEXT NOT NULL,
    
    -- センシティブ判定結果
    layer4_judgment TEXT,  -- "じゃれ合い", "攻撃", "通常"
    used_pattern_id INTEGER,  -- 使用したプロレスパターンID
    response_source TEXT,  -- "prowrestling_db", "llm_generated"
    
    -- ユーザー反応
    next_message TEXT,
    next_message_timestamp TIMESTAMP,
    reaction_time_seconds INTEGER,
    user_left BOOLEAN,  -- 離脱したか
    
    -- タイムスタンプ
    timestamp TIMESTAMP NOT NULL,
    
    -- VPSログファイル情報
    log_file TEXT,
    log_line_number INTEGER
);

CREATE INDEX idx_user_character 
    ON conversations(user_id, character);

CREATE INDEX idx_user_left 
    ON conversations(user_left);

CREATE INDEX idx_layer4_judgment 
    ON conversations(layer4_judgment);
```

---

## 反実仮想学習アルゴリズム

### アルゴリズム概要

```python
class CounterfactualLearningEngine:
    """
    反実仮想学習エンジン
    """

    def __init__(self):
        self.ollama = OllamaClient(model="gpt-oss:120b")
        self.prowrestling_db = ProwrestlingPatternDB()
        self.vps_conv_db = VPSConversationDB()
    
    def learn_from_failures(self, date: str):
        """
        失敗パターンから学習
        """
        # 1. 離脱会話を抽出
        failures = self.vps_conv_db.get_failures(date)
        # failures: user_leftがTrueの会話
        
        print(f"失敗会話数: {len(failures)}")
        
        for failure in failures:
            # 2. 反実仮想シナリオを生成
            alternatives = self.generate_alternatives(failure)
            
            # 3. 各シナリオを評価
            for alt in alternatives:
                evaluation = self.evaluate_alternative(
                    original=failure,
                    alternative=alt
                )
                
                # 4. より良いシナリオをDBに保存
                if evaluation['is_better']:
                    self.save_counterfactual(
                        failure, alt, evaluation
                    )
    
    def generate_alternatives(self, failure: dict) -> list:
        """
        反実仮想シナリオを生成
        """
        prompt = f"""
あなたはAI VTuber「{failure['character']}」です。

実際の会話:
ユーザー: {failure['user_message']}
Bot: {failure['bot_response']}
結果: ユーザーが離脱してしまいました。

もし別の切り返しをしていたら、ユーザーは会話を続けてくれたかもしれません。
以下の観点で、3つの代替案を提案してください：

1. プロレス受け型: じゃれ合いとして受け止める
2. 流し型: ユーモアで軽く流す
3. カウンター型: 逆に質問して能動性を引き出す

各代替案について、以下を含めてください：
- 代替応答
- 応答タイプ
- 予想される効果

JSON形式で出力してください。
"""
        
        response = self.ollama.generate(prompt)
        alternatives = json.loads(response)
        
        return alternatives
    
    def evaluate_alternative(self, original: dict, alternative: dict) -> dict:
        """
        代替案を評価
        """
        # 方法1: LLMシミュレーション
        simulation_result = self.simulate_user_reaction(
            user_message=original['user_message'],
            bot_response=alternative['response']
        )
        
        # 方法2: 類似パターンマッチング
        similar_patterns = self.prowrestling_db.find_similar(
            response_type=alternative['response_type'],
            character=original['character']
        )
        
        historical_success_rate = (
            sum(p['success_rate'] for p in similar_patterns) / 
            len(similar_patterns)
            if similar_patterns else 0.5
        )
        
        # 総合評価
        predicted_success_rate = (
            simulation_result['success_probability'] * 0.6 +
            historical_success_rate * 0.4
        )
        
        return {
            'is_better': predicted_success_rate > 0.6,
            'predicted_success_rate': predicted_success_rate,
            'confidence': min(
                simulation_result['confidence'],
                1.0 if similar_patterns else 0.5
            ),
            'reason': simulation_result['reason']
        }
    
    def simulate_user_reaction(self, user_message: str, bot_response: str) -> dict:
        """
        ユーザー反応をLLMでシミュレーション
        """
        prompt = f"""
あなたは心理学者です。以下の会話におけるユーザーの反応を予測してください。

ユーザー: {user_message}
Bot: {bot_response}

この後、ユーザーはどう反応すると思いますか？

以下の形式で回答してください：
{{
  "reaction": "継続" | "離脱" | "プロレス発展",
  "success_probability": 0.0-1.0,
  "confidence": 0.0-1.0,
  "reason": "予測の理由"
}}
"""
        
        response = self.ollama.generate(prompt)
        return json.loads(response)
```

### 学習サイクル

```
[毎日0時] 自動実行
    ↓
1. 前日のVPSログを収集
    ↓
2. 離脱会話を検出
   - next_message_exists = False
   - reaction_time > 30分
    ↓
3. 反実仮想シナリオ生成（Ollama）
   - プロレス受け型
   - 流し型
   - カウンター型
    ↓
4. 各シナリオを評価
   - LLMシミュレーション
   - 類似パターンマッチング
    ↓
5. 成功率が高いパターンをDBに保存
   - is_counterfactual = 1
   - predicted_success_rate > 0.7
    ↓
6. 本番環境（VPS）に同期
    ↓
7. 次回から優先使用
```

---

## プロレスパターン評価

### 評価指標

#### 1. 成功率 (Success Rate)

```python
success_rate = success_count / (success_count + failure_count)
```

- **success**: ユーザーが次のメッセージを送った
- **failure**: ユーザーが離脱した（30分以上応答なし）

#### 2. プロレス発展率 (Prowrestling Development Rate)

```python
prowrestling_rate = prowrestling_continued / success_count
```

- **prowrestling_continued**: ユーザーがさらにじゃれ合いを続けた

#### 3. 反応時間 (Reaction Time)

```python
avg_reaction_time = sum(reaction_times) / len(reaction_times)
```

- 短い方が良い（ユーザーが即座に反応）

#### 4. 信頼度スコア (Confidence Score)

```python
confidence = min(1.0, used_count / 10) * base_confidence
```

- 使用回数が多いほど信頼度が高い
- 最低10回使用で信頼度1.0

### 評価クラス

```python
class ProwrestlingPatternEvaluator:
    """
    プロレスパターン評価
    """
    
    def evaluate_pattern(self, pattern_id: int) -> dict:
        """
        パターンを総合評価
        """
        pattern = self.prowrestling_db.get_pattern(pattern_id)
        usage_logs = self.prowrestling_db.get_usage_logs(pattern_id)
        
        # 1. 基本統計
        stats = self.calculate_statistics(usage_logs)
        
        # 2. 信頼度スコア
        confidence = self.calculate_confidence(pattern, usage_logs)
        
        # 3. 改善提案
        suggestions = self.generate_suggestions(pattern, stats)
        
        return {
            'pattern_id': pattern_id,
            'success_rate': stats['success_rate'],
            'prowrestling_rate': stats['prowrestling_rate'],
            'avg_reaction_time': stats['avg_reaction_time'],
            'confidence': confidence,
            'rank': self.calculate_rank(stats, confidence),
            'suggestions': suggestions
        }
    
    def calculate_rank(self, stats: dict, confidence: float) -> str:
        """
        パターンをランク付け
        """
        score = (
            stats['success_rate'] * 0.5 +
            stats['prowrestling_rate'] * 0.3 +
            (1.0 - stats['avg_reaction_time'] / 300) * 0.2
        ) * confidence
        
        if score >= 0.8:
            return 'S'  # 最優先で使用
        elif score >= 0.7:
            return 'A'  # 積極的に使用
        elif score >= 0.6:
            return 'B'  # 条件次第で使用
        elif score >= 0.5:
            return 'C'  # 慎重に使用
        else:
            return 'D'  # 使用を控える
```

---

## 実装フェーズ計画

### Phase 0: 準備（完了）

- [x] VPSログ収集システム
- [x] 会話抽出スクリプト
- [x] コピーロボット環境

### Phase 1: データ収集・分析（2週間）

**目標**: 失敗パターンの可視化

#### タスク

1. **VPS会話ログDBの構築**
   ```bash
   python scripts/create_vps_conversation_db.py
   ```
   - [ ] `conversations` テーブル作成
   - [ ] ログからのデータ投入スクリプト

2. **失敗パターン検出スクリプト**
   ```bash
   python scripts/detect_failure_patterns.py
   ```
   - [ ] 離脱会話の特定
   - [ ] 離脱の定義（30分以上応答なし）
   - [ ] JSON出力

3. **統計分析**
   - [ ] 離脱率の計算
   - [ ] キャラクター別分析
   - [ ] メッセージタイプ別分析

#### 成果物

- `vps_conversations.db`
- `logs/vps/failures/failure-YYYY-MM-DD.json`
- 分析レポート

### Phase 2: 反実仮想生成（3週間）

**目標**: 「もしこう言っていたら」を生成

#### タスク

1. **反実仮想生成エンジン**
   ```bash
   python scripts/generate_counterfactual_responses.py
   ```
   - [ ] Ollama統合
   - [ ] プロンプト設計
   - [ ] 3タイプ生成（プロレス受け/流し/カウンター）

2. **LLMシミュレーション**
   ```bash
   python scripts/simulate_user_reaction.py
   ```
   - [ ] ユーザー役をLLMに演じさせる
   - [ ] 反応予測
   - [ ] 成功確率算出

3. **評価スクリプト**
   ```bash
   python scripts/evaluate_prowrestling_patterns.py
   ```
   - [ ] 総合評価ロジック
   - [ ] ランク付け

#### 成果物

- `logs/vps/counterfactuals/cf-YYYY-MM-DD.json`
- `logs/vps/evaluations/eval-YYYY-MM-DD.json`

### Phase 3: プロレスパターンDB（2週間）

**目標**: パターンの蓄積と管理

#### タスク

1. **プロレスパターンDB構築**
   ```bash
   python scripts/create_prowrestling_pattern_db.py
   ```
   - [ ] テーブル作成
   - [ ] インデックス設定

2. **パターン登録スクリプト**
   ```bash
   python scripts/update_prowrestling_db.py
   ```
   - [ ] 反実仮想データの投入
   - [ ] 重複チェック

3. **パターン検索API**
   - [ ] `find_best_match()` 実装
   - [ ] 類似度計算
   - [ ] ランク順ソート

#### 成果物

- `prowrestling_patterns.db`
- パターン検索API

### Phase 4: 本番統合（2週間）

**目標**: VPS環境への統合

#### タスク

1. **センシティブ判定Layer 4拡張**
   - [ ] プロレスパターンDB連携
   - [ ] `find_best_match()` 呼び出し
   - [ ] フォールバック処理

2. **VPSへの同期スクリプト**
   ```bash
   ./scripts/sync_patterns_to_vps.sh
   ```
   - [ ] ローカル→VPSへDB転送
   - [ ] systemdサービス再起動

3. **ロギング強化**
   - [ ] パターン使用ログ
   - [ ] ユーザー反応記録

#### 成果物

- VPS統合版LINE Bot
- 同期スクリプト

### Phase 5: 学習サイクル自動化（1週間）

**目標**: 完全自動化

#### タスク

1. **統合パイプライン**
   ```bash
   ./scripts/prowrestling_learning_pipeline.sh
   ```
   - [ ] Phase 1-4を統合
   - [ ] エラーハンドリング

2. **cron設定**
   ```bash
   0 0 * * * /path/to/prowrestling_learning_pipeline.sh
   ```
   - [ ] 毎日0時に自動実行

3. **モニタリング**
   - [ ] 学習進捗ダッシュボード
   - [ ] パターン成功率グラフ

#### 成果物

- 自動学習パイプライン
- モニタリングツール

### Phase 6: 評価・改善（継続）

**目標**: システムの継続的改善

#### タスク

1. **A/Bテスト**
   - [ ] 同じ状況で異なるパターンを試す
   - [ ] 統計的有意差検定

2. **パターンの進化**
   - [ ] 低スコアパターンの削除
   - [ ] 高スコアパターンの強化

3. **レポート生成**
   - [ ] 週次レポート
   - [ ] 月次レポート

---

## 期待される効果

### 1. ユーザー体験の向上

**Before（現状）**:
```
ユーザー: 「バカじゃないの？」
Bot: 「ひどい！」or ブロック
→ ユーザー離脱率 60%
```

**After（プロレス学習後）**:
```
ユーザー: 「バカじゃないの？」
Bot: 「え、バカって褒め言葉？照れるじゃん！」
→ ユーザー継続率 80%
→ プロレス発展率 50%
```

### 2. センシティブ判定の精度向上

- **誤検知率**: 30% → 10%
- **じゃれ合い正解率**: 40% → 85%

### 3. キャラクター個性の強化

三姉妹それぞれの「プロレススタイル」が確立：

- **牡丹**: ギャル風の明るいボケ返し
- **花相**: 冷静なツッコミ型カウンター
- **百合**: 天然ボケで流す

### 4. コミュニティの活性化

- ユーザー間で「プロレス」が話題に
- 「この切り返し面白かった」というシェア
- VTuber文化との親和性

### 5. コスト効率

- **VPS（gpt-4o）**: 本番会話のみ
- **ローカル（Ollama）**: 学習・検証用
- トータルコスト削減 50%

---

## 付録A: 用語集

| 用語 | 定義 |
|------|------|
| **プロレス** | 信頼関係を土台にしたエンタメ的じゃれ合い |
| **反実仮想学習** | 「もしこうしていたら」を評価して学ぶ手法 |
| **Layer 4** | LLMによる文脈判定レイヤー |
| **プロレス受け** | じゃれ合いとして受け止める応答 |
| **流し** | ユーモアで軽く流す応答 |
| **カウンター** | 逆に質問して能動性を引き出す応答 |
| **離脱** | ユーザーが会話を終了すること |
| **成功率** | ユーザーが会話を継続した割合 |

---

## 付録B: 参考文献

- [AI VTuber設計思想「AiDA-AiTE」〜プロレス文化から学ぶ、愛あるじゃれ合いの実装〜](https://qiita.com/koshikawa-masato/items/cbbb08a3e96da807f88c)
- 強化学習における反実仮想評価（Counterfactual Evaluation）
- VTuber文化とコミュニケーション論

---

**🤖 Generated with Claude Code**

**Co-Authored-By**: Claude <noreply@anthropic.com>

---

## 法的・倫理的配慮

### クローズドテスト環境の利点

本システムは**LINE Bot（1対1のクローズド環境）** で運用されることで、以下の法的・倫理的メリットを享受できます。

#### 1. クローズド環境の特性

```
公開SNS（Twitter/YouTube等）:
  - 会話が公開される
  - 炎上リスクが高い
  - 実験的機能のテストが困難

LINE Bot（1対1）:
  ✅ 会話が非公開
  ✅ テスト参加は任意
  ✅ 実験的機能の安全なテスト
  ✅ 炎上リスクの最小化
```

#### 2. テスト運用としての免責

**明示的な告知により免責が成立**:

1. **AIによる自動応答であることを明示**
   - 「不本意な内容を含む可能性」を事前告知
   - ユーザーの理解・同意を前提

2. **テスト版であることを明示**
   - 研究開発段階
   - 品質保証なし
   - 予告なく変更・停止の可能性

3. **開発者の意図ではないことを明示**
   - AI応答は開発者の意見ではない
   - 自動生成によるもの

**リッチメニューでの告知**:
```
┌─────────────────────┐
│  牡丹  │  花相  │  百合  │
├─────────────────────┤
│  使用上の注意 ⚠️      │  ← ここに規約リンク
└─────────────────────┘
```

#### 3. 会話ログ記録の適法性

**記録の目的を明示**:

✅ **サービス品質向上**
- AIモデルの学習・改善
- エラー分析・デバッグ

✅ **セキュリティ対策**
- 不正利用の検出・防止
- 法的義務への対応

✅ **研究開発**
- AI技術の研究
- 会話パターンの分析

**個人情報保護**:
- LINE IDは匿名化されたユーザーIDのみ
- 氏名、電話番号等の個人情報は収集しない
- 会話ログは暗号化して保管

#### 4. 情報開示の可能性

**法的対応の明示**:

以下の場合、記録された会話ログを開示する可能性があることを事前告知：

1. **法令に基づく開示請求**
   - 裁判所の命令
   - 警察等の捜査機関からの正式な要請

2. **名誉毀損・権利侵害**
   - 第三者の名誉を毀損する内容
   - 著作権・商標権等の侵害
   - ハラスメント・脅迫行為

3. **犯罪行為の疑い**
   - 犯罪予告
   - 違法行為の助長

**抑止効果**:
- 不適切な利用の防止
- 健全なコミュニティ形成

#### 5. データ保管・削除ポリシー

**保管期間**:
- 会話ログ: 最大1年間
- その後、匿名化処理
- 統計データとしてのみ利用

**削除権**:
- ユーザーからの削除依頼に対応
- 個人を特定できる情報の完全削除

### プロレス学習における倫理的配慮

#### 1. 反実仮想学習の透明性

**何を学習しているか**:
- ユーザーが離脱した会話パターン
- 「もしこう言っていたら」の仮想シナリオ
- プロレス（じゃれ合い）の成功パターン

**学習データの扱い**:
- 匿名化された会話データのみ使用
- 個人を特定できる情報は含まない
- 統計的なパターン抽出

#### 2. AIの偏り（Bias）への対策

**問題**:
- 特定のユーザーの好みに過度に最適化
- 不適切なパターンの強化

**対策**:
1. **多様性の確保**
   - 複数ユーザーのデータを総合
   - キャラクター別の個性維持

2. **センシティブ判定の維持**
   - プロレスパターンもLayer 1-5を通過
   - 不適切な応答は自動排除

3. **人間によるレビュー**
   - 定期的なパターンレビュー
   - 問題パターンの手動削除

#### 3. ユーザーの同意

**オプトイン方式**:
- サービス利用=規約同意
- リッチメニューでいつでも確認可能
- 利用停止も自由

**透明性の確保**:
- システムの仕組みを公開（オープンソース化予定）
- GitHubでの開発プロセス公開
- ドキュメントの充実

### 法的リスクの最小化

#### リスクマトリクス

| リスク | 発生確率 | 影響度 | 対策 | 残存リスク |
|--------|----------|--------|------|-----------|
| 不適切な応答 | 中 | 中 | Layer 1-5フィルタ | 低 |
| ユーザークレーム | 低 | 低 | 免責事項・テスト告知 | 極低 |
| 情報漏洩 | 低 | 高 | 暗号化・アクセス制限 | 低 |
| 炎上 | 極低 | 中 | クローズド環境 | 極低 |
| 法的責任追及 | 極低 | 高 | 利用規約・免責 | 極低 |

#### 対応フロー

```
問題発生
    ↓
[即座の対応]
1. 該当ユーザーへ謝罪
2. 問題パターンの削除
3. システムの一時停止（必要に応じて）
    ↓
[原因分析]
4. ログの確認
5. フィルタリングの見直し
    ↓
[再発防止]
6. センシティブ判定の強化
7. プロレスパターンDBの修正
8. ドキュメントの更新
    ↓
[報告]
9. GitHubでの公開（適宜）
10. テスターへの周知
```

### 研究倫理ガイドライン準拠

本プロジェクトは、以下のガイドラインに準拠します：

#### 1. 人を対象とする研究

**研究目的**:
- AI技術の発展
- VTuberコミュニケーションの研究

**倫理原則**:
- インフォームドコンセント（規約同意）
- プライバシー保護
- 参加の任意性
- 撤回の自由

#### 2. データの取り扱い

**収集データ**:
- 最小限の情報のみ
- 匿名化処理
- 暗号化保管

**利用目的の限定**:
- AIモデルの学習・改善のみ
- 第三者への提供なし（法令除く）

#### 3. 研究成果の公開

**オープンソース化**:
- GitHubでのコード公開（予定）
- 技術論文の執筆（予定）
- Qiita記事での知見共有

**匿名性の保持**:
- 個人を特定できる情報は含めない
- 統計データのみ公開

### まとめ：クローズドテストの優位性

```
┌─────────────────────────────────────────┐
│   公開SNS：炎上リスク高、実験困難        │
└─────────────────────────────────────────┘
                    vs
┌─────────────────────────────────────────┐
│   LINE Bot：クローズド、テスト最適        │
│                                          │
│   ✅ 1対1の非公開会話                    │
│   ✅ テスト参加の明確化                  │
│   ✅ 免責事項の事前告知                  │
│   ✅ 情報開示ポリシーの明示              │
│   ✅ 炎上リスクの最小化                  │
│   ✅ 安全な実験環境                      │
│                                          │
│   → プロレス学習に最適な環境             │
└─────────────────────────────────────────┘
```

**本システムの法的・倫理的堅牢性**:

1. **透明性**: 規約・免責事項の明示
2. **同意**: オプトイン方式
3. **プライバシー**: 最小限のデータ収集
4. **安全性**: センシティブ判定5層構造
5. **説明責任**: 情報開示ポリシー
6. **クローズド環境**: 炎上リスク最小化

これらにより、安心してプロレス学習システムを運用できます。

---

**関連ドキュメント**:
- [牡丹プロジェクト_利用規約・免責事項](./牡丹プロジェクト_利用規約・免責事項.md)
