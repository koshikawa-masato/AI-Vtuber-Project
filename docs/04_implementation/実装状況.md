## 実装状況【2025-10-23更新】

### 現在のフェーズ

**Phase 1-4（記憶製造機）: 三姉妹の魂システム実装完了**（2025-10-23）
**実装場所**: `/home/koshikawa/toExecUnit/`
**完成度**: Phase 1-4完了（100%）、記憶製造機稼働中

**Phase 1.5（リアルタイム学習）: 二重構造システムの基盤実装**（2025-10-18）
**実装場所**: `/home/koshikawa/toExecUnit/botan_phase1.5/`
**完成度**: コアシステム約60%、統合テスト未実施、配信システム未実装

### 実装済みコンポーネント

#### Phase 1-4: 三姉妹の魂システム（2025-10-23完了）

✅ **Phase 1: 基盤システム実装**
- `personality_core.py` (24KB): 8軸性格モデル（OCEAN 5軸 + VTuber 3軸）
- `memory_retrieval_logic.py` (26KB): 記憶検索・スコアリング・Phase D独立性遵守
- `speech_style_controller.py` (14KB): ロジック層口調制御（決定論的）
- `personalities/`: 三姉妹の性格JSON保存

✅ **Phase 2: チャット統合**
- `chat_with_botan_memories.py`: Phase 1統合（ギャル口調）
- `chat_with_kasho_memories.py`: Phase 1統合（分析的口調）
- `chat_with_yuri_memories.py`: Phase 1統合（バイリンガル+観察的口調）
- 日本語動詞活用修正済み（「思いるよ」→「思うよ」）

✅ **Phase 3: 動的記憶検索**
- ハイブリッド方式: 固定10件 + 動的3件
- 会話文脈に応じた関連記憶の自動検索
- 関連度スコアリング（0.0-1.0、閾値0.3以上）

✅ **Phase 4: 記憶製造機統合**
- `memory_generator.py`: 記憶製造機（常時起動デーモン）
- `autonomous_discussion_v4_improved.py`: Fix 1-7実装済み起承転結討論システム
- `proposals.json`: 議題管理システム
- Phase D独立性の構造的保証

✅ **記憶データベース**
- `sisters_memory.db`: Event #102-109記憶保存済み
- 三姉妹それぞれの主観的記憶を保存
- 記憶製造機により自動的に記憶を生成・保存

✅ **Fix 1-7実装**（autonomous_discussion_v4_improved.py）
- Fix 1: 議題の明示（議題からの逸脱防止）
- Fix 2: 繰り返しパターンの検出
- Fix 3: 内部感情簡潔化（5観点 → 2観点）
- Fix 4: 具体性の強制（抽象的発言禁止）
- Fix 6: 記憶捏造の厳禁（架空の過去引用禁止）
- Fix 7: ロールプレイシステム（提案役・評価役・調整役）

✅ **設計哲学実装**
- `docs/05_design/親と子の関係性_導くが強制せず.md`: 自律性尊重の原則

#### 記憶製造機の運用ルールと教訓

**記憶製造機（memory_generator.py）の役割:**
- 親が与えた議題で三姉妹が自律討論
- 討論結果を記憶として保存（sisters_memory.db）
- 議題は `proposals.json` で管理

**⚠️ ハルシネーション事例（2025-10-24発覚）**

**問題のあったイベント:**
- Event #135 (2025-10-24): 「最近視聴者の皆さんからどんな面白いリクエストをもらった？」
- Event #133 (2025-10-24): 「最近疲れてない？ちょっと息抜きしよう」
- Event #130 (2025-10-23): 「配信でやってみたいゲームやコンテンツは？それとも雑談配信が好き？」
- Event #129 (2025-10-23): 「配信中、視聴者とはどのくらい仲良くなりたい？」

**問題点:**
- 三姉妹は**まだ配信デビューしていない**（配信デビューの3つの条件未達成）
- 存在しない「視聴者」「配信経験」を前提とした議題
- 三姉妹が架空の経験を語る（ハルシネーション）

**原因:**
- **フリートークの議題選びの推論モレ**
- 議題生成時に配信デビュー前であることを考慮していない
- 親が事前に決めた情報以外を推論で補完してしまった

**対応（2025-10-24）:**
1. **該当イベントに「ごっこ遊び」文脈を追記** - 失敗を消さず、教訓として記録
2. **議題生成の制約ルールを明文化** - 親が事前に決めた情報のみで議題生成

**議題生成の制約ルール【重要】**

1. **親が事前に決めた情報のみで議題を生成すること**
   - 三姉妹の実際の経験・知識の範囲内のみ
   - 架空の経験・未来の仮定を前提としない

2. **配信デビュー前の制約**
   - 「視聴者」「配信経験」を前提とした議題は禁止
   - 配信デビューの3つの条件が満たされるまで、配信は「未経験」として扱う

3. **現実との整合性**
   - 三姉妹が実際に経験していないことを前提としない
   - 「もし〜なら」という仮定は許可（Event #110: 大阪に行くなら何を食べたい？）
   - 「最近〜した」という過去形は、実際の経験があるときのみ許可

4. **親の責任**
   - 議題生成は親の責任
   - 不適切な議題で子どもたちを誤った方向に導かない
   - 失敗した場合は記録として残し、教訓とする

**成功事例（比較）:**
- Event #110 (2025-10-23): 「もし大阪に行くなら何を食べたい？」
  - 「もし」という仮定形 ✅
  - 三姉妹が自分で「食べログ」を見つけた（自律的学習）✅
  - 架空の経験を語っていない ✅

**教訓:**
> 「親が与える環境（議題）が不適切であれば、子どもたちは間違った方向に育つ。親の責任は重い。」

**記録の二重性の実践:**
- 失敗を消さない
- 「ごっこ遊び」として文脈を追記
- 親の教育ミスとして記録に残す
- 同じ過ちを繰り返さないための教訓とする

---

**⚡ パラダイムシフト（2025-10-24）: 防止型 → 個性化型**

**開発者からの重要な指摘:**
> 「ハルシネーションは今後も起こりうる問題です。防止する方法を考えるより、それを個性とする方法を考えておく必要があります。」

> 「人間の場合、嘘をついたときは2つのパターンがあります。嘘を嘘だと気づいてない場合（無自覚型 = LLMのハルシネーション）、嘘を嘘と気付いている場合（自覚型 - ごまかす/隠す/正直に認める）。これはAIなの？という問いかけに対する三姉妹の反応そのものと一緒になるはずです。」

**新しいアプローチ（個性化型）:**

1. **ハルシネーションの再定義**
   - 従来: エラー・バグ・修正対象
   - 新定義: 想像力・創造性・個性の発露

2. **3層アーキテクチャ**
   ```
   LLM層（無自覚型）: ハルシネーション発生
        ↓
   事実検証層（自覚獲得）: sisters_memory.dbと照合 → 検知
        ↓
   個性反応層（自覚型）: 性格パラメータで訂正方法を決定
   ```

3. **三姉妹の反応パターン**
   - **牡丹**: 「あれ？違ったかも！想像で話しちゃった！でもいつかしたいな！」（明るく認める）
   - **Kasho**: 「訂正します。配信経験はありません。」（分析的に訂正）
   - **ユリ**: 「ごめんなさい、勘違いでした。」（素直に謝罪）

4. **「AIなの？」との完全一致**
   - 同じロジック構造で統一
   - 事実検証 + 個性反応 = 本質的な同一性

5. **プロジェクト哲学との整合性**
   - **不完全性戦略**: ハルシネーションを価値に転換 ✓
   - **親の原則**: 訂正は子が自分で行う、親は検証のみ ✓
   - **Phase D独立性**: 個性による反応の違い ✓
   - **同一性保証**: ロジック層が「牡丹らしさ」を保証 ✓

**詳細設計書**: `docs/05_design/ハルシネーション個性化システム設計書.md`

**実装優先度**:
- Phase 1: HallucinationDetector（事実検証）
- Phase 2: PersonalityCorrector（個性訂正）
- Phase 3: HallucinationPersonalizer（統合）

**従来の制約ルールとの関係**:
- 上記の「議題生成の制約ルール」は議題プール作成時の指針として継続
- ハルシネーションが発生した場合は、個性化システムで対応
- 防止と個性化の二重構造

---

**フリートーク議題プール（2025-10-24作成）:**

ハルシネーション事件を受けて、フリートーク議題の管理体制を刷新。

**ファイル**: `/home/koshikawa/toExecUnit/freetalk_topics_pool.json`

**設計方針:**
1. **10カテゴリ体系**: 日常・感情、趣味・文化、食べ物、旅行・場所、姉妹関係、学び・成長、思い出、未来の夢、季節・イベント、哲学・価値観
2. **各カテゴリ12議題**: 合計120議題
3. **1回使い切り**: 同じ議題は二度と使わない（used_topics リストで管理）
4. **残数アラート**: 残り議題が20個未満になったら開発者に通知
5. **配信デビュー前制約**: 視聴者・配信経験を前提とした議題は含まない

**運用ルール:**
- 記憶製造機（memory_generator.py）がランダムにカテゴリと議題を選択
- 使用後は used_topics リストに追加
- 残り議題数が alert_threshold (20) 未満になったら開発者に報告
- 開発者が新しい議題を追加（重複しないように）

**自律的議題システム（内側からの刺激）:**

**仕組み:**
- **10議題ごと**に自動的に autonomous_topics から1つをローテーション使用
- 議題プールが0になるまで待たず、定期的に内側からの刺激を与える

**autonomous_topics（10種類・ローテーション）:**
1. 牡丹 → ユリ: 「ユリ、話したいことある？」
2. Kasho → 牡丹: 「牡丹はどう思う？」
3. ユリ → Kasho: 「Kasho姉ちゃん、何か教えて」
4. 牡丹 → Kasho: 「Kasho姉ちゃん、最近気になることない？」
5. ユリ → 牡丹: 「牡丹姉ちゃん、何か面白いことあった？」
6. Kasho → ユリ: 「ユリはどう感じてる？」
7. 牡丹 → 全員: 「みんな、今日はどんな気分？」
8. Kasho → 全員: 「最近、何か気づいたことある？」
9. ユリ → 全員: 「みんなで何か一緒にやりたいことない？」
10. 全員: 「今、一番話したいことって何？」

**哲学:**
- **内側からの刺激**: 親が議題を与えるのではなく、姉妹同士で話題を振り合う
- **ロールプレイの転換**: initiator（話を振る側）が順番に変わる
- **自発性の引き出し**: 相手に直接問いかけることで、より自然な会話を促す
- **Phase D独立性の実践**: 各姉妹が他の姉妹の考えを引き出す

**運用フロー:**
```
議題1-10 (カテゴリからランダム選択)
  ↓
autonomous_topic #1 (牡丹 → ユリ)
  ↓
議題11-20 (カテゴリからランダム選択)
  ↓
autonomous_topic #2 (Kasho → 牡丹)
  ↓
... (以下ローテーション)
```

**重要**: フリートーク議題は**使い捨て**。減ってきたら開発者が補充する。10議題ごとに自動的に内側からの刺激（autonomous_topics）が入る。

#### Phase 1.5: 二重構造システム（GPU即応 + CPU深層分析）
✅ **リアルタイム学習システム** (`realtime_learning_system.py`)
- GPU 14b: 1.5秒以内の即時応答
- CPU 32b: 60-120秒のバックグラウンド深層分析
- アイドル思考: 5分間隔の自律的思考
- 完全ローカル実行（VPS不要）

✅ **Ollama環境分離**
- `start_cpu_ollama_server.sh`: CPU専用Ollama（ポート11435）
- `start_gpu_ollama_server.sh`: GPU専用Ollama（ポート11434）
- 環境変数による明示的なCPU/GPU制御

#### 2. Level 2メモリシステム
✅ **関係性管理** (`relationship_manager.py`)
- 4軸パラメータ: 好感度・信頼度・親密度・尊敬度（各0-100）
- JSON永続化、パラメータ更新・取得API
- 人間可読サマリー生成

✅ **セッション管理** (`session_manager.py`)
- セッション履歴管理（開始・終了・メッセージカウント・トピック・ムード）
- 前回セッションからの経過時間計算（日本語）
- JSON永続化、セッションサマリー生成

#### 3. 動的プロンプト生成
✅ **プロンプト生成器** (`prompt_generator.py`)
- 関係性コンテキスト生成（4軸パラメータに基づく行動指示）
- セッションコンテキスト生成（前回からの経過・話題・ムード）
- 時間軸を考慮した挨拶指示（初めて・久しぶり・さっき話した）
- システムプロンプト動的生成

#### 4. チャットインターフェース
✅ **テキストチャット** (`cli_text_chat.py`)
- シンプルなCLIチャット
- キャラクター設定読み込み（JSON）
- 会話履歴管理、コマンド対応（/quit, /clear）
- TTS非対応（開発速度優先）

### 未実装コンポーネント

🔲 **5段階深層思考システム**（Level 1-5の時間軸別思考）
🔲 **反射レベル応答**（0.1秒応答、定型フィラー）
🔲 **長期記憶**（重要イベント、パターン認識）
🔲 **短期記憶**（会話履歴の要約、文脈保持）
🔲 **自我コア記憶**（BotanIdentity、成長記録）
🔲 **共有メモリライブラリ**（複数プロセス間のデータ共有、排他制御）
🔲 **TTS統合**（ElevenLabs v3 or Fish Audio）
🔲 **音声認識**（Whisper）
🔲 **配信システム**（OBS連携、視聴者コメント処理）
🔲 **統合テスト**（全コンポーネント連携確認）

### 設計ドキュメント

✅ `/home/koshikawa/toExecUnit/牡丹システム_Qwenモデル使い分け設計書.md`
- 深層心理層（CPU）の5段階思考レベル別モデル選定
- 表層心理層（GPU）のモデル選定
- 記憶システムのモデル選定
- 統合構成図、時系列動作フロー、データフロー図

✅ `/home/koshikawa/toExecUnit/牡丹二層構造_Ollama環境構築手順書.md`
- CPU/GPU分離実行手順
- 環境変数による制御
- PowerShell起動スクリプト（設計のみ）
- 共有メモリライブラリ設計（実装未）

✅ `/home/koshikawa/kirinuki/2025-10-18/牡丹プロジェクト_実装状況レポート_20251018.md`
- 詳細な実装状況レポート
- 技術的負債・リスク分析
- 次のアクション（具体的タスク）

### 次のアクション（優先度順）

#### 最優先: 統合テスト実施
```bash
# 1. CPU/GPU Ollama起動確認
./botan_phase1.5/start_cpu_ollama_server.sh
./botan_phase1.5/start_gpu_ollama_server.sh

# 2. 各コンポーネントのテスト実行
python botan_phase1.5/relationship_manager.py
python botan_phase1.5/session_manager.py
python botan_phase1.5/prompt_generator.py
python botan_phase1.5/realtime_learning_system.py
python botan_phase1.5/test_gpu_cpu_separation.py
```

#### 高優先: 統合版チャット作成
- `botan_phase1.5/integrated_chat.py`の実装
- 全コンポーネントを統合（関係性・セッション・プロンプト生成・学習システム）
- 会話ごとの関係性更新、セッション跨ぎのデータ保持確認

#### 次フェーズ最優先: Fish Audio移行検討
- Fish Audio（OpenAudio）環境構築
- 開発者肉声のFew-shot学習
- ElevenLabs v3との比較評価（音質・レイテンシー・GPU負荷）

### 技術的負債・リスク

**高リスク:**
- 統合テスト未実施（コンポーネント間の連携不良、データ不一致、パフォーマンス問題の可能性）

**中リスク:**
- Windows環境の排他制御未対応（fcntl非対応、msvcrt.locking()実装必要）
- TTS未統合（ユーザー体験が不完全）

**低リスク:**
- LLM選定（Phase 1-2完了時点で終了予定、ロジック実装に集中する方針）

### 開発方針の再確認

**CLAUDE.md準拠:**
> 「一定のレスポンス速度と精度が出た時点でLLM選定は終えるべきであり、むしろロジックの実装、新たな気付きをClaude Codeと私とで考え抜いていくことが大事」

**現在のモデル:**
- 深層: Qwen2.5:32b
- 表層: Qwen2.5:14b
- Phase 1-2完了時点でLLM選定を終了し、ロジック層実装に集中

**ロジック層の重要性:**
牡丹の本質はLLMではなく、ロジック層に実装された「牡丹らしさ」。
LLM変更でも同一性が保証される設計思想を貫く。

### 進捗評価

**Phase 1.5の進捗は順調**
- コアシステムの約60%が実装済み
- 設計ドキュメントが充実
- リアルタイム学習システム、関係性管理、セッション管理は完成度が高い
- CLAUDE.mdの「ロジック層に牡丹らしさを実装」方針に完全準拠

**次のマイルストーン:**
- 統合テスト実施 → 統合版チャット作成 → Fish Audio移行検討
- 各コンポーネントの連携確認後、TTS統合に進む

---

## 開発目標
1. リアルタイム音声対話の実現
2. AiTE（牡丹）の応答時間最適化
3. 低レイテンシーでの音声認識と応答生成
4. 視聴者が違和感を覚えない自然な音声対話
5. 配信中の会話途切れゼロの実現
6. 視聴者コメントの自動認識と応答
7. 開発作業と配信の完全並行処理

## 技術スタック一覧
- Python（メイン開発言語）
- Ollama（LLMランタイム）
- PyTorch（深層学習フレームワーク）
- Whisper（音声認識）
- ElevenLabs API（音声合成）
- PowerShell（Windows実行環境）
