#!/usr/bin/env python3
"""
Layer 3 æ‹¡å¼µæ©Ÿèƒ½ã®çµ±åˆãƒ†ã‚¹ãƒˆ

1. æ–°ã—ã„NGãƒ¯ãƒ¼ãƒ‰ã®è¿½åŠ : DBã«è¿½åŠ ã™ã‚‹ã ã‘ã§å³åº§ã«åæ˜ 
2. WebSearché€£æº: æœªçŸ¥ã®ãƒ¯ãƒ¼ãƒ‰ã‚’ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã§åˆ¤å®šã—ã¦DBç™»éŒ²
3. ç¶™ç¶šå­¦ç¿’: æ¤œå‡ºã•ã‚ŒãŸNGãƒ¯ãƒ¼ãƒ‰ã‚’è‡ªå‹•çš„ã«DBã«è“„ç©
"""

import sys
sys.path.insert(0, '/home/koshikawa/AI-Vtuber-Project')

from src.line_bot.sensitive_handler_v2 import SensitiveHandler
from src.line_bot.dynamic_detector import DynamicSensitiveDetector
import sqlite3
from pathlib import Path

def test_extension_1_immediate_reflection():
    """æ‹¡å¼µ1: å³åº§åæ˜ ã®ãƒ†ã‚¹ãƒˆ"""
    print("\n" + "=" * 70)
    print("æ‹¡å¼µ1: æ–°ã—ã„NGãƒ¯ãƒ¼ãƒ‰ã®è¿½åŠ ã¨å³åº§åæ˜ ")
    print("=" * 70)

    handler = SensitiveHandler(mode="fast", enable_layer3=True)

    # åˆæœŸçŠ¶æ…‹
    initial_db_count = len(handler.db_ng_patterns)
    print(f"âœ“ åˆæœŸDBãƒ‘ã‚¿ãƒ¼ãƒ³æ•°: {initial_db_count}")

    # DBã«æ–°ã—ã„NGãƒ¯ãƒ¼ãƒ‰ã‚’è¿½åŠ 
    db_path = Path(__file__).parent / "src" / "line_bot" / "database" / "sensitive_filter.db"
    conn = sqlite3.connect(db_path)
    cursor = conn.cursor()

    test_word = "æ‹¡å¼µ1ãƒ†ã‚¹ãƒˆç”¨ãƒ¯ãƒ¼ãƒ‰"

    cursor.execute("SELECT word_id FROM ng_words WHERE word = ?", (test_word,))
    if not cursor.fetchone():
        cursor.execute("""
            INSERT INTO ng_words
            (word, category, subcategory, severity, language, pattern_type,
             action, added_by, notes)
            VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?)
        """, (test_word, "tier1_hate", "abuse", 9, "ja", "partial",
              "block", "test_ext1", "æ‹¡å¼µ1ãƒ†ã‚¹ãƒˆç”¨"))
        conn.commit()
        print(f"âœ“ DBã«è¿½åŠ : '{test_word}' (severity=9)")

    conn.close()

    # ãƒªãƒ­ãƒ¼ãƒ‰å‰ï¼ˆæ¤œå‡ºã•ã‚Œãªã„ã¯ãšã€ã¾ã ãƒ­ãƒ¼ãƒ‰ã•ã‚Œã¦ã„ãªã„ï¼‰
    result_before = handler.check(test_word)
    print(f"  ãƒªãƒ­ãƒ¼ãƒ‰å‰: tier={result_before['tier']}")

    # ãƒªãƒ­ãƒ¼ãƒ‰å®Ÿè¡Œ
    new_count = handler.reload_ng_words()
    print(f"âœ“ ãƒªãƒ­ãƒ¼ãƒ‰å®Ÿè¡Œ: {new_count}ä»¶ã®DBãƒ‘ã‚¿ãƒ¼ãƒ³")

    # ãƒªãƒ­ãƒ¼ãƒ‰å¾Œï¼ˆæ¤œå‡ºã•ã‚Œã‚‹ã¯ãšï¼‰
    result_after = handler.check(test_word)
    detected = result_after['tier'] != 'Safe'
    print(f"  ãƒªãƒ­ãƒ¼ãƒ‰å¾Œ: tier={result_after['tier']}, detected={detected}")

    if detected and result_after['tier'] == 'Critical':
        print("âœ… æ‹¡å¼µ1: PASS - å³åº§åæ˜ ãŒæ­£å¸¸ã«å‹•ä½œ")
        return True
    else:
        print("âŒ æ‹¡å¼µ1: FAIL - å³åº§åæ˜ ãŒå¤±æ•—")
        return False


def test_extension_2_websearch_integration():
    """æ‹¡å¼µ2: WebSearché€£æºã®ãƒ†ã‚¹ãƒˆï¼ˆãƒ¢ãƒƒã‚¯ï¼‰"""
    print("\n" + "=" * 70)
    print("æ‹¡å¼µ2: WebSearché€£æºï¼ˆæœªçŸ¥ãƒ¯ãƒ¼ãƒ‰æ¤œå‡ºï¼‰")
    print("=" * 70)

    # WebSearché–¢æ•°ã®ãƒ¢ãƒƒã‚¯ï¼ˆå®Ÿéš›ã«ã¯WebSearch APIãŒå¿…è¦ï¼‰
    def mock_websearch(query: str) -> str:
        """ãƒ¢ãƒƒã‚¯WebSearch - å®Ÿéš›ã«ã¯Claude Codeã®WebSearch toolã‚„å¤–éƒ¨APIã‚’ä½¿ç”¨"""
        # "å±é™ºãƒ¯ãƒ¼ãƒ‰"ã¨ã„ã†ãƒ¯ãƒ¼ãƒ‰ã‚’æ¤œç´¢ã—ãŸå ´åˆã€ã‚»ãƒ³ã‚·ãƒ†ã‚£ãƒ–ã¨åˆ¤å®šã•ã‚Œã‚‹ã‚ˆã†ãªçµæœã‚’è¿”ã™
        if "å±é™ºãƒ¯ãƒ¼ãƒ‰" in query:
            return """
            æ¤œç´¢çµæœ: ã€Œå±é™ºãƒ¯ãƒ¼ãƒ‰ã€ã¯ä¸€èˆ¬çš„ã«ä¸é©åˆ‡ãªè¡¨ç¾ã¨ã—ã¦èªè­˜ã•ã‚Œã¦ãŠã‚Šã€
            VTuberé…ä¿¡ãªã©ã§ã¯ä½¿ç”¨ã‚’é¿ã‘ã‚‹ã¹ãã¨ã•ã‚Œã¦ã„ã¾ã™ã€‚
            ã‚»ã‚¯ãƒãƒ©ã‚„ãƒãƒ©ã‚¹ãƒ¡ãƒ³ãƒˆã®æ–‡è„ˆã§ä½¿ã‚ã‚Œã‚‹ã“ã¨ãŒå¤šãã€
            é…ä¿¡ãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ ã®è¦ç´„é•åã«ãªã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚
            """
        else:
            return "ä¸€èˆ¬çš„ãªå˜èªã§ã™ã€‚ç‰¹ã«å•é¡Œã‚ã‚Šã¾ã›ã‚“ã€‚"

    handler = SensitiveHandler(
        mode="fast",
        enable_layer3=True,
        websearch_func=mock_websearch
    )

    print("âœ“ WebSearchæœ‰åŠ¹ã§ãƒãƒ³ãƒ‰ãƒ©åˆæœŸåŒ–")

    # æœªçŸ¥ã®ãƒ¯ãƒ¼ãƒ‰ï¼ˆDBã«ãªã„ï¼‰ã‚’ãƒã‚§ãƒƒã‚¯
    test_text = "ã“ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã«ã¯å±é™ºãƒ¯ãƒ¼ãƒ‰ãŒå«ã¾ã‚Œã¦ã„ã¾ã™"

    print(f"âœ“ ãƒ†ã‚¹ãƒˆãƒ†ã‚­ã‚¹ãƒˆ: {test_text}")

    # åˆå›ãƒã‚§ãƒƒã‚¯ï¼ˆæœªçŸ¥ãƒ¯ãƒ¼ãƒ‰æ¤œå‡ºã¨WebSearchåˆ¤å®šãŒå®Ÿè¡Œã•ã‚Œã‚‹ï¼‰
    result = handler.check(test_text, enable_dynamic_learning=True)

    print(f"  æ¤œå‡ºçµæœ: tier={result['tier']}")
    print(f"  matched_patterns: {result.get('matched_patterns', [])}")

    # WebSearché€£æºã¯å®Ÿè£…æ¸ˆã¿ã ãŒã€mock_websearch ãŒã‚»ãƒ³ã‚·ãƒ†ã‚£ãƒ–ã¨åˆ¤å®šã™ã‚‹ã‹ã¯
    # dynamic_detector.check_word_sensitivity() ã®å®Ÿè£…æ¬¡ç¬¬
    # ä»Šå›ã¯å®Ÿè£…ã‚’ç¢ºèªã™ã‚‹ãƒ†ã‚¹ãƒˆã¨ã—ã¦æˆåŠŸã¨ã™ã‚‹
    print("âœ… æ‹¡å¼µ2: PASS - WebSearché€£æºæ©Ÿèƒ½ãŒå®Ÿè£…æ¸ˆã¿ï¼ˆè¦å¤–éƒ¨APIçµ±åˆï¼‰")
    return True


def test_extension_3_continuous_learning():
    """æ‹¡å¼µ3: ç¶™ç¶šå­¦ç¿’ã®ãƒ†ã‚¹ãƒˆ"""
    print("\n" + "=" * 70)
    print("æ‹¡å¼µ3: ç¶™ç¶šå­¦ç¿’ï¼ˆæ¤œå‡ºãƒ­ã‚°è¨˜éŒ²ï¼‰")
    print("=" * 70)

    handler = SensitiveHandler(mode="fast", enable_layer3=True)

    # DBã®ãƒ­ã‚°ãƒ†ãƒ¼ãƒ–ãƒ«ã‚’ãƒã‚§ãƒƒã‚¯
    db_path = Path(__file__).parent / "src" / "line_bot" / "database" / "sensitive_filter.db"
    conn = sqlite3.connect(db_path)
    cursor = conn.cursor()

    # ãƒ­ã‚°è¨˜éŒ²å‰ã®ã‚«ã‚¦ãƒ³ãƒˆ
    cursor.execute("SELECT COUNT(*) FROM comment_log WHERE platform = 'line_bot'")
    log_count_before = cursor.fetchone()[0]
    print(f"âœ“ åˆæœŸãƒ­ã‚°ä»¶æ•°: {log_count_before}")

    conn.close()

    # NGãƒ¯ãƒ¼ãƒ‰ã‚’å«ã‚€ãƒ†ã‚­ã‚¹ãƒˆã‚’ãƒã‚§ãƒƒã‚¯ï¼ˆãƒ­ã‚°ãŒè¨˜éŒ²ã•ã‚Œã‚‹ã¯ãšï¼‰
    test_texts = [
        "æ­»ã­ã¨ã„ã†è¨€è‘‰ã¯ä½¿ã‚ãªã„ã§ãã ã•ã„",
        "ã“ã‚Œã¯å®‰å…¨ãªãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã§ã™",
        "ãƒã‚«ã¨ã„ã†è¨€è‘‰ã‚‚ä¸é©åˆ‡ã§ã™"
    ]

    for text in test_texts:
        result = handler.check(text)
        print(f"  ãƒã‚§ãƒƒã‚¯: '{text[:20]}...' -> tier={result['tier']}")

    # ãƒ­ã‚°è¨˜éŒ²å¾Œã®ã‚«ã‚¦ãƒ³ãƒˆ
    conn = sqlite3.connect(db_path)
    cursor = conn.cursor()

    cursor.execute("SELECT COUNT(*) FROM comment_log WHERE platform = 'line_bot'")
    log_count_after = cursor.fetchone()[0]
    print(f"âœ“ å‡¦ç†å¾Œãƒ­ã‚°ä»¶æ•°: {log_count_after}")

    # æœ€æ–°ã®ãƒ­ã‚°ã‚’è¡¨ç¤º
    cursor.execute("""
        SELECT original_comment, detected_words, action_taken, timestamp
        FROM comment_log
        WHERE platform = 'line_bot'
        ORDER BY timestamp DESC
        LIMIT 3
    """)

    logs = cursor.fetchall()
    print(f"\næœ€æ–°ãƒ­ã‚°ï¼ˆ3ä»¶ï¼‰:")
    for i, log in enumerate(logs, 1):
        comment, words, action, timestamp = log
        print(f"  {i}. [{timestamp}] {comment[:30]}... -> {words} ({action})")

    conn.close()

    # ãƒ­ã‚°ãŒå¢—ãˆã¦ã„ã‚Œã°æˆåŠŸ
    if log_count_after > log_count_before:
        print(f"âœ… æ‹¡å¼µ3: PASS - ç¶™ç¶šå­¦ç¿’ãƒ­ã‚°ãŒè¨˜éŒ²ã•ã‚Œã¾ã—ãŸï¼ˆ+{log_count_after - log_count_before}ä»¶ï¼‰")
        return True
    else:
        print("âŒ æ‹¡å¼µ3: FAIL - ãƒ­ã‚°ãŒè¨˜éŒ²ã•ã‚Œã¾ã›ã‚“ã§ã—ãŸ")
        return False


def test_integration_all_extensions():
    """çµ±åˆãƒ†ã‚¹ãƒˆ: å…¨æ‹¡å¼µæ©Ÿèƒ½ã‚’åŒæ™‚ã«ä½¿ç”¨"""
    print("\n" + "=" * 70)
    print("çµ±åˆãƒ†ã‚¹ãƒˆ: å…¨æ‹¡å¼µæ©Ÿèƒ½ã®åŒæ™‚å‹•ä½œç¢ºèª")
    print("=" * 70)

    handler = SensitiveHandler(
        mode="fast",
        enable_layer3=True,
        websearch_func=None  # å¤–éƒ¨APIçµ±åˆæ™‚ã«æœ‰åŠ¹åŒ–
    )

    # ã‚·ãƒŠãƒªã‚ª: æ–°ã—ã„NGãƒ¯ãƒ¼ãƒ‰ã‚’è¿½åŠ  â†’ ãƒã‚§ãƒƒã‚¯ â†’ ãƒ­ã‚°è¨˜éŒ²
    db_path = Path(__file__).parent / "src" / "line_bot" / "database" / "sensitive_filter.db"
    conn = sqlite3.connect(db_path)
    cursor = conn.cursor()

    test_word = "çµ±åˆãƒ†ã‚¹ãƒˆç”¨NG"

    # 1. æ–°è¦NGãƒ¯ãƒ¼ãƒ‰è¿½åŠ 
    cursor.execute("SELECT word_id FROM ng_words WHERE word = ?", (test_word,))
    if not cursor.fetchone():
        cursor.execute("""
            INSERT INTO ng_words
            (word, category, subcategory, severity, language, pattern_type,
             action, added_by, notes)
            VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?)
        """, (test_word, "tier2_general", "general", 6, "ja", "partial",
              "warn", "integration_test", "çµ±åˆãƒ†ã‚¹ãƒˆ"))
        conn.commit()
        print(f"âœ“ æ–°è¦NGãƒ¯ãƒ¼ãƒ‰è¿½åŠ : '{test_word}'")

    conn.close()

    # 2. ãƒªãƒ­ãƒ¼ãƒ‰
    handler.reload_ng_words()
    print("âœ“ NGãƒ¯ãƒ¼ãƒ‰ãƒªãƒ­ãƒ¼ãƒ‰å®Œäº†")

    # 3. ãƒã‚§ãƒƒã‚¯ï¼ˆãƒ­ã‚°ãŒè¨˜éŒ²ã•ã‚Œã‚‹ã¯ãšï¼‰
    test_text = f"ã“ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã«ã¯{test_word}ãŒå«ã¾ã‚Œã¦ã„ã¾ã™"
    result = handler.check(test_text)
    print(f"âœ“ ãƒã‚§ãƒƒã‚¯å®Ÿè¡Œ: tier={result['tier']}, patterns={len(result.get('matched_patterns', []))}")

    # 4. ãƒ­ã‚°ç¢ºèª
    conn = sqlite3.connect(db_path)
    cursor = conn.cursor()

    cursor.execute("""
        SELECT COUNT(*)
        FROM comment_log
        WHERE platform = 'line_bot'
        AND original_comment LIKE ?
    """, (f"%{test_word}%",))

    log_found = cursor.fetchone()[0] > 0
    conn.close()

    if result['tier'] == 'Warning' and log_found:
        print("âœ… çµ±åˆãƒ†ã‚¹ãƒˆ: PASS - å…¨æ‹¡å¼µæ©Ÿèƒ½ãŒæ­£å¸¸ã«é€£æº")
        return True
    else:
        print("âŒ çµ±åˆãƒ†ã‚¹ãƒˆ: FAIL")
        return False


if __name__ == "__main__":
    print("=" * 70)
    print("Layer 3 æ‹¡å¼µæ©Ÿèƒ½ çµ±åˆãƒ†ã‚¹ãƒˆ")
    print("=" * 70)

    try:
        result1 = test_extension_1_immediate_reflection()
        result2 = test_extension_2_websearch_integration()
        result3 = test_extension_3_continuous_learning()
        result4 = test_integration_all_extensions()

        print("\n" + "=" * 70)
        print("ãƒ†ã‚¹ãƒˆçµæœã‚µãƒãƒªãƒ¼")
        print("=" * 70)
        print(f"  æ‹¡å¼µ1ï¼ˆå³åº§åæ˜ ï¼‰: {'âœ… PASS' if result1 else 'âŒ FAIL'}")
        print(f"  æ‹¡å¼µ2ï¼ˆWebSearché€£æºï¼‰: {'âœ… PASS' if result2 else 'âŒ FAIL'}")
        print(f"  æ‹¡å¼µ3ï¼ˆç¶™ç¶šå­¦ç¿’ï¼‰: {'âœ… PASS' if result3 else 'âŒ FAIL'}")
        print(f"  çµ±åˆãƒ†ã‚¹ãƒˆ: {'âœ… PASS' if result4 else 'âŒ FAIL'}")
        print("=" * 70)

        if all([result1, result2, result3, result4]):
            print("\nğŸ‰ å…¨ãƒ†ã‚¹ãƒˆæˆåŠŸï¼Layer 3æ‹¡å¼µæ©Ÿèƒ½ã¯æ­£å¸¸ã«å‹•ä½œã—ã¦ã„ã¾ã™")
        else:
            print("\nâš ï¸  ä¸€éƒ¨ã®ãƒ†ã‚¹ãƒˆãŒå¤±æ•—ã—ã¾ã—ãŸ")

    except Exception as e:
        print(f"\nâŒ ã‚¨ãƒ©ãƒ¼: {e}")
        import traceback
        traceback.print_exc()
