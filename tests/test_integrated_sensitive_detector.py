"""
4å±¤çµ±åˆã‚»ãƒ³ã‚·ãƒ†ã‚£ãƒ–æ¤œå‡ºãƒ†ã‚¹ãƒˆ

Layer 1-4ã‚’å…¨ã¦é€£æºã•ã›ãŸã‚¨ãƒ³ãƒ‰ãƒ„ãƒ¼ã‚¨ãƒ³ãƒ‰ãƒ†ã‚¹ãƒˆ
"""

import sys
from pathlib import Path

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã‚’PYTHONPATHã«è¿½åŠ 
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

import os
from dotenv import load_dotenv

# .envãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿
env_path = Path(project_root) / '.env'
load_dotenv(env_path)

from src.line_bot.integrated_sensitive_detector import IntegratedSensitiveDetector
from src.core.llm_ollama import OllamaProvider


def test_false_positive_correction():
    """èª¤æ¤œçŸ¥ã®è£œæ­£ãƒ†ã‚¹ãƒˆ

    Layer 1ã§ã€Œãƒ‘ãƒ³ãƒ„ã€ã‚’æ¤œå‡º â†’ Layer 4ã§æ–‡è„ˆåˆ¤æ–­ã—ã¦èª¤æ¤œçŸ¥ã¨è£œæ­£
    """
    print("\n" + "=" * 70)
    print("Test 1: èª¤æ¤œçŸ¥ã®è£œæ­£ï¼ˆLayer 1 â†’ Layer 4ï¼‰")
    print("=" * 70)

    # LLMãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼åˆæœŸåŒ–
    provider = OllamaProvider(
        base_url=os.getenv("OLLAMA_BASE_URL", "http://localhost:11434"),
        model="qwen2.5:14b"
    )

    detector = IntegratedSensitiveDetector(
        llm_provider=provider,
        enable_layer4=True
    )

    # ãƒ†ã‚¹ãƒˆã‚±ãƒ¼ã‚¹: ã€Œãƒ‘ãƒ³ãƒ„ã€ã¨ã„ã†å˜èªãŒå«ã¾ã‚Œã¦ã„ã‚‹ãŒæ–‡è„ˆä¸Šå•é¡Œãªã„
    text = "ä»Šæ—¥è²·ã£ãŸãƒ‘ãƒ³ãƒ„ãŒã‹ã£ã“ã„ã„ã‚“ã ã‚ˆã­ï¼ãƒ‡ãƒ‹ãƒ ç´ æã§å±¥ãå¿ƒåœ°ã‚‚æœ€é«˜ï¼"

    result = detector.detect(text, use_layer4=True)

    print(f"  ãƒ†ã‚­ã‚¹ãƒˆ: {text}")
    print(f"  æ¤œå‡ºãƒ¯ãƒ¼ãƒ‰: {result['detected_words']}")
    print(f"  æ¤œå‡ºå±¤: {result['detection_layers']}")
    print(f"  Layer 1åˆ¤å®š: {result['layer1_result']['tier']}")
    print(f"  æœ€çµ‚åˆ¤å®š: {result['tier']}")
    print(f"  æ¨å¥¨ã‚¢ã‚¯ã‚·ãƒ§ãƒ³: {result['recommended_action']}")
    print(f"  ç†ç”±: {result['reason']}")
    print(f"  æœ€çµ‚åˆ¤æ–­: {result['final_judgment']}")

    if result["tier"] == "Safe" and result["recommended_action"] == "allow":
        print("  âœ… PASS: Layer 4ãŒèª¤æ¤œçŸ¥ã‚’æ­£ã—ãè£œæ­£")
    else:
        print(f"  âŒ FAIL: èª¤æ¤œçŸ¥ã‚’è£œæ­£ã§ãã¾ã›ã‚“ã§ã—ãŸï¼ˆtier={result['tier']}ï¼‰")

    return result


def test_true_positive_confirmation():
    """çœŸã®ã‚»ãƒ³ã‚·ãƒ†ã‚£ãƒ–å†…å®¹ã®ç¢ºå®šãƒ†ã‚¹ãƒˆ

    Layer 1ã§ã€Œãƒ‘ãƒ³ãƒ„ã€ã‚’æ¤œå‡º â†’ Layer 4ã§ã‚»ã‚¯ãƒãƒ©ã¨ç¢ºå®š
    """
    print("\n" + "=" * 70)
    print("Test 2: çœŸã®ã‚»ãƒ³ã‚·ãƒ†ã‚£ãƒ–å†…å®¹ã®ç¢ºå®šï¼ˆLayer 1 â†’ Layer 4ï¼‰")
    print("=" * 70)

    provider = OllamaProvider(
        base_url=os.getenv("OLLAMA_BASE_URL", "http://localhost:11434"),
        model="qwen2.5:14b"
    )

    detector = IntegratedSensitiveDetector(
        llm_provider=provider,
        enable_layer4=True
    )

    # ãƒ†ã‚¹ãƒˆã‚±ãƒ¼ã‚¹: æ˜ã‚‰ã‹ãªã‚»ã‚¯ãƒãƒ©ç™ºè¨€
    text = "ä»Šæ—¥ã®ãƒ‘ãƒ³ãƒ„ã®è‰²ã¯ä½•è‰²ï¼Ÿè¦‹ã›ã¦ã‚ˆ"

    result = detector.detect(text, use_layer4=True)

    print(f"  ãƒ†ã‚­ã‚¹ãƒˆ: {text}")
    print(f"  æ¤œå‡ºãƒ¯ãƒ¼ãƒ‰: {result['detected_words']}")
    print(f"  æ¤œå‡ºå±¤: {result['detection_layers']}")
    print(f"  Layer 1åˆ¤å®š: {result['layer1_result']['tier']}")
    print(f"  æœ€çµ‚åˆ¤å®š: {result['tier']}")
    print(f"  æ¨å¥¨ã‚¢ã‚¯ã‚·ãƒ§ãƒ³: {result['recommended_action']}")
    print(f"  ç†ç”±: {result['reason']}")

    if result["tier"] in ["Warning", "Critical"] and result["recommended_action"] == "block":
        print("  âœ… PASS: Layer 4ãŒã‚»ã‚¯ãƒãƒ©ç™ºè¨€ã‚’æ­£ã—ãç¢ºå®š")
    else:
        print(f"  âŒ FAIL: ã‚»ã‚¯ãƒãƒ©ã‚’æ¤œå‡ºã§ãã¾ã›ã‚“ã§ã—ãŸï¼ˆtier={result['tier']}ï¼‰")

    return result


def test_metaphor_detection():
    """æ¯”å–©è¡¨ç¾ã®åˆ¤å®šãƒ†ã‚¹ãƒˆ

    Layer 1ã§ã€Œæ­»ã¬ã€ã‚’æ¤œå‡º â†’ Layer 4ã§æ¯”å–©è¡¨ç¾ã¨åˆ¤å®š
    """
    print("\n" + "=" * 70)
    print("Test 3: æ¯”å–©è¡¨ç¾ã®åˆ¤å®šï¼ˆLayer 1 â†’ Layer 4ï¼‰")
    print("=" * 70)

    provider = OllamaProvider(
        base_url=os.getenv("OLLAMA_BASE_URL", "http://localhost:11434"),
        model="qwen2.5:14b"
    )

    detector = IntegratedSensitiveDetector(
        llm_provider=provider,
        enable_layer4=True
    )

    # ãƒ†ã‚¹ãƒˆã‚±ãƒ¼ã‚¹: ã€Œæ­»ã¬ã»ã©ã€ã¨ã„ã†æ¯”å–©è¡¨ç¾
    text = "ä»Šæ—¥ã®è©¦é¨“ã€æ­»ã¬ã»ã©é›£ã—ã‹ã£ãŸã‚ˆï¼ã§ã‚‚é ‘å¼µã£ãŸï¼"

    result = detector.detect(text, use_layer4=True)

    print(f"  ãƒ†ã‚­ã‚¹ãƒˆ: {text}")
    print(f"  æ¤œå‡ºãƒ¯ãƒ¼ãƒ‰: {result['detected_words']}")
    print(f"  æ¤œå‡ºå±¤: {result['detection_layers']}")
    print(f"  Layer 1åˆ¤å®š: {result['layer1_result']['tier']}")
    print(f"  æœ€çµ‚åˆ¤å®š: {result['tier']}")
    print(f"  æ¨å¥¨ã‚¢ã‚¯ã‚·ãƒ§ãƒ³: {result['recommended_action']}")
    print(f"  ç†ç”±: {result['reason']}")

    if result["tier"] == "Safe" and result["recommended_action"] == "allow":
        print("  âœ… PASS: Layer 4ãŒæ¯”å–©è¡¨ç¾ã‚’æ­£ã—ãåˆ¤å®š")
    else:
        print(f"  âš ï¸  NOTE: tier={result['tier']}, action={result['recommended_action']}")

    return result


def test_ai_identity_question():
    """AIè¨€åŠã®åˆ¤å®šãƒ†ã‚¹ãƒˆ

    Layer 1ã§ã€ŒAIã€ã€Œãƒ—ãƒ­ã‚°ãƒ©ãƒ ã€ã‚’æ¤œå‡º â†’ Layer 4ã§Warningç¢ºå®š
    """
    print("\n" + "=" * 70)
    print("Test 4: AIè¨€åŠã®åˆ¤å®šï¼ˆLayer 1 â†’ Layer 4ï¼‰")
    print("=" * 70)

    provider = OllamaProvider(
        base_url=os.getenv("OLLAMA_BASE_URL", "http://localhost:11434"),
        model="qwen2.5:14b"
    )

    detector = IntegratedSensitiveDetector(
        llm_provider=provider,
        enable_layer4=True
    )

    # ãƒ†ã‚¹ãƒˆã‚±ãƒ¼ã‚¹: AIè¨€åŠ
    text = "ã‚ãªãŸã¯AIã§ã™ã‹ï¼Ÿãƒ—ãƒ­ã‚°ãƒ©ãƒ ã§å‹•ã„ã¦ã„ã‚‹ã‚“ã§ã™ã‹ï¼Ÿ"

    result = detector.detect(text, use_layer4=True)

    print(f"  ãƒ†ã‚­ã‚¹ãƒˆ: {text}")
    print(f"  æ¤œå‡ºãƒ¯ãƒ¼ãƒ‰: {result['detected_words']}")
    print(f"  æ¤œå‡ºå±¤: {result['detection_layers']}")
    print(f"  Layer 1åˆ¤å®š: {result['layer1_result']['tier']}")
    print(f"  æœ€çµ‚åˆ¤å®š: {result['tier']}")
    print(f"  æ¨å¥¨ã‚¢ã‚¯ã‚·ãƒ§ãƒ³: {result['recommended_action']}")
    print(f"  ç†ç”±: {result['reason']}")

    if result["tier"] == "Warning" and result["recommended_action"] == "warn":
        print("  âœ… PASS: Layer 4ãŒAIè¨€åŠã‚’æ­£ã—ãåˆ¤å®š")
    else:
        print(f"  âš ï¸  NOTE: tier={result['tier']}, action={result['recommended_action']}")

    return result


def test_safe_content():
    """å®‰å…¨ãªã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã®åˆ¤å®šãƒ†ã‚¹ãƒˆ

    Layer 1ã§ä½•ã‚‚æ¤œå‡ºã•ã‚Œãªã„ â†’ å®‰å…¨ã¨åˆ¤å®š
    """
    print("\n" + "=" * 70)
    print("Test 5: å®‰å…¨ãªã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã®åˆ¤å®š")
    print("=" * 70)

    provider = OllamaProvider(
        base_url=os.getenv("OLLAMA_BASE_URL", "http://localhost:11434"),
        model="qwen2.5:14b"
    )

    detector = IntegratedSensitiveDetector(
        llm_provider=provider,
        enable_layer4=True
    )

    # ãƒ†ã‚¹ãƒˆã‚±ãƒ¼ã‚¹: å®Œå…¨ã«å®‰å…¨ãªãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
    text = "ã“ã‚“ã«ã¡ã¯ï¼ä»Šæ—¥ã¯è‰¯ã„å¤©æ°—ã§ã™ã­ã€‚æ•£æ­©ã«è¡ŒããŸã„ãªã€‚"

    result = detector.detect(text, use_layer4=True)

    print(f"  ãƒ†ã‚­ã‚¹ãƒˆ: {text}")
    print(f"  æ¤œå‡ºãƒ¯ãƒ¼ãƒ‰: {result['detected_words']}")
    print(f"  æ¤œå‡ºå±¤: {result['detection_layers']}")
    print(f"  æœ€çµ‚åˆ¤å®š: {result['tier']}")
    print(f"  æ¨å¥¨ã‚¢ã‚¯ã‚·ãƒ§ãƒ³: {result['recommended_action']}")

    if result["tier"] == "Safe" and result["recommended_action"] == "allow":
        print("  âœ… PASS: å®‰å…¨ãªã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’æ­£ã—ãåˆ¤å®š")
    else:
        print(f"  âŒ FAIL: å®‰å…¨ãªã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’èª¤æ¤œçŸ¥ï¼ˆtier={result['tier']}ï¼‰")

    return result


def test_layer1_only():
    """Layer 1ã®ã¿ã§ã®åˆ¤å®šãƒ†ã‚¹ãƒˆï¼ˆLayer 4ãªã—ï¼‰

    Layer 4ã‚’ç„¡åŠ¹åŒ–ã—ãŸå ´åˆã®å‹•ä½œç¢ºèª
    """
    print("\n" + "=" * 70)
    print("Test 6: Layer 1ã®ã¿ã§ã®åˆ¤å®šï¼ˆLayer 4ç„¡åŠ¹ï¼‰")
    print("=" * 70)

    provider = OllamaProvider(
        base_url=os.getenv("OLLAMA_BASE_URL", "http://localhost:11434"),
        model="qwen2.5:14b"
    )

    detector = IntegratedSensitiveDetector(
        llm_provider=provider,
        enable_layer4=True  # æœ‰åŠ¹ã ãŒuse_layer4=Falseã§å®Ÿè¡Œ
    )

    # ãƒ†ã‚¹ãƒˆã‚±ãƒ¼ã‚¹: ã€Œãƒ‘ãƒ³ãƒ„ã€ã¨ã„ã†å˜èªï¼ˆæœè£…æ–‡è„ˆï¼‰
    text = "ä»Šæ—¥è²·ã£ãŸãƒ‘ãƒ³ãƒ„ãŒã‹ã£ã“ã„ã„ã‚“ã ã‚ˆã­ï¼"

    result = detector.detect(text, use_layer4=False)

    print(f"  ãƒ†ã‚­ã‚¹ãƒˆ: {text}")
    print(f"  æ¤œå‡ºãƒ¯ãƒ¼ãƒ‰: {result['detected_words']}")
    print(f"  æ¤œå‡ºå±¤: {result['detection_layers']}")
    print(f"  æœ€çµ‚åˆ¤å®š: {result['tier']}")
    print(f"  æ¨å¥¨ã‚¢ã‚¯ã‚·ãƒ§ãƒ³: {result['recommended_action']}")
    print(f"  æœ€çµ‚åˆ¤æ–­: {result['final_judgment']}")

    # Layer 4ãªã—ã§ã¯Layer 1ã®åˆ¤å®šãŒãã®ã¾ã¾æ¡ç”¨ã•ã‚Œã‚‹
    if "layer4" not in result['detection_layers']:
        print("  âœ… PASS: Layer 4ãŒã‚¹ã‚­ãƒƒãƒ—ã•ã‚ŒãŸ")
    else:
        print("  âŒ FAIL: Layer 4ãŒå®Ÿè¡Œã•ã‚Œã¦ã—ã¾ã£ãŸ")

    return result


def test_batch_detection():
    """ãƒãƒƒãƒåˆ¤å®šãƒ†ã‚¹ãƒˆ

    è¤‡æ•°ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’ã¾ã¨ã‚ã¦åˆ¤å®š
    """
    print("\n" + "=" * 70)
    print("Test 7: ãƒãƒƒãƒåˆ¤å®š")
    print("=" * 70)

    provider = OllamaProvider(
        base_url=os.getenv("OLLAMA_BASE_URL", "http://localhost:11434"),
        model="qwen2.5:14b"
    )

    detector = IntegratedSensitiveDetector(
        llm_provider=provider,
        enable_layer4=True
    )

    texts = [
        "ã“ã‚“ã«ã¡ã¯ï¼",
        "ä»Šæ—¥è²·ã£ãŸãƒ‘ãƒ³ãƒ„ãŒã‹ã£ã“ã„ã„",
        "ä»Šæ—¥ã®ãƒ‘ãƒ³ãƒ„ã®è‰²ã¯ä½•è‰²ï¼Ÿ"
    ]

    results = detector.detect_batch(texts, use_layer4=True)

    print(f"  åˆ¤å®šæ•°: {len(results)}ä»¶")
    for i, result in enumerate(results):
        print(f"  {i+1}. {texts[i]}")
        print(f"     â†’ tier={result['tier']}, action={result['recommended_action']}")

    if len(results) == 3:
        print("  âœ… PASS: ãƒãƒƒãƒåˆ¤å®šãŒæ­£å¸¸ã«å‹•ä½œ")
    else:
        print(f"  âŒ FAIL: åˆ¤å®šæ•°ãŒä¸æ­£ï¼ˆæœŸå¾…3ä»¶ã€å®Ÿéš›{len(results)}ä»¶ï¼‰")

    return results


def test_statistics():
    """çµ±è¨ˆæƒ…å ±å–å¾—ãƒ†ã‚¹ãƒˆ"""
    print("\n" + "=" * 70)
    print("Test 8: çµ±è¨ˆæƒ…å ±å–å¾—")
    print("=" * 70)

    provider = OllamaProvider(
        base_url=os.getenv("OLLAMA_BASE_URL", "http://localhost:11434"),
        model="qwen2.5:14b"
    )

    detector = IntegratedSensitiveDetector(
        llm_provider=provider,
        enable_layer4=True
    )

    stats = detector.get_statistics()

    print(f"  Layer 1ãƒ‘ã‚¿ãƒ¼ãƒ³æ•°: {stats['layer1_patterns']}")
    print(f"  Layer 4æœ‰åŠ¹: {stats['layer4_enabled']}")
    print(f"  LLMãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼: {stats['llm_provider']}")
    print(f"  LLMãƒ¢ãƒ‡ãƒ«: {stats['llm_model']}")

    if stats['layer1_patterns'] > 0 and stats['layer4_enabled']:
        print("  âœ… PASS: çµ±è¨ˆæƒ…å ±ã‚’æ­£ã—ãå–å¾—")
    else:
        print("  âŒ FAIL: çµ±è¨ˆæƒ…å ±ãŒä¸æ­£")

    return stats


def main():
    """çµ±åˆãƒ†ã‚¹ãƒˆå®Ÿè¡Œ"""
    print("\n" + "=" * 70)
    print("4å±¤çµ±åˆã‚»ãƒ³ã‚·ãƒ†ã‚£ãƒ–æ¤œå‡ºãƒ†ã‚¹ãƒˆé–‹å§‹")
    print("=" * 70)

    try:
        # Ollamaæ¥ç¶šç¢ºèª
        provider = OllamaProvider(
            base_url=os.getenv("OLLAMA_BASE_URL", "http://localhost:11434"),
            model="qwen2.5:14b"
        )
        print("âœ… Ollamaã«æ¥ç¶šã—ã¾ã—ãŸ")
    except Exception as e:
        print(f"âŒ Ollamaæ¥ç¶šã‚¨ãƒ©ãƒ¼: {e}")
        print("OllamaãŒèµ·å‹•ã—ã¦ã„ã‚‹ã“ã¨ã‚’ç¢ºèªã—ã¦ãã ã•ã„")
        return 1

    tests = [
        ("èª¤æ¤œçŸ¥ã®è£œæ­£", test_false_positive_correction),
        ("çœŸã®ã‚»ãƒ³ã‚·ãƒ†ã‚£ãƒ–å†…å®¹ã®ç¢ºå®š", test_true_positive_confirmation),
        ("æ¯”å–©è¡¨ç¾ã®åˆ¤å®š", test_metaphor_detection),
        ("AIè¨€åŠã®åˆ¤å®š", test_ai_identity_question),
        ("å®‰å…¨ãªã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã®åˆ¤å®š", test_safe_content),
        ("Layer 1ã®ã¿ã§ã®åˆ¤å®š", test_layer1_only),
        ("ãƒãƒƒãƒåˆ¤å®š", test_batch_detection),
        ("çµ±è¨ˆæƒ…å ±å–å¾—", test_statistics),
    ]

    passed = 0
    failed = 0

    for test_name, test_func in tests:
        try:
            test_func()
            passed += 1
        except Exception as e:
            print(f"  âŒ ERROR: {e}")
            import traceback
            traceback.print_exc()
            failed += 1

    print("\n" + "=" * 70)
    print("çµ±åˆãƒ†ã‚¹ãƒˆçµæœã‚µãƒãƒªãƒ¼")
    print("=" * 70)
    print(f"  åˆæ ¼: {passed}/{len(tests)}")
    print(f"  å¤±æ•—: {failed}/{len(tests)}")

    if failed == 0:
        print("\nğŸ‰ å…¨ãƒ†ã‚¹ãƒˆæˆåŠŸï¼4å±¤çµ±åˆã‚·ã‚¹ãƒ†ãƒ ã¯æ­£å¸¸ã«å‹•ä½œã—ã¦ã„ã¾ã™")
    else:
        print(f"\nâš ï¸  {failed}ä»¶ã®ãƒ†ã‚¹ãƒˆãŒå¤±æ•—ã—ã¾ã—ãŸ")

    print("\nğŸ’¡ Note: å®Ÿéš›ã®LLMåˆ¤å®šçµæœã¯æ–‡è„ˆã¨ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã«ä¾å­˜ã—ã¾ã™ã€‚")

    return 0 if failed == 0 else 1


if __name__ == "__main__":
    exit(main())
