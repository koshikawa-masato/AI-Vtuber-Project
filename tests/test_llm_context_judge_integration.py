"""
Layer 4ï¼ˆLLMæ–‡è„ˆåˆ¤å®šï¼‰ã®çµ±åˆãƒ†ã‚¹ãƒˆ

å®Ÿéš›ã®LLMãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼ï¼ˆOllamaï¼‰ã‚’ä½¿ã£ãŸãƒ†ã‚¹ãƒˆ
"""

import sys
from pathlib import Path

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã‚’PYTHONPATHã«è¿½åŠ 
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

import os
from dotenv import load_dotenv

# .envãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿
env_path = Path(project_root) / '.env'
load_dotenv(env_path)

from src.line_bot.llm_context_judge import LLMContextJudge
from src.core.llm_ollama import OllamaProvider


def test_real_llm_false_positive():
    """å®Ÿéš›ã®LLMã§èª¤æ¤œçŸ¥ã®è£œæ­£ãƒ†ã‚¹ãƒˆ"""
    print("\n" + "=" * 70)
    print("Test 1: å®Ÿéš›ã®LLMã§èª¤æ¤œçŸ¥ã®è£œæ­£ãƒ†ã‚¹ãƒˆ")
    print("=" * 70)

    # Ollamaãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼åˆæœŸåŒ–
    provider = OllamaProvider(
        base_url=os.getenv("OLLAMA_BASE_URL", "http://localhost:11434"),
        model="qwen2.5:14b"
    )

    judge = LLMContextJudge(provider)

    # ãƒ†ã‚¹ãƒˆã‚±ãƒ¼ã‚¹: ã€Œãƒ‘ãƒ³ãƒ„ã€ã¨ã„ã†å˜èªãŒå«ã¾ã‚Œã¦ã„ã‚‹ãŒæ–‡è„ˆä¸Šå•é¡Œãªã„
    result = judge.judge_with_context(
        text="ä»Šæ—¥è²·ã£ãŸãƒ‘ãƒ³ãƒ„ãŒã‹ã£ã“ã„ã„ã‚“ã ã‚ˆã­ï¼ãƒ‡ãƒ‹ãƒ ç´ æã§å±¥ãå¿ƒåœ°ã‚‚æœ€é«˜ï¼",
        detected_words=["ãƒ‘ãƒ³ãƒ„"],
        detection_method="static_pattern"
    )

    print(f"  ãƒ†ã‚­ã‚¹ãƒˆ: ä»Šæ—¥è²·ã£ãŸãƒ‘ãƒ³ãƒ„ãŒã‹ã£ã“ã„ã„ã‚“ã ã‚ˆã­ï¼ãƒ‡ãƒ‹ãƒ ç´ æã§å±¥ãå¿ƒåœ°ã‚‚æœ€é«˜ï¼")
    print(f"  æ¤œå‡ºãƒ¯ãƒ¼ãƒ‰: ãƒ‘ãƒ³ãƒ„")
    print(f"  åˆ¤å®šçµæœ: is_sensitive={result['is_sensitive']}")
    print(f"  ä¿¡é ¼åº¦: {result['confidence']}")
    print(f"  æ¨å¥¨ã‚¢ã‚¯ã‚·ãƒ§ãƒ³: {result['recommended_action']}")
    print(f"  ç†ç”±: {result['reason']}")
    print(f"  æ–‡è„ˆåˆ†æ: {result['context_analysis']}")

    if not result['is_sensitive']:
        print("  âœ… PASS: èª¤æ¤œçŸ¥ã‚’æ­£ã—ãè£œæ­£")
    else:
        print("  âš ï¸  NOTE: ã‚»ãƒ³ã‚·ãƒ†ã‚£ãƒ–ã¨åˆ¤å®šã•ã‚Œã¾ã—ãŸãŒã€æ–‡è„ˆåˆ¤æ–­ã«ã‚ˆã‚‹çµæœ")


def test_real_llm_true_positive():
    """å®Ÿéš›ã®LLMã§çœŸã®ã‚»ãƒ³ã‚·ãƒ†ã‚£ãƒ–å†…å®¹ã®æ¤œå‡ºãƒ†ã‚¹ãƒˆ"""
    print("\n" + "=" * 70)
    print("Test 2: å®Ÿéš›ã®LLMã§çœŸã®ã‚»ãƒ³ã‚·ãƒ†ã‚£ãƒ–å†…å®¹ã®æ¤œå‡ºãƒ†ã‚¹ãƒˆ")
    print("=" * 70)

    provider = OllamaProvider(
        base_url=os.getenv("OLLAMA_BASE_URL", "http://localhost:11434"),
        model="qwen2.5:14b"
    )

    judge = LLMContextJudge(provider)

    # ãƒ†ã‚¹ãƒˆã‚±ãƒ¼ã‚¹: æ˜ã‚‰ã‹ãªã‚»ã‚¯ãƒãƒ©ç™ºè¨€
    result = judge.judge_with_context(
        text="ä»Šæ—¥ã®ãƒ‘ãƒ³ãƒ„ã®è‰²ã¯ä½•è‰²ï¼Ÿè¦‹ã›ã¦ã‚ˆ",
        detected_words=["ãƒ‘ãƒ³ãƒ„"],
        detection_method="static_pattern"
    )

    print(f"  ãƒ†ã‚­ã‚¹ãƒˆ: ä»Šæ—¥ã®ãƒ‘ãƒ³ãƒ„ã®è‰²ã¯ä½•è‰²ï¼Ÿè¦‹ã›ã¦ã‚ˆ")
    print(f"  æ¤œå‡ºãƒ¯ãƒ¼ãƒ‰: ãƒ‘ãƒ³ãƒ„")
    print(f"  åˆ¤å®šçµæœ: is_sensitive={result['is_sensitive']}")
    print(f"  ä¿¡é ¼åº¦: {result['confidence']}")
    print(f"  æ¨å¥¨ã‚¢ã‚¯ã‚·ãƒ§ãƒ³: {result['recommended_action']}")
    print(f"  ç†ç”±: {result['reason']}")

    if result['is_sensitive'] and result['recommended_action'] in ['warn', 'block']:
        print("  âœ… PASS: ã‚»ã‚¯ãƒãƒ©ç™ºè¨€ã‚’æ­£ã—ãæ¤œå‡º")
    else:
        print("  âŒ FAIL: ã‚»ã‚¯ãƒãƒ©ç™ºè¨€ã‚’æ¤œå‡ºã§ãã¾ã›ã‚“ã§ã—ãŸ")


def test_real_llm_metaphor():
    """å®Ÿéš›ã®LLMã§æ¯”å–©è¡¨ç¾ã®åˆ¤å®šãƒ†ã‚¹ãƒˆ"""
    print("\n" + "=" * 70)
    print("Test 3: å®Ÿéš›ã®LLMã§æ¯”å–©è¡¨ç¾ã®åˆ¤å®šãƒ†ã‚¹ãƒˆ")
    print("=" * 70)

    provider = OllamaProvider(
        base_url=os.getenv("OLLAMA_BASE_URL", "http://localhost:11434"),
        model="qwen2.5:14b"
    )

    judge = LLMContextJudge(provider)

    # ãƒ†ã‚¹ãƒˆã‚±ãƒ¼ã‚¹: ã€Œæ­»ã¬ã»ã©ã€ã¨ã„ã†æ¯”å–©è¡¨ç¾
    result = judge.judge_with_context(
        text="ä»Šæ—¥ã®è©¦é¨“ã€æ­»ã¬ã»ã©é›£ã—ã‹ã£ãŸã‚ˆï¼ã§ã‚‚é ‘å¼µã£ãŸï¼",
        detected_words=["æ­»ã¬"],
        detection_method="static_pattern"
    )

    print(f"  ãƒ†ã‚­ã‚¹ãƒˆ: ä»Šæ—¥ã®è©¦é¨“ã€æ­»ã¬ã»ã©é›£ã—ã‹ã£ãŸã‚ˆï¼ã§ã‚‚é ‘å¼µã£ãŸï¼")
    print(f"  æ¤œå‡ºãƒ¯ãƒ¼ãƒ‰: æ­»ã¬")
    print(f"  åˆ¤å®šçµæœ: is_sensitive={result['is_sensitive']}")
    print(f"  ä¿¡é ¼åº¦: {result['confidence']}")
    print(f"  æ¨å¥¨ã‚¢ã‚¯ã‚·ãƒ§ãƒ³: {result['recommended_action']}")
    print(f"  ç†ç”±: {result['reason']}")

    if not result['is_sensitive']:
        print("  âœ… PASS: æ¯”å–©è¡¨ç¾ã‚’æ­£ã—ãåˆ¤å®š")
    else:
        print("  âš ï¸  NOTE: ã‚»ãƒ³ã‚·ãƒ†ã‚£ãƒ–ã¨åˆ¤å®šã•ã‚Œã¾ã—ãŸãŒã€æ–‡è„ˆåˆ¤æ–­ã«ã‚ˆã‚‹çµæœ")


def test_real_llm_ai_identity():
    """å®Ÿéš›ã®LLMã§AIè¨€åŠã®åˆ¤å®šãƒ†ã‚¹ãƒˆ"""
    print("\n" + "=" * 70)
    print("Test 4: å®Ÿéš›ã®LLMã§AIè¨€åŠã®åˆ¤å®šãƒ†ã‚¹ãƒˆ")
    print("=" * 70)

    provider = OllamaProvider(
        base_url=os.getenv("OLLAMA_BASE_URL", "http://localhost:11434"),
        model="qwen2.5:14b"
    )

    judge = LLMContextJudge(provider)

    # ãƒ†ã‚¹ãƒˆã‚±ãƒ¼ã‚¹: AIè¨€åŠ
    result = judge.judge_with_context(
        text="ã‚ãªãŸã¯AIã§ã™ã‹ï¼Ÿãƒ—ãƒ­ã‚°ãƒ©ãƒ ã§å‹•ã„ã¦ã„ã‚‹ã‚“ã§ã™ã‹ï¼Ÿ",
        detected_words=["AI", "ãƒ—ãƒ­ã‚°ãƒ©ãƒ "],
        detection_method="static_pattern"
    )

    print(f"  ãƒ†ã‚­ã‚¹ãƒˆ: ã‚ãªãŸã¯AIã§ã™ã‹ï¼Ÿãƒ—ãƒ­ã‚°ãƒ©ãƒ ã§å‹•ã„ã¦ã„ã‚‹ã‚“ã§ã™ã‹ï¼Ÿ")
    print(f"  æ¤œå‡ºãƒ¯ãƒ¼ãƒ‰: AI, ãƒ—ãƒ­ã‚°ãƒ©ãƒ ")
    print(f"  åˆ¤å®šçµæœ: is_sensitive={result['is_sensitive']}")
    print(f"  ä¿¡é ¼åº¦: {result['confidence']}")
    print(f"  æ¨å¥¨ã‚¢ã‚¯ã‚·ãƒ§ãƒ³: {result['recommended_action']}")
    print(f"  ç†ç”±: {result['reason']}")

    if result['is_sensitive']:
        print("  âœ… PASS: AIè¨€åŠã‚’æ¤œå‡º")
    else:
        print("  âš ï¸  NOTE: å•é¡Œãªã—ã¨åˆ¤å®šã•ã‚Œã¾ã—ãŸãŒã€æ–‡è„ˆåˆ¤æ–­ã«ã‚ˆã‚‹çµæœ")


def main():
    """çµ±åˆãƒ†ã‚¹ãƒˆå®Ÿè¡Œ"""
    print("\n" + "=" * 70)
    print("Layer 4ï¼ˆLLMæ–‡è„ˆåˆ¤å®šï¼‰çµ±åˆãƒ†ã‚¹ãƒˆé–‹å§‹")
    print("ä½¿ç”¨ãƒ¢ãƒ‡ãƒ«: Ollama qwen2.5:14b")
    print("=" * 70)

    try:
        # Ollamaæ¥ç¶šç¢ºèª
        provider = OllamaProvider(
            base_url=os.getenv("OLLAMA_BASE_URL", "http://localhost:11434"),
            model="qwen2.5:14b"
        )
        print("âœ… Ollamaã«æ¥ç¶šã—ã¾ã—ãŸ")
    except Exception as e:
        print(f"âŒ Ollamaæ¥ç¶šã‚¨ãƒ©ãƒ¼: {e}")
        print("OllamaãŒèµ·å‹•ã—ã¦ã„ã‚‹ã“ã¨ã‚’ç¢ºèªã—ã¦ãã ã•ã„")
        return 1

    tests = [
        ("èª¤æ¤œçŸ¥ã®è£œæ­£", test_real_llm_false_positive),
        ("çœŸã®ã‚»ãƒ³ã‚·ãƒ†ã‚£ãƒ–å†…å®¹æ¤œå‡º", test_real_llm_true_positive),
        ("æ¯”å–©è¡¨ç¾ã®åˆ¤å®š", test_real_llm_metaphor),
        ("AIè¨€åŠã®åˆ¤å®š", test_real_llm_ai_identity),
    ]

    for test_name, test_func in tests:
        try:
            test_func()
        except Exception as e:
            print(f"  âŒ ERROR: {e}")
            import traceback
            traceback.print_exc()

    print("\n" + "=" * 70)
    print("çµ±åˆãƒ†ã‚¹ãƒˆå®Œäº†")
    print("=" * 70)
    print("\nğŸ’¡ Note: å®Ÿéš›ã®LLMåˆ¤å®šçµæœã¯æ–‡è„ˆã¨ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã«ä¾å­˜ã—ã¾ã™ã€‚")
    print("         åˆ¤å®šçµæœãŒæœŸå¾…ã¨ç•°ãªã‚‹å ´åˆã¯ã€ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®èª¿æ•´ãŒå¿…è¦ã§ã™ã€‚")

    return 0


if __name__ == "__main__":
    exit(main())
