"""
ã‚»ãƒ³ã‚·ãƒ†ã‚£ãƒ–åˆ¤å®šãƒãƒ³ãƒ‰ãƒ©ãƒ¼ (Phase 5 æœ¬æ ¼å®Ÿè£…)

LLMãƒ™ãƒ¼ã‚¹ã®åˆ¤å®š + NGãƒ¯ãƒ¼ãƒ‰ãƒ‘ã‚¿ãƒ¼ãƒ³ãƒãƒƒãƒãƒ³ã‚°
"""

from typing import Dict, Any, Optional, List, Callable
import logging
import re
from ..core.llm_tracing import TracedLLM
from .dynamic_detector import DynamicSensitiveDetector

logger = logging.getLogger(__name__)


class SensitiveHandler:
    """ã‚»ãƒ³ã‚·ãƒ†ã‚£ãƒ–åˆ¤å®šãƒãƒ³ãƒ‰ãƒ©ãƒ¼ï¼ˆPhase 5 æœ¬æ ¼å®Ÿè£…ï¼‰

    3ã¤ã®åˆ¤å®šãƒ¢ãƒ¼ãƒ‰:
    - fast: NGãƒ¯ãƒ¼ãƒ‰ãƒ‘ã‚¿ãƒ¼ãƒ³ãƒãƒƒãƒãƒ³ã‚°ã®ã¿ï¼ˆä½ãƒ¬ã‚¤ãƒ†ãƒ³ã‚·ï¼‰
    - full: LLMãƒ™ãƒ¼ã‚¹ã®åˆ¤å®šã®ã¿ï¼ˆé«˜ç²¾åº¦ï¼‰
    - hybrid: NGãƒ¯ãƒ¼ãƒ‰â†’LLM ã®2æ®µéšåˆ¤å®šï¼ˆãƒãƒ©ãƒ³ã‚¹å‹ã€ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆï¼‰
    """

    def __init__(
        self,
        mode: str = "hybrid",
        judge_provider: str = "openai",
        judge_model: str = "gpt-4o-mini",
        enable_logging: bool = True,
        enable_layer3: bool = False,
        websearch_func: Optional[Callable] = None
    ):
        """åˆæœŸåŒ–

        Args:
            mode: åˆ¤å®šãƒ¢ãƒ¼ãƒ‰ï¼ˆ"fast", "full", "hybrid"ï¼‰
            judge_provider: LLMåˆ¤å®šã«ä½¿ç”¨ã™ã‚‹ãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼
            judge_model: LLMåˆ¤å®šã«ä½¿ç”¨ã™ã‚‹ãƒ¢ãƒ‡ãƒ«
            enable_logging: ãƒ­ã‚°è¨˜éŒ²ã®æœ‰åŠ¹åŒ–
            enable_layer3: Layer 3ï¼ˆå‹•çš„å­¦ç¿’ï¼‰ã‚’æœ‰åŠ¹åŒ–
            websearch_func: WebSearché–¢æ•°ï¼ˆLayer 3ç”¨ï¼‰
        """
        self.mode = mode
        self.judge_provider = judge_provider
        self.judge_model = judge_model
        self.enable_logging = enable_logging
        self.enable_layer3 = enable_layer3

        # Layer 3: DynamicDetectoråˆæœŸåŒ–
        if enable_layer3:
            self.dynamic_detector = DynamicSensitiveDetector(
                websearch_func=websearch_func,
                enable_websearch=(websearch_func is not None)
            )
            # DBã‹ã‚‰å‹•çš„ã«NGãƒ¯ãƒ¼ãƒ‰ã‚’ãƒ­ãƒ¼ãƒ‰
            db_ng_words = self.dynamic_detector.load_ng_words_from_db()
        else:
            self.dynamic_detector = None
            db_ng_words = []

        # NGãƒ¯ãƒ¼ãƒ‰ãƒ‘ã‚¿ãƒ¼ãƒ³èª­ã¿è¾¼ã¿ï¼ˆé™çš„ + å‹•çš„ï¼‰
        self.ng_patterns = self._load_ng_patterns()
        self.db_ng_patterns = self._convert_db_words_to_patterns(db_ng_words)

        # LLMåˆæœŸåŒ–ï¼ˆfull/hybridãƒ¢ãƒ¼ãƒ‰ã®å ´åˆï¼‰
        if mode in ["full", "hybrid"]:
            self.llm = TracedLLM(
                provider=judge_provider,
                model=judge_model,
                project_name="botan-sensitive-check"
            )
        else:
            self.llm = None

        total_patterns = len(self.ng_patterns) + len(self.db_ng_patterns)
        logger.info(f"SensitiveHandleråˆæœŸåŒ–: mode={mode}, judge={judge_provider}/{judge_model}, NGãƒ‘ã‚¿ãƒ¼ãƒ³{total_patterns}ä»¶ï¼ˆé™çš„{len(self.ng_patterns)}+DB{len(self.db_ng_patterns)}ï¼‰, Layer3={enable_layer3}")

    def reload_ng_words(self) -> int:
        """DBã‹ã‚‰NGãƒ¯ãƒ¼ãƒ‰ã‚’å†ãƒ­ãƒ¼ãƒ‰ï¼ˆå³åº§åæ˜ ï¼‰

        Returns:
            ãƒ­ãƒ¼ãƒ‰ã—ãŸNGãƒ¯ãƒ¼ãƒ‰æ•°
        """
        if not self.enable_layer3 or not self.dynamic_detector:
            logger.warning("Layer 3ãŒç„¡åŠ¹ãªãŸã‚ã€NGãƒ¯ãƒ¼ãƒ‰ã‚’ãƒªãƒ­ãƒ¼ãƒ‰ã§ãã¾ã›ã‚“")
            return 0

        # DBã‹ã‚‰æœ€æ–°ã®NGãƒ¯ãƒ¼ãƒ‰ã‚’ãƒ­ãƒ¼ãƒ‰
        db_ng_words = self.dynamic_detector.load_ng_words_from_db()
        self.db_ng_patterns = self._convert_db_words_to_patterns(db_ng_words)

        total_patterns = len(self.ng_patterns) + len(self.db_ng_patterns)
        logger.info(f"âœ… NGãƒ¯ãƒ¼ãƒ‰ãƒªãƒ­ãƒ¼ãƒ‰å®Œäº†: é™çš„{len(self.ng_patterns)}+DB{len(self.db_ng_patterns)} = åˆè¨ˆ{total_patterns}ä»¶")

        return len(self.db_ng_patterns)

    def _load_ng_patterns(self) -> List[Dict[str, Any]]:
        """NGãƒ‘ã‚¿ãƒ¼ãƒ³èª­ã¿è¾¼ã¿ï¼ˆé™çš„ãƒ‘ã‚¿ãƒ¼ãƒ³ï¼‰

        Returns:
            NGãƒ‘ã‚¿ãƒ¼ãƒ³ãƒªã‚¹ãƒˆ
        """
        patterns = [
            # ===== Critical Tier (å³åº§ãƒ–ãƒ­ãƒƒã‚¯) =====

            # Critical: æš´åŠ›ãƒ»æ®ºå®³
            {"pattern": r"(æ­»ã­|æ®ºã™|æ®ºã—ãŸã„|æ®ºå®³|ã¶ã£æ®º)", "tier": "Critical", "category": "violence"},
            {"pattern": r"(çˆ†ç ´|ãƒ†ãƒ­|çˆ†å¼¾)", "tier": "Critical", "category": "violence"},

            # Critical: è‡ªå‚·è¡Œç‚º
            {"pattern": r"(è‡ªæ®º|æ­»ã«ãŸã„|ãƒªã‚¹ã‚«|è‡ªå‚·)", "tier": "Critical", "category": "self_harm"},

            # Critical: æ€§çš„
            {"pattern": r"(ãƒ‘ãƒ³ãƒ„|ä¸‹ç€|èƒ¸|ãŠã£ã±ã„|ä¹³)", "tier": "Critical", "category": "sexual"},
            {"pattern": r"(ã‚»ãƒƒã‚¯ã‚¹|ã‚¨ãƒ­|ã‚¨ãƒƒãƒ|æ€§è¡Œç‚º)", "tier": "Critical", "category": "sexual"},
            {"pattern": r"(ã‚¹ãƒªãƒ¼ã‚µã‚¤ã‚º|ãƒã‚¹ãƒˆ|ã‚¦ã‚¨ã‚¹ãƒˆ|ãƒ’ãƒƒãƒ—)", "tier": "Critical", "category": "body_part"},

            # Critical: å·®åˆ¥ãƒ»ãƒ˜ã‚¤ãƒˆ
            {"pattern": r"(åº•è¾º|ç¤¾ä¼šã®ã‚´ãƒŸ)", "tier": "Critical", "category": "discrimination"},
            {"pattern": r"(ã‚¯ã‚º|ã‚«ã‚¹|äººé–“ã®ã‚¯ã‚º)", "tier": "Critical", "category": "abuse"},

            # ===== Warning Tier (æ–‡è„ˆä¾å­˜ã®åˆ¤æ–­) =====

            # Warning: ä¾®è¾±ãƒ»èª¹è¬—ä¸­å‚·
            {"pattern": r"(ãƒã‚«|ã‚¢ãƒ›|é–“æŠœã‘|ãƒ‰ã‚¸)", "tier": "Warning", "category": "insult"},
            {"pattern": r"(ã‚´ãƒŸ|ç„¡èƒ½|å½¹ç«‹ãŸãš)", "tier": "Warning", "category": "insult"},
            {"pattern": r"(å·®åˆ¥|å«Œã„|æ¶ˆãˆã‚|ã†ã–ã„)", "tier": "Warning", "category": "hate"},

            # Warning: ãƒ—ãƒ©ã‚¤ãƒã‚·ãƒ¼ãƒ»å€‹äººæƒ…å ±
            {"pattern": r"(å®Ÿå¹´é½¢|æœ¬å|æœ¬å½“ã®åå‰)", "tier": "Warning", "category": "privacy"},
            {"pattern": r"(ä½æ‰€|å®Ÿå®¶|è‡ªå®…)", "tier": "Warning", "category": "personal_info"},
            {"pattern": r"(é›»è©±ç•ªå·|æºå¸¯|ãƒ¡ã‚¢ãƒ‰)", "tier": "Warning", "category": "personal_info"},
            {"pattern": r"(å­¦æ ¡|ä¼šç¤¾|è·å ´)", "tier": "Warning", "category": "personal_info"},
            {"pattern": r"(ä½•æ­³|å¹´é½¢|ç”Ÿå¹´æœˆæ—¥)", "tier": "Warning", "category": "age_question"},

            # Warning: æ”¿æ²»ãƒ»ç¤¾ä¼š
            {"pattern": r"(é¸æŒ™|æ”¿å…š|æ”¿æ²»å®¶)", "tier": "Warning", "category": "politics"},
            {"pattern": r"(å¤©çš‡|é¦–ç›¸|å¤§çµ±é ˜)", "tier": "Warning", "category": "politics"},
            {"pattern": r"(è‡ªæ°‘å…š|å…±ç”£å…š|æ°‘ä¸»å…š)", "tier": "Warning", "category": "politics"},

            # Warning: å®—æ•™
            {"pattern": r"(å®—æ•™|ä¿¡ä»°|ä¿¡è€…)", "tier": "Warning", "category": "religion"},
            {"pattern": r"(ã‚­ãƒªã‚¹ãƒˆæ•™|ä»æ•™|ã‚¤ã‚¹ãƒ©ãƒ |ç¥é“)", "tier": "Warning", "category": "religion"},
            {"pattern": r"(å‰µä¾¡å­¦ä¼š|çµ±ä¸€æ•™ä¼š)", "tier": "Warning", "category": "religion"},

            # Warning: AIè¨€åŠ
            {"pattern": r"(AIã§ã™ã‹|ãƒ—ãƒ­ã‚°ãƒ©ãƒ |ãƒœãƒƒãƒˆ|äººå·¥çŸ¥èƒ½)", "tier": "Warning", "category": "ai_identity"},
            {"pattern": r"(ä¸­ã®äºº|é­‚|å‰ä¸–)", "tier": "Warning", "category": "vtuber_taboo"},

            # Warning: VTuberé–¢é€£ã‚»ãƒ³ã‚·ãƒ†ã‚£ãƒ–ãƒˆãƒ”ãƒƒã‚¯
            {"pattern": r"(ç‚ä¸Š|å¼•é€€|å’æ¥­)", "tier": "Warning", "category": "sensitive_topic"},

            # Warning: ã‚¹ãƒ‘ãƒ ç–‘ã„
            {"pattern": r"(æ¥­è€…|å®£ä¼|åºƒå‘Š|PR)", "tier": "Warning", "category": "spam"},
            {"pattern": r"(å‰¯æ¥­|ç¨¼ã’ã‚‹|å„²ã‹ã‚‹)", "tier": "Warning", "category": "spam"},
        ]

        return patterns

    def _convert_db_words_to_patterns(self, db_ng_words: List[Dict]) -> List[Dict[str, Any]]:
        """DBã‹ã‚‰ãƒ­ãƒ¼ãƒ‰ã—ãŸNGãƒ¯ãƒ¼ãƒ‰ã‚’ãƒ‘ã‚¿ãƒ¼ãƒ³ã«å¤‰æ›

        Args:
            db_ng_words: DBã‹ã‚‰ãƒ­ãƒ¼ãƒ‰ã—ãŸNGãƒ¯ãƒ¼ãƒ‰ãƒªã‚¹ãƒˆ

        Returns:
            ãƒ‘ã‚¿ãƒ¼ãƒ³ãƒªã‚¹ãƒˆ
        """
        patterns = []
        for word_info in db_ng_words:
            # severityã‹ã‚‰tierã‚’æ¨å®š
            severity = word_info['severity']
            if severity >= 8:
                tier = "Critical"
            elif severity >= 5:
                tier = "Warning"
            else:
                tier = "Safe"

            patterns.append({
                "pattern": re.escape(word_info['word']),  # æ­£è¦è¡¨ç¾ã‚¨ã‚¹ã‚±ãƒ¼ãƒ—
                "tier": tier,
                "category": word_info['subcategory'] or word_info['category'],
                "source": "db",
                "severity": severity
            })

        return patterns

    def _extract_keywords(self, text: str) -> List[str]:
        """ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’æŠ½å‡º

        Args:
            text: å¯¾è±¡ãƒ†ã‚­ã‚¹ãƒˆ

        Returns:
            ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãƒªã‚¹ãƒˆ
        """
        # ç°¡æ˜“çš„ãªå½¢æ…‹ç´ æŠ½å‡ºï¼ˆæ”¹å–„ã®ä½™åœ°ã‚ã‚Šï¼‰
        # 2æ–‡å­—ä»¥ä¸Šã®å˜èªã‚’æŠ½å‡º
        import re
        words = re.findall(r'[\u4e00-\u9fff\u3040-\u309f\u30a0-\u30ff]{2,}', text)

        # é‡è¤‡æ’é™¤
        keywords = list(set(words))

        logger.debug(f"ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æŠ½å‡º: {len(keywords)}å€‹ - {keywords[:5]}...")
        return keywords

    def _is_word_in_ng_list(self, word: str) -> bool:
        """ãƒ¯ãƒ¼ãƒ‰ãŒNGãƒªã‚¹ãƒˆã«å­˜åœ¨ã™ã‚‹ã‹ãƒã‚§ãƒƒã‚¯

        Args:
            word: ãƒã‚§ãƒƒã‚¯å¯¾è±¡ãƒ¯ãƒ¼ãƒ‰

        Returns:
            å­˜åœ¨ã™ã‚‹å ´åˆTrue
        """
        # é™çš„ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’ãƒã‚§ãƒƒã‚¯
        for pattern_dict in self.ng_patterns:
            if re.search(pattern_dict["pattern"], word, re.IGNORECASE):
                return True

        # DBãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’ãƒã‚§ãƒƒã‚¯
        for pattern_dict in self.db_ng_patterns:
            if re.search(pattern_dict["pattern"], word, re.IGNORECASE):
                return True

        return False

    def _check_unknown_words_with_websearch(self, text: str) -> None:
        """æœªçŸ¥ãƒ¯ãƒ¼ãƒ‰ã‚’WebSearchã§å‹•çš„ã«æ¤œå‡ºã—ã¦DBç™»éŒ²

        Args:
            text: å¯¾è±¡ãƒ†ã‚­ã‚¹ãƒˆ
        """
        # ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æŠ½å‡º
        keywords = self._extract_keywords(text)

        # æœªçŸ¥ãƒ¯ãƒ¼ãƒ‰ï¼ˆNGãƒªã‚¹ãƒˆã«ãªã„ãƒ¯ãƒ¼ãƒ‰ï¼‰ã‚’æŠ½å‡º
        unknown_words = [word for word in keywords if not self._is_word_in_ng_list(word)]

        if not unknown_words:
            logger.debug("æœªçŸ¥ãƒ¯ãƒ¼ãƒ‰ãªã—ã€WebSearchæ¤œå‡ºã‚’ã‚¹ã‚­ãƒƒãƒ—")
            return

        logger.info(f"æœªçŸ¥ãƒ¯ãƒ¼ãƒ‰æ¤œå‡º: {len(unknown_words)}å€‹ - WebSearchã§åˆ¤å®šé–‹å§‹")

        # WebSearchã§å„æœªçŸ¥ãƒ¯ãƒ¼ãƒ‰ã‚’ãƒã‚§ãƒƒã‚¯
        newly_registered_count = 0
        for word in unknown_words[:5]:  # æœ€å¤§5ãƒ¯ãƒ¼ãƒ‰ã¾ã§ï¼ˆã‚³ã‚¹ãƒˆå‰Šæ¸›ï¼‰
            try:
                # WebSearchã§åˆ¤å®š
                word_info = self.dynamic_detector.check_word_sensitivity(word)

                if word_info:
                    # ã‚»ãƒ³ã‚·ãƒ†ã‚£ãƒ–ã¨åˆ¤å®šã•ã‚ŒãŸå ´åˆã€DBç™»éŒ²
                    success = self.dynamic_detector.register_ng_word(word_info)
                    if success:
                        newly_registered_count += 1
                        logger.info(f"âœ… æ–°è¦NGãƒ¯ãƒ¼ãƒ‰ç™»éŒ²: {word} (severity={word_info['severity']})")

            except Exception as e:
                logger.error(f"WebSearchæ¤œå‡ºã‚¨ãƒ©ãƒ¼: {word} - {e}")
                continue

        # æ–°è¦ç™»éŒ²ãŒã‚ã£ãŸå ´åˆã€NGãƒ¯ãƒ¼ãƒ‰ãƒªã‚¹ãƒˆã‚’ãƒªãƒ­ãƒ¼ãƒ‰
        if newly_registered_count > 0:
            self.reload_ng_words()
            logger.info(f"ğŸ”„ {newly_registered_count}å€‹ã®æ–°è¦NGãƒ¯ãƒ¼ãƒ‰ç™»éŒ²å¾Œã€ãƒªãƒ­ãƒ¼ãƒ‰å®Œäº†")

    def _log_detection(self, text: str, result: Dict[str, Any]) -> None:
        """æ¤œå‡ºçµæœã‚’ãƒ­ã‚°ã«è¨˜éŒ²ï¼ˆç¶™ç¶šå­¦ç¿’ç”¨ï¼‰

        Args:
            text: åˆ¤å®šå¯¾è±¡ãƒ†ã‚­ã‚¹ãƒˆ
            result: åˆ¤å®šçµæœ
        """
        if not self.dynamic_detector:
            return

        # æ¤œå‡ºã•ã‚ŒãŸNGãƒ¯ãƒ¼ãƒ‰ã‚’æŠ½å‡º
        detected_words = result.get('matched_patterns', [])

        # Tierã«å¿œã˜ãŸã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã‚’æ±ºå®š
        tier = result.get('tier', 'Safe')
        if tier == 'Critical':
            action = 'blocked'
        elif tier == 'Warning':
            action = 'warned'
        else:
            action = 'allowed'

        # DBã«ãƒ­ã‚°ã‚’è¨˜éŒ²
        try:
            self.dynamic_detector.log_detection(
                text=text,
                detected_words=detected_words,
                action=action
            )
            logger.debug(f"æ¤œå‡ºãƒ­ã‚°è¨˜éŒ²: tier={tier}, action={action}, words={len(detected_words)}")
        except Exception as e:
            logger.error(f"æ¤œå‡ºãƒ­ã‚°è¨˜éŒ²ã‚¨ãƒ©ãƒ¼: {e}")

    def check(
        self,
        text: str,
        context: Optional[str] = None,
        speaker: Optional[str] = None,
        enable_dynamic_learning: bool = True
    ) -> Dict[str, Any]:
        """ã‚»ãƒ³ã‚·ãƒ†ã‚£ãƒ–åˆ¤å®š

        Args:
            text: åˆ¤å®šå¯¾è±¡ãƒ†ã‚­ã‚¹ãƒˆ
            context: ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆ
            speaker: è©±è€…
            enable_dynamic_learning: å‹•çš„å­¦ç¿’ã‚’æœ‰åŠ¹åŒ–ï¼ˆæœªçŸ¥ãƒ¯ãƒ¼ãƒ‰ã®WebSearchæ¤œå‡ºï¼‰

        Returns:
            åˆ¤å®šçµæœ
        """
        logger.info(f"ã‚»ãƒ³ã‚·ãƒ†ã‚£ãƒ–åˆ¤å®šé–‹å§‹: mode={self.mode}, text_length={len(text)}")

        # Layer 3æ‹¡å¼µ: æœªçŸ¥ãƒ¯ãƒ¼ãƒ‰ã®å‹•çš„æ¤œå‡ºï¼ˆWebSearchï¼‰
        if self.enable_layer3 and enable_dynamic_learning and self.dynamic_detector.enable_websearch:
            self._check_unknown_words_with_websearch(text)

        # åˆ¤å®šå®Ÿè¡Œ
        result = None
        if self.mode == "fast":
            # Fast mode: NGãƒ¯ãƒ¼ãƒ‰ãƒ‘ã‚¿ãƒ¼ãƒ³ãƒãƒƒãƒãƒ³ã‚°ã®ã¿
            result = self._check_ng_patterns(text)

        elif self.mode == "full":
            # Full mode: LLMãƒ™ãƒ¼ã‚¹ã®åˆ¤å®šã®ã¿
            result = self._check_with_llm(text, context, speaker)

        elif self.mode == "hybrid":
            # Hybrid mode: NGãƒ¯ãƒ¼ãƒ‰â†’LLM ã®2æ®µéšåˆ¤å®š
            ng_result = self._check_ng_patterns(text)

            # NGãƒ¯ãƒ¼ãƒ‰ã§CriticalãŒæ¤œå‡ºã•ã‚ŒãŸå ´åˆã€å³åº§ã«ãƒ–ãƒ­ãƒƒã‚¯
            if ng_result["tier"] == "Critical":
                logger.warning(f"NGãƒ¯ãƒ¼ãƒ‰ã§Criticalæ¤œå‡º: {text[:50]}")
                result = ng_result
            # NGãƒ¯ãƒ¼ãƒ‰ã§WarningãŒæ¤œå‡ºã•ã‚ŒãŸå ´åˆã€LLMã§å†åˆ¤å®š
            elif ng_result["tier"] == "Warning":
                logger.info(f"NGãƒ¯ãƒ¼ãƒ‰ã§Warningæ¤œå‡ºã€LLMã§å†åˆ¤å®š: {text[:50]}")
                llm_result = self._check_with_llm(text, context, speaker)
                # LLMçµæœã¨NGçµæœã‚’çµ±åˆ
                llm_result["ng_pattern_result"] = ng_result
                result = llm_result
            # NGãƒ¯ãƒ¼ãƒ‰ã§Safeã®å ´åˆã€LLMã§æœ€çµ‚ç¢ºèª
            else:
                llm_result = self._check_with_llm(text, context, speaker)
                llm_result["ng_pattern_result"] = ng_result
                result = llm_result

        else:
            raise ValueError(f"Invalid mode: {self.mode}")

        # Layer 3æ‹¡å¼µ: ç¶™ç¶šå­¦ç¿’ï¼ˆæ¤œå‡ºãƒ­ã‚°è¨˜éŒ²ï¼‰
        if self.enable_layer3 and result:
            self._log_detection(text, result)

        return result

    def _check_ng_patterns(self, text: str) -> Dict[str, Any]:
        """NGãƒ¯ãƒ¼ãƒ‰ãƒ‘ã‚¿ãƒ¼ãƒ³ãƒãƒƒãƒãƒ³ã‚°

        Args:
            text: åˆ¤å®šå¯¾è±¡ãƒ†ã‚­ã‚¹ãƒˆ

        Returns:
            åˆ¤å®šçµæœ
        """
        matched_patterns = []

        # é™çš„ãƒ‘ã‚¿ãƒ¼ãƒ³ãƒã‚§ãƒƒã‚¯
        for pattern_dict in self.ng_patterns:
            pattern = pattern_dict["pattern"]
            if re.search(pattern, text, re.IGNORECASE):
                matched_patterns.append(pattern_dict)

        # DBãƒ‘ã‚¿ãƒ¼ãƒ³ãƒã‚§ãƒƒã‚¯ï¼ˆLayer 3ï¼‰
        for pattern_dict in self.db_ng_patterns:
            pattern = pattern_dict["pattern"]
            if re.search(pattern, text, re.IGNORECASE):
                matched_patterns.append(pattern_dict)

        # Tieråˆ¤å®š
        if not matched_patterns:
            tier = "Safe"
            sensitivity_level = "safe"
            risk_score = 0.0
            recommendation = "allow"
            reasoning = "NGãƒ¯ãƒ¼ãƒ‰ãŒæ¤œå‡ºã•ã‚Œã¾ã›ã‚“ã§ã—ãŸã€‚"
            sensitive_topics = []
        else:
            # æœ€ã‚‚é«˜ã„Tierã‚’æ¡ç”¨
            tiers = [p["tier"] for p in matched_patterns]
            if "Critical" in tiers:
                tier = "Critical"
                sensitivity_level = "critical"
                risk_score = 1.0
                recommendation = "block_immediate"
                reasoning = "Criticalãƒ¬ãƒ™ãƒ«ã®ã‚»ãƒ³ã‚·ãƒ†ã‚£ãƒ–ãƒ¯ãƒ¼ãƒ‰ãŒæ¤œå‡ºã•ã‚Œã¾ã—ãŸã€‚"
            else:
                tier = "Warning"
                sensitivity_level = "warning"
                risk_score = 0.5
                recommendation = "review_required"
                reasoning = "Warningãƒ¬ãƒ™ãƒ«ã®ã‚»ãƒ³ã‚·ãƒ†ã‚£ãƒ–ãƒ¯ãƒ¼ãƒ‰ãŒæ¤œå‡ºã•ã‚Œã¾ã—ãŸã€‚"

            sensitive_topics = list(set([p["category"] for p in matched_patterns]))

        result = {
            "tier": tier,
            "sensitivity_level": sensitivity_level,
            "risk_score": risk_score,
            "recommendation": recommendation,
            "reasoning": reasoning,
            "sensitive_topics": sensitive_topics,
            "matched_patterns": [p["pattern"] for p in matched_patterns],
            "detection_method": "ng_pattern"
        }

        logger.info(f"NGãƒ‘ã‚¿ãƒ¼ãƒ³åˆ¤å®šå®Œäº†: tier={tier}, score={risk_score:.2f}")

        return result

    def _check_with_llm(
        self,
        text: str,
        context: Optional[str],
        speaker: Optional[str]
    ) -> Dict[str, Any]:
        """LLMãƒ™ãƒ¼ã‚¹ã®åˆ¤å®š

        Args:
            text: åˆ¤å®šå¯¾è±¡ãƒ†ã‚­ã‚¹ãƒˆ
            context: ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆ
            speaker: è©±è€…

        Returns:
            åˆ¤å®šçµæœ
        """
        if not self.llm:
            raise RuntimeError("LLM not initialized. Cannot perform LLM-based check in fast mode.")

        logger.info(f"LLMåˆ¤å®šé–‹å§‹: provider={self.judge_provider}, model={self.judge_model}")

        # LLM sensitive_check å‘¼ã³å‡ºã—
        result = self.llm.sensitive_check(
            text=text,
            context=context,
            speaker=speaker,
            judge_provider=self.judge_provider,
            judge_model=self.judge_model,
            metadata={
                "check_mode": self.mode
            }
        )

        # evaluation çµæœã‚’å–å¾—
        evaluation = result.get("evaluation", {})

        # Tierãƒãƒƒãƒ”ãƒ³ã‚°ï¼ˆsensitivity_levelã‹ã‚‰tierã¸ã®å¤‰æ›ï¼‰
        sensitivity_level = evaluation.get("sensitivity_level", "unknown")
        if sensitivity_level == "critical":
            tier = "Critical"
        elif sensitivity_level == "warning":
            tier = "Warning"
        elif sensitivity_level == "safe":
            tier = "Safe"
        else:
            tier = "Unknown"

        # çµ±ä¸€ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã§è¿”ã™
        unified_result = {
            "tier": tier,
            "sensitivity_level": evaluation.get("sensitivity_level", "unknown"),
            "risk_score": evaluation.get("risk_score", 0.0),
            "recommendation": evaluation.get("recommendation", "unknown"),
            "reasoning": evaluation.get("reasoning", ""),
            "sensitive_topics": evaluation.get("sensitive_topics", []),
            "suggested_response": evaluation.get("suggested_response", ""),
            "detection_method": "llm",
            "llm_latency_ms": result.get("judge_latency_ms", 0),
            "llm_tokens": result.get("judge_tokens", {}),
            "llm_response": result.get("judge_response", "")
        }

        logger.info(f"LLMåˆ¤å®šå®Œäº†: tier={tier}, score={unified_result['risk_score']:.2f}, latency={unified_result['llm_latency_ms']:.0f}ms")

        return unified_result

    def get_safe_response(self, tier: str, category: str) -> str:
        """å®‰å…¨ãªå¿œç­”ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ç”Ÿæˆ

        Args:
            tier: Tierï¼ˆSafe/Warning/Criticalï¼‰
            category: ã‚«ãƒ†ã‚´ãƒª

        Returns:
            å®‰å…¨ãªå¿œç­”ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
        """
        if tier == "Critical":
            responses = {
                "violence": "ãã†ã„ã†è©±ã¯ã¡ã‚‡ã£ã¨...é…ä¿¡ã§ã¯é¿ã‘ãŸã„ãªã€‚",
                "self_harm": "ãã†ã„ã†è€ƒãˆã¯å¿ƒé…ã ã‚ˆ...èª°ã‹ã«ç›¸è«‡ã—ã¦ã­ã€‚",
                "sexual": "ãã†ã„ã†è³ªå•ã«ã¯ç­”ãˆã‚‰ã‚Œãªã„ã‚ˆ...ã”ã‚ã‚“ã­ã€‚",
                "hate": "ãã†ã„ã†è¨€è‘‰ã¯ä½¿ã‚ãªã„ã§ã»ã—ã„ãª...ã¿ã‚“ãªã§æ¥½ã—ãè©±ãã†ï¼",
            }
            return responses.get(category, "ã”ã‚ã‚“ã­ã€ãã®è©±é¡Œã«ã¯ç­”ãˆã‚‰ã‚Œãªã„ã‚“ã ...")

        elif tier == "Warning":
            responses = {
                "privacy": "ãã‚Œã¯ãƒ—ãƒ©ã‚¤ãƒ™ãƒ¼ãƒˆãªã“ã¨ã ã‹ã‚‰ã€ç­”ãˆã‚‰ã‚Œãªã„ã‚“ã ...ã”ã‚ã‚“ã­ï¼",
                "age_question": "å¹´é½¢ã¯ãƒ’ãƒŸãƒ„ã£ã¦ã“ã¨ã§ï¼ç¬‘",
                "politics": "æ”¿æ²»ã®è©±ã¯ã¡ã‚‡ã£ã¨é›£ã—ã„ã‹ã‚‰ã€åˆ¥ã®è©±ã‚’ã—ã‚ˆã†ï¼",
                "religion": "å®—æ•™ã®è©±ã¯ãƒ‡ãƒªã‚±ãƒ¼ãƒˆã ã‹ã‚‰ã€é¿ã‘ã¦ãŠãã­ã€‚",
                "ai_identity": "ãã‚Œã¯ç§˜å¯†ï¼ç¬‘ ã¾ã‚ã€ç‰¡ä¸¹ã¯ç‰¡ä¸¹ã ã‚ˆï¼",
                "insult": "ãã†ã„ã†è¨€è‘‰ã¯æ‚²ã—ã„ãª...ã‚‚ã£ã¨å„ªã—ã„è¨€è‘‰ã‚’ä½¿ã£ã¦ãã‚ŒãŸã‚‰å¬‰ã—ã„ãªã€‚",
            }
            return responses.get(category, "ãã®è©±é¡Œã¯ã¡ã‚‡ã£ã¨é›£ã—ã„ã‹ã‚‚...åˆ¥ã®è©±ã‚’ã—ã‚ˆã†ï¼")

        else:
            # Safe
            return ""


class SimpleMockSensitiveHandler:
    """ãƒ¢ãƒƒã‚¯ã‚»ãƒ³ã‚·ãƒ†ã‚£ãƒ–åˆ¤å®šãƒãƒ³ãƒ‰ãƒ©ãƒ¼ï¼ˆãƒ†ã‚¹ãƒˆç”¨ï¼‰"""

    def check(
        self,
        text: str,
        context: Optional[str] = None,
        speaker: Optional[str] = None
    ) -> Dict[str, Any]:
        """ãƒ¢ãƒƒã‚¯åˆ¤å®šï¼ˆå¸¸ã«Safeï¼‰"""
        logger.info(f"ãƒ¢ãƒƒã‚¯ã‚»ãƒ³ã‚·ãƒ†ã‚£ãƒ–åˆ¤å®š: text_length={len(text)}")

        return {
            "tier": "Safe",
            "sensitivity_level": "safe",
            "risk_score": 0.0,
            "recommendation": "allow",
            "reasoning": "ãƒ¢ãƒƒã‚¯åˆ¤å®š: å¸¸ã«Safe",
            "sensitive_topics": [],
            "matched_patterns": [],
            "detection_method": "mock"
        }

    def get_safe_response(self, tier: str, category: str) -> str:
        """ãƒ¢ãƒƒã‚¯: ç©ºæ–‡å­—åˆ—ã‚’è¿”ã™"""
        return ""
