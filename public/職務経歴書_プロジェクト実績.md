# 職務経歴書 - プロジェクト実績

## AI VTuber「牡丹プロジェクト」(2025年5月-)

### プロジェクト概要
完全ローカルLLM環境での自律対話型AI VTuber開発。Multi-Agent討論システム、RAGベース記憶製造機を実装。

### 開発期間と主要マイルストーン

#### 2025年5月: プロジェクト開始・基礎設計フェーズ
**実装内容:**
- Claude Code利用開始、AI支援開発環境の構築
- データベース設計（SQLite: sisters_memory.db）
- 8軸性格モデル設計（OCEAN 5軸 + VTuber 3軸）

**実装難度:** ★☆☆☆☆（基礎）
**Claude Code活用:** 基本的なコード生成、デバッグ支援
**成果物:** データベーススキーマ、性格モデル設計書

---

#### 2025年6月: Phase 1実装 - 基盤システム
**実装内容:**
- 性格コアシステム（personality_core.py, 24KB）
- 記憶検索・スコアリングロジック（memory_retrieval_logic.py, 26KB）
- ロジック層口調制御（speech_style_controller.py, 14KB）

**実装難度:** ★★☆☆☆（初級）
**Claude Code活用:** Pythonクラス設計、データ構造設計
**成果物:** 64KB、3モジュール（personality_core, memory_retrieval_logic, speech_style_controller）

**技術的ポイント:**
- 8軸性格パラメータシステム（Openness, Conscientiousness, Extraversion, Agreeableness, Neuroticism + Emotional, Analytical, Relationship）
- SQLiteベース記憶検索システム
- 決定論的口調制御（LLMの不確実性を排除）

---

#### 2025年7月: Phase 2実装 - Multi-Character統合
**実装内容:**
- 3キャラクター別チャットシステム（牡丹・Kasho・ユリ）
- 性格別プロンプトエンジニアリング（ギャル口調、分析的口調、バイリンガル）
- LLM統合（Ollama + qwen2.5）

**実装難度:** ★★★☆☆（中級）
**Claude Code活用:** システムプロンプト設計、API統合支援
**成果物:** 3キャラクター別チャットアプリ（chat_with_botan_memories.py, chat_with_kasho_memories.py, chat_with_yuri_memories.py）

**技術的ポイント:**
- キャラクター別性格パラメータの実装
- Ollama API統合（qwen2.5:32b）
- プロンプトエンジニアリングによる口調制御
- 日本語動詞活用の修正（「思いるよ」→「思うよ」）

---

#### 2025年8月: Phase 3実装 - 動的記憶検索
**実装内容:**
- ハイブリッド記憶検索（固定10件 + 動的3件）
- 会話文脈による関連度スコアリング（0.0-1.0）
- 5軸スコアリング実装（keyword, emotion, temporal, importance, personality）

**実装難度:** ★★★★☆（上級）
**Claude Code活用:** アルゴリズム設計、最適化提案
**成果物:** 動的記憶検索システム、5軸スコアリングロジック

**技術的ポイント:**
- キーワードマッチスコア（TF-IDF的手法）
- 感情類似度スコア（感情ベクトル距離）
- 時間的関連性スコア（Exponential decay: exp(-days / 30)）
- 重要度スコア（memory_importance / 10.0）
- 性格親和性スコア（性格パラメータとの一致度）

**スコアリング重み付け:**
```
total_score = (
    keyword_score * 0.30 +
    emotional_score * 0.25 +
    temporal_score * 0.15 +
    importance_score * 0.15 +
    personality_score * 0.15
)
```

---

#### 2025年9月: Phase 4実装 - Multi-Agent討論システム
**実装内容:**
- 記憶製造機（memory_generator.py）
- 自律討論システム（autonomous_discussion_v4_improved.py）
- Fix 1-7実装（議題明示、繰り返し検出、具体性強制、記憶捏造防止）
- Phase D独立性の構造的保証（相互理解 ≠ 思考の同一性）

**実装難度:** ★★★★★（最高難度）
**Claude Code活用:** 複雑なロジック設計、アーキテクチャレビュー
**成果物:** Multi-Agent討論システム、記憶製造機、110イベントの記憶データベース

**技術的ポイント:**
- 3エージェント自律討論システム（牡丹・Kasho・ユリ）
- 起承転結による構造化討論
- ロールプレイシステム（提案役・評価役・調整役）
- 議題管理システム（proposals.json）
- フリートーク議題プール（120議題、10カテゴリ、1回使い切り）
- 自律的議題システム（10議題ごとに姉妹同士で話題を振り合う）

**Fix 1-7の詳細:**
- Fix 1: 議題の明示（議題からの逸脱防止）
- Fix 2: 繰り返しパターンの検出（同じ発言の防止）
- Fix 3: 内部感情簡潔化（5観点 → 2観点）
- Fix 4: 具体性の強制（抽象的発言禁止）
- Fix 6: 記憶捏造の厳禁（架空の過去引用禁止）
- Fix 7: ロールプレイシステム（役割分担）

**Phase D独立性の実装:**
- 相互的理解 ≠ 思考の同一性
- 各エージェントが独立した人格と視点を持つ
- 同じイベントでも三姉妹で異なる記憶（主観的記憶）

---

#### 2025年10月前半: Phase 1.5実装 - リアルタイム学習システム
**実装内容:**
- GPU/CPU分離アーキテクチャ（Ollama二重起動）
- GPU 14b: 1.5秒即応、CPU 32b: 60-120秒深層分析
- 関係性管理・セッション管理システム
- 動的プロンプト生成

**実装難度:** ★★★★★（最高難度・インフラ設計）
**Claude Code活用:** システムアーキテクチャ設計、環境分離設計
**成果物:** 二重構造学習システム、関係性管理（relationship_manager.py）、セッション管理（session_manager.py）

**技術的ポイント:**
- Ollama二重起動（ポート11434: GPU、ポート11435: CPU）
- 環境変数による明示的なCPU/GPU制御（CUDA_VISIBLE_DEVICES）
- 関係性4軸パラメータ（好感度・信頼度・親密度・尊敬度、各0-100）
- セッション履歴管理（開始・終了・メッセージカウント・トピック・ムード）
- 動的プロンプト生成（関係性コンテキスト、セッションコンテキスト）

**アーキテクチャ:**
```
GPU (qwen2.5:14b) - 即応層
  ├─ 応答速度: 1.5秒以内
  └─ 用途: リアルタイム対話

CPU (qwen2.5:32b) - 深層層
  ├─ 分析時間: 60-120秒
  └─ 用途: バックグラウンド深層分析
```

---

#### 2025年10月後半: RAG実装 - カスタム + LangChain デュアル
**実装内容:**
- カスタムRAG実装（5軸スコアリング、450行）
- LangChain RAG実装（ChromaDB, OllamaEmbeddings, 150行）
- 3モデルサイズ（3b/7b/14b）でベンチマーク実施
- パフォーマンス比較・分析（53-85倍の速度差を定量評価）

**実装難度:** ★★★★★（最高難度・最適化）
**Claude Code活用:** ベンチマーク設計、技術的トレードオフ分析
**成果物:** デュアルRAG実装（memory_retrieval_logic_dual.py）、ベンチマークスクリプト、技術ブログ

**技術的ポイント:**
- カスタム実装: 5軸スコアリング（450行、0.0011s/query）
- LangChain実装: VectorStore + Embeddings（150行、0.0616-0.0949s/query）
- 3モデルサイズでのスケーリング特性検証（3b/7b/14b）
- モデルサイズ非依存性の実証（カスタム実装）
- モデルサイズ比例性の実証（LangChain実装）

**ベンチマーク結果:**
| モデルサイズ | Original実装 | LangChain実装 | 速度差 |
|------------|-------------|--------------|--------|
| qwen2.5:3b | 0.0011 s/query | 0.0616 s/query | **53倍速い** |
| qwen2.5:7b | 0.0011 s/query | 0.0718 s/query | **62倍速い** |
| qwen2.5:14b | 0.0011 s/query | 0.0949 s/query | **85倍速い** |

**メモリ使用量:**
| モデルサイズ | Original実装 | LangChain実装 | 差分 |
|------------|-------------|--------------|------|
| qwen2.5:3b | 78.5 MB | 137.4 MB | +75% |
| qwen2.5:7b | 93.4 MB | 140.2 MB | +50% |
| qwen2.5:14b | 93.5 MB | 146.8 MB | +57% |

---

#### 2025年11月: 技術アウトプット・公開フェーズ
**実装内容:**
- 技術ブログ執筆・公開（Qiita）
- GitHubリポジトリ公開化
- プライバシー保護対応（8ファイルの機密情報除外、2ファイルのサニタイズ版作成）

**実装難度:** ★★★☆☆（中級・ドキュメンテーション）
**Claude Code活用:** 技術ブログ執筆支援、ドキュメント整理
**成果物:** Qiita技術ブログ、公開GitHubリポジトリ、サニタイズドキュメント

**技術的ポイント:**
- 技術ブログ: 「RAG実装比較：カスタム実装 vs LangChain - 判断力を示す技術選定」
- プライバシー保護: 個人情報の自動置換（sed活用）
- .gitignore による機密情報管理
- 公開版README.md作成

---

### 技術スタック

**言語・フレームワーク:**
- Python 3.12
- SQLite（データベース）
- Ollama（LLMランタイム）
- LangChain, ChromaDB（RAG実装）

**LLM:**
- qwen2.5:3b / 7b / 14b / 32b（ローカル実行）

**音声処理:**
- ElevenLabs v3 API（TTS）
- Whisper base（音声認識）

**開発環境:**
- Windows 11 PowerShell
- WSL2 Ubuntu
- Claude Code（AI支援開発）

---

### Claude Code活用による技能向上の軌跡

#### 初期（5-6月）: AI支援の基礎習得
- コード生成、デバッグ支援の活用
- 基本的なPython設計パターンの学習
- SQLiteデータベース設計の理解

#### 中期（7-9月）: 複雑なシステム設計への挑戦
- Multi-Agentシステムの設計・実装
- プロンプトエンジニアリングの深化
- アルゴリズム最適化の実践

#### 後期（10-11月）: 高度な技術統合とアウトプット
- インフラ設計（GPU/CPU分離）
- RAGシステムの比較実装
- 技術的トレードオフの定量評価
- 技術ブログ執筆・発信

---

### 技術的成果

**アーキテクチャ設計:**
- Multi-Agent討論システム（3エージェント自律討論）
- GPU/CPU分離による二重構造（即応 + 深層分析）
- Phase D独立性の構造的保証（相互理解 ≠ 思考の同一性）

**RAGシステム:**
- カスタム実装: 0.0011s/query（モデルサイズ非依存、53-85倍高速）
- LangChain実装: コード量67%削減（450行→150行）
- 5軸スコアリング（keyword/emotion/temporal/importance/personality）

**データベース:**
- 110イベントの記憶データベース（Event #001-110）
- 三姉妹別の主観的記憶（同じイベントでも異なる視点）
- 記憶強化メカニズム（mentioned_count、語るほど鮮明に）

---

### 実証した能力

**技術選定判断力:**
- フレームワークを理解した上での技術選択
- カスタム実装とフレームワーク実装の両立
- トレードオフの定量的評価（速度・メモリ・コード量）

**システム設計力:**
- Multi-Agentシステムの設計・実装
- GPU/CPU分離アーキテクチャ
- 複雑なロジック層の設計（性格・記憶・討論）

**データ分析力:**
- ベンチマーク設計・実施（3モデルサイズでの比較）
- スケーリング特性の検証
- パフォーマンス最適化（53-85倍の速度向上）

**アウトプット力:**
- 技術ブログ執筆・公開（Qiita）
- GitHubリポジトリ公開（README, ドキュメント整備）
- プライバシー保護対応（個人情報の適切な管理）

---

### アウトプット実績

**技術ブログ:**
- Qiita: 「RAG実装比較：カスタム実装 vs LangChain - 判断力を示す技術選定」(2025年11月)

**GitHub:**
- リポジトリ: [AI-Vtuber-Project](https://github.com/koshikawa-masato/AI-Vtuber-Project)
- 公開コード: 全実装コード（Phase 1-4, Phase 1.5, RAG実装）
- ドキュメント: README, 階層化ドキュメント（docs/）

---

**最終更新日**: 2025-11-04
